{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNLSTM_pamap2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**CNN-LSTM model for Human Activity Recognition**\n",
        "\n",
        "\n",
        "Experiements on [Pamap2](https://archive.ics.uci.edu/ml/datasets/pamap2+physical+activity+monitoring) dataset using different combinations of (with/without) x (channel, temporal and/or spatial attention). \n",
        "\n",
        "Baseline CNN-LSTM architecture used is proposed in [Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition](https://www.mdpi.com/1424-8220/16/1/115/htm).  "
      ],
      "metadata": {
        "id": "-hUwKQBBY40r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSzZmQw9QLlv",
        "outputId": "09eff22f-1e23-4a7c-aea3-f7699d796dba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml h5py  # Required to save models in HDF5 format\n",
        "!pip install -q tensorflow-addons\n",
        "!pip install keras\n",
        "!pip install pyts\n"
      ],
      "metadata": {
        "id": "UAFxJj4VR7Vf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d62f47-d681-48cd-bf84-ef0102b61cae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyts in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numba>=0.48.0 in /usr/local/lib/python3.7/dist-packages (from pyts) (0.56.0)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from pyts) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pyts) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from pyts) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.17.5 in /usr/local/lib/python3.7/dist-packages (from pyts) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts) (4.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts) (0.39.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->pyts) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.48.0->pyts) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.48.0->pyts) (3.8.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/Debarshi-Bhattacharya/Ensem_HAR/blob/9d7769f34258185c56feb7c34f6059e07469030f/Implementation_on_PAMAP2/datapreprocessing.ipynb\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import h5py\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "'''\n",
        "0: 'transient', 1: 'lying', 2: 'sitting', 3: 'standing', 4: 'walking', 5: 'running', 6: 'cycling', 7: 'Nordic_walking', 9: 'watching_TV', \n",
        "10: 'computer_work', 11: 'car driving', 12: 'ascending_stairs', 13: 'descending_stairs', 16: 'vacuum_cleaning', 17: 'ironing', \n",
        "18: 'folding_laundry', 19: 'house_cleaning', 20: 'playing_soccer', 24: 'rope_jumping'\n",
        "'''\n",
        "\n",
        "def read_files():\n",
        "    list_of_files = ['Protocol/subject101.dat',\n",
        "                     'Protocol/subject102.dat',\n",
        "                     'Protocol/subject103.dat',\n",
        "                     'Protocol/subject104.dat',\n",
        "                     'Protocol/subject105.dat',\n",
        "                     'Protocol/subject106.dat',\n",
        "                     'Protocol/subject107.dat',\n",
        "                     'Protocol/subject108.dat',\n",
        "                     'Protocol/subject109.dat']\n",
        "    \n",
        "    subjectID = [1,2,3,4,5,6,7,8,9]\n",
        "    \n",
        "    # there are 54 columns in the data files\n",
        "    colNames = [\"timestamp\", \"activityID\",\"heartrate\"] # 1, 2, 3\n",
        "    IMUhand = ['handTemperature', \n",
        "               'handAcc16_1', 'handAcc16_2', 'handAcc16_3', \n",
        "               'handAcc6_1', 'handAcc6_2', 'handAcc6_3', \n",
        "               'handGyro1', 'handGyro2', 'handGyro3', \n",
        "               'handMagne1', 'handMagne2', 'handMagne3',\n",
        "               'handOrientation1', 'handOrientation2', 'handOrientation3', 'handOrientation4'] # 4-20\n",
        "    IMUchest = ['chestTemperature', \n",
        "               'chestAcc16_1', 'chestAcc16_2', 'chestAcc16_3', \n",
        "               'chestAcc6_1', 'chestAcc6_2', 'chestAcc6_3', \n",
        "               'chestGyro1', 'chestGyro2', 'chestGyro3', \n",
        "               'chestMagne1', 'chestMagne2', 'chestMagne3',\n",
        "               'chestOrientation1', 'chestOrientation2', 'chestOrientation3', 'chestOrientation4'] # 21-37\n",
        "    IMUankle = ['ankleTemperature', \n",
        "               'ankleAcc16_1', 'ankleAcc16_2', 'ankleAcc16_3', \n",
        "               'ankleAcc6_1', 'ankleAcc6_2', 'ankleAcc6_3', \n",
        "               'ankleGyro1', 'ankleGyro2', 'ankleGyro3', \n",
        "               'ankleMagne1', 'ankleMagne2', 'ankleMagne3',\n",
        "               'ankleOrientation1', 'ankleOrientation2', 'ankleOrientation3', 'ankleOrientation4'] # 38-54\n",
        "    \n",
        "    columns = colNames + IMUhand + IMUchest + IMUankle\n",
        "    \n",
        "    dataCollection = pd.DataFrame()\n",
        "\n",
        "    for file in list_of_files:\n",
        "        print(file)\n",
        "        procData = pd.read_table(file, header=None, sep='\\s+')\n",
        "        procData.columns = columns\n",
        "        dataCollection = dataCollection.append(procData, ignore_index=True) \n",
        "        \n",
        "    dataCollection.reset_index(drop=True, inplace=True)\n",
        "    \n",
        "    return dataCollection\n",
        "\n",
        "data = read_files()\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "YbmYrB20AkyI",
        "outputId": "691cb256-aef2-4364-edcc-58a02a5bfac7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Protocol/subject101.dat\n",
            "Protocol/subject102.dat\n",
            "Protocol/subject103.dat\n",
            "Protocol/subject104.dat\n",
            "Protocol/subject105.dat\n",
            "Protocol/subject106.dat\n",
            "Protocol/subject107.dat\n",
            "Protocol/subject108.dat\n",
            "Protocol/subject109.dat\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   timestamp  activityID  heartrate  handTemperature  handAcc16_1  \\\n",
              "0       8.38           0      104.0             30.0      2.37223   \n",
              "1       8.39           0        NaN             30.0      2.18837   \n",
              "2       8.40           0        NaN             30.0      2.37357   \n",
              "3       8.41           0        NaN             30.0      2.07473   \n",
              "4       8.42           0        NaN             30.0      2.22936   \n",
              "\n",
              "   handAcc16_2  handAcc16_3  handAcc6_1  handAcc6_2  handAcc6_3  ...  \\\n",
              "0      8.60074      3.51048     2.43954     8.76165     3.35465  ...   \n",
              "1      8.56560      3.66179     2.39494     8.55081     3.64207  ...   \n",
              "2      8.60107      3.54898     2.30514     8.53644     3.73280  ...   \n",
              "3      8.52853      3.66021     2.33528     8.53622     3.73277  ...   \n",
              "4      8.83122      3.70000     2.23055     8.59741     3.76295  ...   \n",
              "\n",
              "   ankleGyro1  ankleGyro2  ankleGyro3  ankleMagne1  ankleMagne2  ankleMagne3  \\\n",
              "0    0.008300    0.009250   -0.017580     -61.1888     -38.9599     -58.1438   \n",
              "1   -0.006577   -0.004638    0.000368     -59.8479     -38.8919     -58.5253   \n",
              "2    0.003014    0.000148    0.022495     -60.7361     -39.4138     -58.3999   \n",
              "3    0.003175   -0.020301    0.011275     -60.4091     -38.7635     -58.3956   \n",
              "4    0.012698   -0.014303   -0.002823     -61.5199     -39.3879     -58.2694   \n",
              "\n",
              "   ankleOrientation1  ankleOrientation2  ankleOrientation3  ankleOrientation4  \n",
              "0                1.0                0.0                0.0                0.0  \n",
              "1                1.0                0.0                0.0                0.0  \n",
              "2                1.0                0.0                0.0                0.0  \n",
              "3                1.0                0.0                0.0                0.0  \n",
              "4                1.0                0.0                0.0                0.0  \n",
              "\n",
              "[5 rows x 54 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e589b6dd-dbdc-40a4-9c07-f76940710069\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>activityID</th>\n",
              "      <th>heartrate</th>\n",
              "      <th>handTemperature</th>\n",
              "      <th>handAcc16_1</th>\n",
              "      <th>handAcc16_2</th>\n",
              "      <th>handAcc16_3</th>\n",
              "      <th>handAcc6_1</th>\n",
              "      <th>handAcc6_2</th>\n",
              "      <th>handAcc6_3</th>\n",
              "      <th>...</th>\n",
              "      <th>ankleGyro1</th>\n",
              "      <th>ankleGyro2</th>\n",
              "      <th>ankleGyro3</th>\n",
              "      <th>ankleMagne1</th>\n",
              "      <th>ankleMagne2</th>\n",
              "      <th>ankleMagne3</th>\n",
              "      <th>ankleOrientation1</th>\n",
              "      <th>ankleOrientation2</th>\n",
              "      <th>ankleOrientation3</th>\n",
              "      <th>ankleOrientation4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.38</td>\n",
              "      <td>0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>2.37223</td>\n",
              "      <td>8.60074</td>\n",
              "      <td>3.51048</td>\n",
              "      <td>2.43954</td>\n",
              "      <td>8.76165</td>\n",
              "      <td>3.35465</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008300</td>\n",
              "      <td>0.009250</td>\n",
              "      <td>-0.017580</td>\n",
              "      <td>-61.1888</td>\n",
              "      <td>-38.9599</td>\n",
              "      <td>-58.1438</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.39</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.0</td>\n",
              "      <td>2.18837</td>\n",
              "      <td>8.56560</td>\n",
              "      <td>3.66179</td>\n",
              "      <td>2.39494</td>\n",
              "      <td>8.55081</td>\n",
              "      <td>3.64207</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.006577</td>\n",
              "      <td>-0.004638</td>\n",
              "      <td>0.000368</td>\n",
              "      <td>-59.8479</td>\n",
              "      <td>-38.8919</td>\n",
              "      <td>-58.5253</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.40</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.0</td>\n",
              "      <td>2.37357</td>\n",
              "      <td>8.60107</td>\n",
              "      <td>3.54898</td>\n",
              "      <td>2.30514</td>\n",
              "      <td>8.53644</td>\n",
              "      <td>3.73280</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003014</td>\n",
              "      <td>0.000148</td>\n",
              "      <td>0.022495</td>\n",
              "      <td>-60.7361</td>\n",
              "      <td>-39.4138</td>\n",
              "      <td>-58.3999</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.41</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.0</td>\n",
              "      <td>2.07473</td>\n",
              "      <td>8.52853</td>\n",
              "      <td>3.66021</td>\n",
              "      <td>2.33528</td>\n",
              "      <td>8.53622</td>\n",
              "      <td>3.73277</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003175</td>\n",
              "      <td>-0.020301</td>\n",
              "      <td>0.011275</td>\n",
              "      <td>-60.4091</td>\n",
              "      <td>-38.7635</td>\n",
              "      <td>-58.3956</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.42</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.0</td>\n",
              "      <td>2.22936</td>\n",
              "      <td>8.83122</td>\n",
              "      <td>3.70000</td>\n",
              "      <td>2.23055</td>\n",
              "      <td>8.59741</td>\n",
              "      <td>3.76295</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012698</td>\n",
              "      <td>-0.014303</td>\n",
              "      <td>-0.002823</td>\n",
              "      <td>-61.5199</td>\n",
              "      <td>-39.3879</td>\n",
              "      <td>-58.2694</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 54 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e589b6dd-dbdc-40a4-9c07-f76940710069')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e589b6dd-dbdc-40a4-9c07-f76940710069 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e589b6dd-dbdc-40a4-9c07-f76940710069');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dataCleaning(dataCollection):\n",
        "    dataCollection = dataCollection.drop(['timestamp', 'handOrientation1', 'handOrientation2', 'handOrientation3', 'handOrientation4',\n",
        "                                         'chestOrientation1', 'chestOrientation2', 'chestOrientation3', 'chestOrientation4',\n",
        "                                         'ankleOrientation1', 'ankleOrientation2', 'ankleOrientation3', 'ankleOrientation4'],\n",
        "                                         axis = 1)  # removal of orientation columns as they are not needed\n",
        "    dataCollection = dataCollection.drop(dataCollection[dataCollection.activityID == 0].index) # removal of any row of activity 0 as it is transient activity which it is not used\n",
        "    dataCollection = dataCollection.apply(pd.to_numeric, errors = 'coerce') # removal of non numeric data in cells\n",
        "    dataCollection = dataCollection.drop(['heartrate'], axis = 1)\n",
        "    dataCollection = dataCollection.dropna()\n",
        "\n",
        "    dataCollection = dataCollection.drop(['handTemperature', 'chestTemperature', 'ankleTemperature'],\n",
        "                                         axis = 1)  # removal of temperature columns as they are not needed - sumeyye\n",
        "    print(\"data cleaned!\")\n",
        "    return dataCollection\n",
        "\n",
        "cleaned_data = dataCleaning(data)\n",
        "print(cleaned_data['activityID'].value_counts())\n",
        "cleaned_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "IGCabJ_FAnEJ",
        "outputId": "1b155dd4-c2e6-4e22-ae7d-70a75afa3f8a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data cleaned!\n",
            "17    237902\n",
            "4     229709\n",
            "1     192290\n",
            "3     188984\n",
            "2     184645\n",
            "7     184444\n",
            "16    174976\n",
            "6     163302\n",
            "12    117094\n",
            "13    104865\n",
            "5      95641\n",
            "24     47579\n",
            "Name: activityID, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      activityID  handAcc16_1  handAcc16_2  handAcc16_3  handAcc6_1  \\\n",
              "2928           1      2.21530      8.27915      5.58753     2.24689   \n",
              "2929           1      2.29196      7.67288      5.74467     2.27373   \n",
              "2930           1      2.29090      7.14240      5.82342     2.26966   \n",
              "2931           1      2.21800      7.14365      5.89930     2.22177   \n",
              "2932           1      2.30106      7.25857      6.09259     2.20720   \n",
              "\n",
              "      handAcc6_2  handAcc6_3  handGyro1  handGyro2  handGyro3  ...  \\\n",
              "2928     8.55387     5.77143  -0.004750   0.037579  -0.011145  ...   \n",
              "2929     8.14592     5.78739  -0.171710   0.025479  -0.009538  ...   \n",
              "2930     7.66268     5.78846  -0.238241   0.011214   0.000831  ...   \n",
              "2931     7.25535     5.88000  -0.192912   0.019053   0.013374  ...   \n",
              "2932     7.24042     5.95555  -0.069961  -0.018328   0.004582  ...   \n",
              "\n",
              "      ankleAcc16_3  ankleAcc6_1  ankleAcc6_2  ankleAcc6_3  ankleGyro1  \\\n",
              "2928      0.095156      9.63162     -1.76757     0.265761    0.002908   \n",
              "2929     -0.020804      9.58649     -1.75247     0.250816    0.020882   \n",
              "2930     -0.059173      9.60196     -1.73721     0.356632   -0.035392   \n",
              "2931      0.094385      9.58674     -1.78264     0.311453   -0.032514   \n",
              "2932      0.095775      9.64677     -1.75240     0.295902    0.001351   \n",
              "\n",
              "      ankleGyro2  ankleGyro3  ankleMagne1  ankleMagne2  ankleMagne3  \n",
              "2928   -0.027714    0.001752     -61.1081     -36.8636     -58.3696  \n",
              "2929    0.000945    0.006007     -60.8916     -36.3197     -58.3656  \n",
              "2930   -0.052422   -0.004882     -60.3407     -35.7842     -58.6119  \n",
              "2931   -0.018844    0.026950     -60.7646     -37.1028     -57.8799  \n",
              "2932   -0.048878   -0.006328     -60.2040     -37.1225     -57.8847  \n",
              "\n",
              "[5 rows x 37 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51d26eb8-c1c2-4d1b-a21f-b24dff65a7ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>activityID</th>\n",
              "      <th>handAcc16_1</th>\n",
              "      <th>handAcc16_2</th>\n",
              "      <th>handAcc16_3</th>\n",
              "      <th>handAcc6_1</th>\n",
              "      <th>handAcc6_2</th>\n",
              "      <th>handAcc6_3</th>\n",
              "      <th>handGyro1</th>\n",
              "      <th>handGyro2</th>\n",
              "      <th>handGyro3</th>\n",
              "      <th>...</th>\n",
              "      <th>ankleAcc16_3</th>\n",
              "      <th>ankleAcc6_1</th>\n",
              "      <th>ankleAcc6_2</th>\n",
              "      <th>ankleAcc6_3</th>\n",
              "      <th>ankleGyro1</th>\n",
              "      <th>ankleGyro2</th>\n",
              "      <th>ankleGyro3</th>\n",
              "      <th>ankleMagne1</th>\n",
              "      <th>ankleMagne2</th>\n",
              "      <th>ankleMagne3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2928</th>\n",
              "      <td>1</td>\n",
              "      <td>2.21530</td>\n",
              "      <td>8.27915</td>\n",
              "      <td>5.58753</td>\n",
              "      <td>2.24689</td>\n",
              "      <td>8.55387</td>\n",
              "      <td>5.77143</td>\n",
              "      <td>-0.004750</td>\n",
              "      <td>0.037579</td>\n",
              "      <td>-0.011145</td>\n",
              "      <td>...</td>\n",
              "      <td>0.095156</td>\n",
              "      <td>9.63162</td>\n",
              "      <td>-1.76757</td>\n",
              "      <td>0.265761</td>\n",
              "      <td>0.002908</td>\n",
              "      <td>-0.027714</td>\n",
              "      <td>0.001752</td>\n",
              "      <td>-61.1081</td>\n",
              "      <td>-36.8636</td>\n",
              "      <td>-58.3696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2929</th>\n",
              "      <td>1</td>\n",
              "      <td>2.29196</td>\n",
              "      <td>7.67288</td>\n",
              "      <td>5.74467</td>\n",
              "      <td>2.27373</td>\n",
              "      <td>8.14592</td>\n",
              "      <td>5.78739</td>\n",
              "      <td>-0.171710</td>\n",
              "      <td>0.025479</td>\n",
              "      <td>-0.009538</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.020804</td>\n",
              "      <td>9.58649</td>\n",
              "      <td>-1.75247</td>\n",
              "      <td>0.250816</td>\n",
              "      <td>0.020882</td>\n",
              "      <td>0.000945</td>\n",
              "      <td>0.006007</td>\n",
              "      <td>-60.8916</td>\n",
              "      <td>-36.3197</td>\n",
              "      <td>-58.3656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2930</th>\n",
              "      <td>1</td>\n",
              "      <td>2.29090</td>\n",
              "      <td>7.14240</td>\n",
              "      <td>5.82342</td>\n",
              "      <td>2.26966</td>\n",
              "      <td>7.66268</td>\n",
              "      <td>5.78846</td>\n",
              "      <td>-0.238241</td>\n",
              "      <td>0.011214</td>\n",
              "      <td>0.000831</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.059173</td>\n",
              "      <td>9.60196</td>\n",
              "      <td>-1.73721</td>\n",
              "      <td>0.356632</td>\n",
              "      <td>-0.035392</td>\n",
              "      <td>-0.052422</td>\n",
              "      <td>-0.004882</td>\n",
              "      <td>-60.3407</td>\n",
              "      <td>-35.7842</td>\n",
              "      <td>-58.6119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2931</th>\n",
              "      <td>1</td>\n",
              "      <td>2.21800</td>\n",
              "      <td>7.14365</td>\n",
              "      <td>5.89930</td>\n",
              "      <td>2.22177</td>\n",
              "      <td>7.25535</td>\n",
              "      <td>5.88000</td>\n",
              "      <td>-0.192912</td>\n",
              "      <td>0.019053</td>\n",
              "      <td>0.013374</td>\n",
              "      <td>...</td>\n",
              "      <td>0.094385</td>\n",
              "      <td>9.58674</td>\n",
              "      <td>-1.78264</td>\n",
              "      <td>0.311453</td>\n",
              "      <td>-0.032514</td>\n",
              "      <td>-0.018844</td>\n",
              "      <td>0.026950</td>\n",
              "      <td>-60.7646</td>\n",
              "      <td>-37.1028</td>\n",
              "      <td>-57.8799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2932</th>\n",
              "      <td>1</td>\n",
              "      <td>2.30106</td>\n",
              "      <td>7.25857</td>\n",
              "      <td>6.09259</td>\n",
              "      <td>2.20720</td>\n",
              "      <td>7.24042</td>\n",
              "      <td>5.95555</td>\n",
              "      <td>-0.069961</td>\n",
              "      <td>-0.018328</td>\n",
              "      <td>0.004582</td>\n",
              "      <td>...</td>\n",
              "      <td>0.095775</td>\n",
              "      <td>9.64677</td>\n",
              "      <td>-1.75240</td>\n",
              "      <td>0.295902</td>\n",
              "      <td>0.001351</td>\n",
              "      <td>-0.048878</td>\n",
              "      <td>-0.006328</td>\n",
              "      <td>-60.2040</td>\n",
              "      <td>-37.1225</td>\n",
              "      <td>-57.8847</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 37 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51d26eb8-c1c2-4d1b-a21f-b24dff65a7ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-51d26eb8-c1c2-4d1b-a21f-b24dff65a7ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-51d26eb8-c1c2-4d1b-a21f-b24dff65a7ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reset_label(dataCollection): \n",
        "    # Convert original labels {1, 2, 3, 4, 5, 6, 7, 12, 13, 16, 17, 24} to new labels. \n",
        "    mapping = {24:0,1:1,2:2,3:3,4:4,5:5,6:6,7:7,12:8,13:9,16:10,17:11} # old activity Id to new activity Id \n",
        "    for i in [24,12,13,16,17]:\n",
        "        dataCollection.loc[dataCollection.activityID == i, 'activityID'] = mapping[i]\n",
        "\n",
        "    return dataCollection\n",
        "data_reset = reset_label(cleaned_data)  \n",
        "data_reset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "g1XksDiFApxb",
        "outputId": "11916ecb-58b1-4510-e732-3336a0064b55"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      activityID  handAcc16_1  handAcc16_2  handAcc16_3  handAcc6_1  \\\n",
              "2928           1      2.21530      8.27915      5.58753     2.24689   \n",
              "2929           1      2.29196      7.67288      5.74467     2.27373   \n",
              "2930           1      2.29090      7.14240      5.82342     2.26966   \n",
              "2931           1      2.21800      7.14365      5.89930     2.22177   \n",
              "2932           1      2.30106      7.25857      6.09259     2.20720   \n",
              "\n",
              "      handAcc6_2  handAcc6_3  handGyro1  handGyro2  handGyro3  ...  \\\n",
              "2928     8.55387     5.77143  -0.004750   0.037579  -0.011145  ...   \n",
              "2929     8.14592     5.78739  -0.171710   0.025479  -0.009538  ...   \n",
              "2930     7.66268     5.78846  -0.238241   0.011214   0.000831  ...   \n",
              "2931     7.25535     5.88000  -0.192912   0.019053   0.013374  ...   \n",
              "2932     7.24042     5.95555  -0.069961  -0.018328   0.004582  ...   \n",
              "\n",
              "      ankleAcc16_3  ankleAcc6_1  ankleAcc6_2  ankleAcc6_3  ankleGyro1  \\\n",
              "2928      0.095156      9.63162     -1.76757     0.265761    0.002908   \n",
              "2929     -0.020804      9.58649     -1.75247     0.250816    0.020882   \n",
              "2930     -0.059173      9.60196     -1.73721     0.356632   -0.035392   \n",
              "2931      0.094385      9.58674     -1.78264     0.311453   -0.032514   \n",
              "2932      0.095775      9.64677     -1.75240     0.295902    0.001351   \n",
              "\n",
              "      ankleGyro2  ankleGyro3  ankleMagne1  ankleMagne2  ankleMagne3  \n",
              "2928   -0.027714    0.001752     -61.1081     -36.8636     -58.3696  \n",
              "2929    0.000945    0.006007     -60.8916     -36.3197     -58.3656  \n",
              "2930   -0.052422   -0.004882     -60.3407     -35.7842     -58.6119  \n",
              "2931   -0.018844    0.026950     -60.7646     -37.1028     -57.8799  \n",
              "2932   -0.048878   -0.006328     -60.2040     -37.1225     -57.8847  \n",
              "\n",
              "[5 rows x 37 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f926dd5-29c6-4acb-9ae6-7acf739f8bff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>activityID</th>\n",
              "      <th>handAcc16_1</th>\n",
              "      <th>handAcc16_2</th>\n",
              "      <th>handAcc16_3</th>\n",
              "      <th>handAcc6_1</th>\n",
              "      <th>handAcc6_2</th>\n",
              "      <th>handAcc6_3</th>\n",
              "      <th>handGyro1</th>\n",
              "      <th>handGyro2</th>\n",
              "      <th>handGyro3</th>\n",
              "      <th>...</th>\n",
              "      <th>ankleAcc16_3</th>\n",
              "      <th>ankleAcc6_1</th>\n",
              "      <th>ankleAcc6_2</th>\n",
              "      <th>ankleAcc6_3</th>\n",
              "      <th>ankleGyro1</th>\n",
              "      <th>ankleGyro2</th>\n",
              "      <th>ankleGyro3</th>\n",
              "      <th>ankleMagne1</th>\n",
              "      <th>ankleMagne2</th>\n",
              "      <th>ankleMagne3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2928</th>\n",
              "      <td>1</td>\n",
              "      <td>2.21530</td>\n",
              "      <td>8.27915</td>\n",
              "      <td>5.58753</td>\n",
              "      <td>2.24689</td>\n",
              "      <td>8.55387</td>\n",
              "      <td>5.77143</td>\n",
              "      <td>-0.004750</td>\n",
              "      <td>0.037579</td>\n",
              "      <td>-0.011145</td>\n",
              "      <td>...</td>\n",
              "      <td>0.095156</td>\n",
              "      <td>9.63162</td>\n",
              "      <td>-1.76757</td>\n",
              "      <td>0.265761</td>\n",
              "      <td>0.002908</td>\n",
              "      <td>-0.027714</td>\n",
              "      <td>0.001752</td>\n",
              "      <td>-61.1081</td>\n",
              "      <td>-36.8636</td>\n",
              "      <td>-58.3696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2929</th>\n",
              "      <td>1</td>\n",
              "      <td>2.29196</td>\n",
              "      <td>7.67288</td>\n",
              "      <td>5.74467</td>\n",
              "      <td>2.27373</td>\n",
              "      <td>8.14592</td>\n",
              "      <td>5.78739</td>\n",
              "      <td>-0.171710</td>\n",
              "      <td>0.025479</td>\n",
              "      <td>-0.009538</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.020804</td>\n",
              "      <td>9.58649</td>\n",
              "      <td>-1.75247</td>\n",
              "      <td>0.250816</td>\n",
              "      <td>0.020882</td>\n",
              "      <td>0.000945</td>\n",
              "      <td>0.006007</td>\n",
              "      <td>-60.8916</td>\n",
              "      <td>-36.3197</td>\n",
              "      <td>-58.3656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2930</th>\n",
              "      <td>1</td>\n",
              "      <td>2.29090</td>\n",
              "      <td>7.14240</td>\n",
              "      <td>5.82342</td>\n",
              "      <td>2.26966</td>\n",
              "      <td>7.66268</td>\n",
              "      <td>5.78846</td>\n",
              "      <td>-0.238241</td>\n",
              "      <td>0.011214</td>\n",
              "      <td>0.000831</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.059173</td>\n",
              "      <td>9.60196</td>\n",
              "      <td>-1.73721</td>\n",
              "      <td>0.356632</td>\n",
              "      <td>-0.035392</td>\n",
              "      <td>-0.052422</td>\n",
              "      <td>-0.004882</td>\n",
              "      <td>-60.3407</td>\n",
              "      <td>-35.7842</td>\n",
              "      <td>-58.6119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2931</th>\n",
              "      <td>1</td>\n",
              "      <td>2.21800</td>\n",
              "      <td>7.14365</td>\n",
              "      <td>5.89930</td>\n",
              "      <td>2.22177</td>\n",
              "      <td>7.25535</td>\n",
              "      <td>5.88000</td>\n",
              "      <td>-0.192912</td>\n",
              "      <td>0.019053</td>\n",
              "      <td>0.013374</td>\n",
              "      <td>...</td>\n",
              "      <td>0.094385</td>\n",
              "      <td>9.58674</td>\n",
              "      <td>-1.78264</td>\n",
              "      <td>0.311453</td>\n",
              "      <td>-0.032514</td>\n",
              "      <td>-0.018844</td>\n",
              "      <td>0.026950</td>\n",
              "      <td>-60.7646</td>\n",
              "      <td>-37.1028</td>\n",
              "      <td>-57.8799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2932</th>\n",
              "      <td>1</td>\n",
              "      <td>2.30106</td>\n",
              "      <td>7.25857</td>\n",
              "      <td>6.09259</td>\n",
              "      <td>2.20720</td>\n",
              "      <td>7.24042</td>\n",
              "      <td>5.95555</td>\n",
              "      <td>-0.069961</td>\n",
              "      <td>-0.018328</td>\n",
              "      <td>0.004582</td>\n",
              "      <td>...</td>\n",
              "      <td>0.095775</td>\n",
              "      <td>9.64677</td>\n",
              "      <td>-1.75240</td>\n",
              "      <td>0.295902</td>\n",
              "      <td>0.001351</td>\n",
              "      <td>-0.048878</td>\n",
              "      <td>-0.006328</td>\n",
              "      <td>-60.2040</td>\n",
              "      <td>-37.1225</td>\n",
              "      <td>-57.8847</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 37 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f926dd5-29c6-4acb-9ae6-7acf739f8bff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f926dd5-29c6-4acb-9ae6-7acf739f8bff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f926dd5-29c6-4acb-9ae6-7acf739f8bff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=data_reset.drop(['activityID'],axis=1)\n",
        "y=data_reset['activityID']\n",
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "2LRpqMLWtvX6",
        "outputId": "ce6ffb98-0b12-45db-ec5c-4c0638025ead"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      handAcc16_1  handAcc16_2  handAcc16_3  handAcc6_1  handAcc6_2  \\\n",
              "2928      2.21530      8.27915      5.58753     2.24689     8.55387   \n",
              "2929      2.29196      7.67288      5.74467     2.27373     8.14592   \n",
              "2930      2.29090      7.14240      5.82342     2.26966     7.66268   \n",
              "2931      2.21800      7.14365      5.89930     2.22177     7.25535   \n",
              "2932      2.30106      7.25857      6.09259     2.20720     7.24042   \n",
              "\n",
              "      handAcc6_3  handGyro1  handGyro2  handGyro3  handMagne1  ...  \\\n",
              "2928     5.77143  -0.004750   0.037579  -0.011145     8.93200  ...   \n",
              "2929     5.78739  -0.171710   0.025479  -0.009538     9.58300  ...   \n",
              "2930     5.78846  -0.238241   0.011214   0.000831     9.05516  ...   \n",
              "2931     5.88000  -0.192912   0.019053   0.013374     9.92698  ...   \n",
              "2932     5.95555  -0.069961  -0.018328   0.004582     9.15626  ...   \n",
              "\n",
              "      ankleAcc16_3  ankleAcc6_1  ankleAcc6_2  ankleAcc6_3  ankleGyro1  \\\n",
              "2928      0.095156      9.63162     -1.76757     0.265761    0.002908   \n",
              "2929     -0.020804      9.58649     -1.75247     0.250816    0.020882   \n",
              "2930     -0.059173      9.60196     -1.73721     0.356632   -0.035392   \n",
              "2931      0.094385      9.58674     -1.78264     0.311453   -0.032514   \n",
              "2932      0.095775      9.64677     -1.75240     0.295902    0.001351   \n",
              "\n",
              "      ankleGyro2  ankleGyro3  ankleMagne1  ankleMagne2  ankleMagne3  \n",
              "2928   -0.027714    0.001752     -61.1081     -36.8636     -58.3696  \n",
              "2929    0.000945    0.006007     -60.8916     -36.3197     -58.3656  \n",
              "2930   -0.052422   -0.004882     -60.3407     -35.7842     -58.6119  \n",
              "2931   -0.018844    0.026950     -60.7646     -37.1028     -57.8799  \n",
              "2932   -0.048878   -0.006328     -60.2040     -37.1225     -57.8847  \n",
              "\n",
              "[5 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01e90ba6-939c-498a-951f-304a5a1da7bd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>handAcc16_1</th>\n",
              "      <th>handAcc16_2</th>\n",
              "      <th>handAcc16_3</th>\n",
              "      <th>handAcc6_1</th>\n",
              "      <th>handAcc6_2</th>\n",
              "      <th>handAcc6_3</th>\n",
              "      <th>handGyro1</th>\n",
              "      <th>handGyro2</th>\n",
              "      <th>handGyro3</th>\n",
              "      <th>handMagne1</th>\n",
              "      <th>...</th>\n",
              "      <th>ankleAcc16_3</th>\n",
              "      <th>ankleAcc6_1</th>\n",
              "      <th>ankleAcc6_2</th>\n",
              "      <th>ankleAcc6_3</th>\n",
              "      <th>ankleGyro1</th>\n",
              "      <th>ankleGyro2</th>\n",
              "      <th>ankleGyro3</th>\n",
              "      <th>ankleMagne1</th>\n",
              "      <th>ankleMagne2</th>\n",
              "      <th>ankleMagne3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2928</th>\n",
              "      <td>2.21530</td>\n",
              "      <td>8.27915</td>\n",
              "      <td>5.58753</td>\n",
              "      <td>2.24689</td>\n",
              "      <td>8.55387</td>\n",
              "      <td>5.77143</td>\n",
              "      <td>-0.004750</td>\n",
              "      <td>0.037579</td>\n",
              "      <td>-0.011145</td>\n",
              "      <td>8.93200</td>\n",
              "      <td>...</td>\n",
              "      <td>0.095156</td>\n",
              "      <td>9.63162</td>\n",
              "      <td>-1.76757</td>\n",
              "      <td>0.265761</td>\n",
              "      <td>0.002908</td>\n",
              "      <td>-0.027714</td>\n",
              "      <td>0.001752</td>\n",
              "      <td>-61.1081</td>\n",
              "      <td>-36.8636</td>\n",
              "      <td>-58.3696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2929</th>\n",
              "      <td>2.29196</td>\n",
              "      <td>7.67288</td>\n",
              "      <td>5.74467</td>\n",
              "      <td>2.27373</td>\n",
              "      <td>8.14592</td>\n",
              "      <td>5.78739</td>\n",
              "      <td>-0.171710</td>\n",
              "      <td>0.025479</td>\n",
              "      <td>-0.009538</td>\n",
              "      <td>9.58300</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.020804</td>\n",
              "      <td>9.58649</td>\n",
              "      <td>-1.75247</td>\n",
              "      <td>0.250816</td>\n",
              "      <td>0.020882</td>\n",
              "      <td>0.000945</td>\n",
              "      <td>0.006007</td>\n",
              "      <td>-60.8916</td>\n",
              "      <td>-36.3197</td>\n",
              "      <td>-58.3656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2930</th>\n",
              "      <td>2.29090</td>\n",
              "      <td>7.14240</td>\n",
              "      <td>5.82342</td>\n",
              "      <td>2.26966</td>\n",
              "      <td>7.66268</td>\n",
              "      <td>5.78846</td>\n",
              "      <td>-0.238241</td>\n",
              "      <td>0.011214</td>\n",
              "      <td>0.000831</td>\n",
              "      <td>9.05516</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.059173</td>\n",
              "      <td>9.60196</td>\n",
              "      <td>-1.73721</td>\n",
              "      <td>0.356632</td>\n",
              "      <td>-0.035392</td>\n",
              "      <td>-0.052422</td>\n",
              "      <td>-0.004882</td>\n",
              "      <td>-60.3407</td>\n",
              "      <td>-35.7842</td>\n",
              "      <td>-58.6119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2931</th>\n",
              "      <td>2.21800</td>\n",
              "      <td>7.14365</td>\n",
              "      <td>5.89930</td>\n",
              "      <td>2.22177</td>\n",
              "      <td>7.25535</td>\n",
              "      <td>5.88000</td>\n",
              "      <td>-0.192912</td>\n",
              "      <td>0.019053</td>\n",
              "      <td>0.013374</td>\n",
              "      <td>9.92698</td>\n",
              "      <td>...</td>\n",
              "      <td>0.094385</td>\n",
              "      <td>9.58674</td>\n",
              "      <td>-1.78264</td>\n",
              "      <td>0.311453</td>\n",
              "      <td>-0.032514</td>\n",
              "      <td>-0.018844</td>\n",
              "      <td>0.026950</td>\n",
              "      <td>-60.7646</td>\n",
              "      <td>-37.1028</td>\n",
              "      <td>-57.8799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2932</th>\n",
              "      <td>2.30106</td>\n",
              "      <td>7.25857</td>\n",
              "      <td>6.09259</td>\n",
              "      <td>2.20720</td>\n",
              "      <td>7.24042</td>\n",
              "      <td>5.95555</td>\n",
              "      <td>-0.069961</td>\n",
              "      <td>-0.018328</td>\n",
              "      <td>0.004582</td>\n",
              "      <td>9.15626</td>\n",
              "      <td>...</td>\n",
              "      <td>0.095775</td>\n",
              "      <td>9.64677</td>\n",
              "      <td>-1.75240</td>\n",
              "      <td>0.295902</td>\n",
              "      <td>0.001351</td>\n",
              "      <td>-0.048878</td>\n",
              "      <td>-0.006328</td>\n",
              "      <td>-60.2040</td>\n",
              "      <td>-37.1225</td>\n",
              "      <td>-57.8847</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 36 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01e90ba6-939c-498a-951f-304a5a1da7bd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-01e90ba6-939c-498a-951f-304a5a1da7bd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-01e90ba6-939c-498a-951f-304a5a1da7bd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scale(df): # minmax scale\n",
        "    features=df.columns[0:X.shape[1]]\n",
        "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "    df[features]=scaler.fit_transform(df[features])\n",
        "    return df\n",
        "\n",
        "X_scaled = scale(X)\n",
        "X_scaled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "fshxU5tnAuRu",
        "outputId": "e45e06bb-8bc6-40c7-a91f-65ca8ed219f5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      handAcc16_1  handAcc16_2  handAcc16_3  handAcc6_1  handAcc6_2  \\\n",
              "2928     0.417516    -0.133999    -0.174116    0.113009    0.134484   \n",
              "2929     0.418253    -0.138662    -0.172903    0.113480    0.127909   \n",
              "2930     0.418242    -0.142743    -0.172296    0.113408    0.120122   \n",
              "2931     0.417542    -0.142733    -0.171710    0.112568    0.113557   \n",
              "2932     0.418340    -0.141849    -0.170219    0.112313    0.113316   \n",
              "\n",
              "      handAcc6_3  handGyro1  handGyro2  handGyro3  handMagne1  ...  \\\n",
              "2928    0.093285   0.031349  -0.125912  -0.003356   -0.065176  ...   \n",
              "2929    0.093543   0.025227  -0.126503  -0.003244   -0.059784  ...   \n",
              "2930    0.093560   0.022788  -0.127200  -0.002519   -0.064156  ...   \n",
              "2931    0.095039   0.024450  -0.126817  -0.001641   -0.056935  ...   \n",
              "2932    0.096259   0.028958  -0.128644  -0.002256   -0.063319  ...   \n",
              "\n",
              "      ankleAcc16_3  ankleAcc6_1  ankleAcc6_2  ankleAcc6_3  ankleGyro1  \\\n",
              "2928      0.000769     0.143942    -0.029670     0.015502    0.186908   \n",
              "2929      0.000039     0.143204    -0.029426     0.015259    0.187797   \n",
              "2930     -0.000202     0.143457    -0.029180     0.016977    0.185013   \n",
              "2931      0.000764     0.143208    -0.029913     0.016243    0.185156   \n",
              "2932      0.000773     0.144190    -0.029425     0.015991    0.186831   \n",
              "\n",
              "      ankleGyro2  ankleGyro3  ankleMagne1  ankleMagne2  ankleMagne3  \n",
              "2928    0.141361   -0.082024    -0.154691    -0.129512    -0.644683  \n",
              "2929    0.143168   -0.081745    -0.153053    -0.124827    -0.644651  \n",
              "2930    0.139803   -0.082458    -0.148886    -0.120213    -0.646624  \n",
              "2931    0.141920   -0.080374    -0.152093    -0.131573    -0.640759  \n",
              "2932    0.140026   -0.082553    -0.147852    -0.131743    -0.640798  \n",
              "\n",
              "[5 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-597563bb-91fd-405c-aeac-d902bca63e04\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>handAcc16_1</th>\n",
              "      <th>handAcc16_2</th>\n",
              "      <th>handAcc16_3</th>\n",
              "      <th>handAcc6_1</th>\n",
              "      <th>handAcc6_2</th>\n",
              "      <th>handAcc6_3</th>\n",
              "      <th>handGyro1</th>\n",
              "      <th>handGyro2</th>\n",
              "      <th>handGyro3</th>\n",
              "      <th>handMagne1</th>\n",
              "      <th>...</th>\n",
              "      <th>ankleAcc16_3</th>\n",
              "      <th>ankleAcc6_1</th>\n",
              "      <th>ankleAcc6_2</th>\n",
              "      <th>ankleAcc6_3</th>\n",
              "      <th>ankleGyro1</th>\n",
              "      <th>ankleGyro2</th>\n",
              "      <th>ankleGyro3</th>\n",
              "      <th>ankleMagne1</th>\n",
              "      <th>ankleMagne2</th>\n",
              "      <th>ankleMagne3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2928</th>\n",
              "      <td>0.417516</td>\n",
              "      <td>-0.133999</td>\n",
              "      <td>-0.174116</td>\n",
              "      <td>0.113009</td>\n",
              "      <td>0.134484</td>\n",
              "      <td>0.093285</td>\n",
              "      <td>0.031349</td>\n",
              "      <td>-0.125912</td>\n",
              "      <td>-0.003356</td>\n",
              "      <td>-0.065176</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000769</td>\n",
              "      <td>0.143942</td>\n",
              "      <td>-0.029670</td>\n",
              "      <td>0.015502</td>\n",
              "      <td>0.186908</td>\n",
              "      <td>0.141361</td>\n",
              "      <td>-0.082024</td>\n",
              "      <td>-0.154691</td>\n",
              "      <td>-0.129512</td>\n",
              "      <td>-0.644683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2929</th>\n",
              "      <td>0.418253</td>\n",
              "      <td>-0.138662</td>\n",
              "      <td>-0.172903</td>\n",
              "      <td>0.113480</td>\n",
              "      <td>0.127909</td>\n",
              "      <td>0.093543</td>\n",
              "      <td>0.025227</td>\n",
              "      <td>-0.126503</td>\n",
              "      <td>-0.003244</td>\n",
              "      <td>-0.059784</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>0.143204</td>\n",
              "      <td>-0.029426</td>\n",
              "      <td>0.015259</td>\n",
              "      <td>0.187797</td>\n",
              "      <td>0.143168</td>\n",
              "      <td>-0.081745</td>\n",
              "      <td>-0.153053</td>\n",
              "      <td>-0.124827</td>\n",
              "      <td>-0.644651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2930</th>\n",
              "      <td>0.418242</td>\n",
              "      <td>-0.142743</td>\n",
              "      <td>-0.172296</td>\n",
              "      <td>0.113408</td>\n",
              "      <td>0.120122</td>\n",
              "      <td>0.093560</td>\n",
              "      <td>0.022788</td>\n",
              "      <td>-0.127200</td>\n",
              "      <td>-0.002519</td>\n",
              "      <td>-0.064156</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000202</td>\n",
              "      <td>0.143457</td>\n",
              "      <td>-0.029180</td>\n",
              "      <td>0.016977</td>\n",
              "      <td>0.185013</td>\n",
              "      <td>0.139803</td>\n",
              "      <td>-0.082458</td>\n",
              "      <td>-0.148886</td>\n",
              "      <td>-0.120213</td>\n",
              "      <td>-0.646624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2931</th>\n",
              "      <td>0.417542</td>\n",
              "      <td>-0.142733</td>\n",
              "      <td>-0.171710</td>\n",
              "      <td>0.112568</td>\n",
              "      <td>0.113557</td>\n",
              "      <td>0.095039</td>\n",
              "      <td>0.024450</td>\n",
              "      <td>-0.126817</td>\n",
              "      <td>-0.001641</td>\n",
              "      <td>-0.056935</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000764</td>\n",
              "      <td>0.143208</td>\n",
              "      <td>-0.029913</td>\n",
              "      <td>0.016243</td>\n",
              "      <td>0.185156</td>\n",
              "      <td>0.141920</td>\n",
              "      <td>-0.080374</td>\n",
              "      <td>-0.152093</td>\n",
              "      <td>-0.131573</td>\n",
              "      <td>-0.640759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2932</th>\n",
              "      <td>0.418340</td>\n",
              "      <td>-0.141849</td>\n",
              "      <td>-0.170219</td>\n",
              "      <td>0.112313</td>\n",
              "      <td>0.113316</td>\n",
              "      <td>0.096259</td>\n",
              "      <td>0.028958</td>\n",
              "      <td>-0.128644</td>\n",
              "      <td>-0.002256</td>\n",
              "      <td>-0.063319</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000773</td>\n",
              "      <td>0.144190</td>\n",
              "      <td>-0.029425</td>\n",
              "      <td>0.015991</td>\n",
              "      <td>0.186831</td>\n",
              "      <td>0.140026</td>\n",
              "      <td>-0.082553</td>\n",
              "      <td>-0.147852</td>\n",
              "      <td>-0.131743</td>\n",
              "      <td>-0.640798</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 36 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-597563bb-91fd-405c-aeac-d902bca63e04')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-597563bb-91fd-405c-aeac-d902bca63e04 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-597563bb-91fd-405c-aeac-d902bca63e04');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INITIAL_SAMPLING_RATE = 100 #Hz\n",
        "WINDOW_SIZE = 1 #second\n",
        "\n",
        "SLIDING_WINDOW_LENGTH = INITIAL_SAMPLING_RATE*WINDOW_SIZE\n",
        "\n",
        "def segment_signal(data_x, data_y, window_size): # data is numpy array\n",
        "    X, y = [], []\n",
        "    start, end = 0, 0\n",
        "    while start + window_size - 1 < data_x.shape[0]:\n",
        "        end = start + window_size - 1\n",
        "        # if the frame contains the same activity and from the same object\n",
        "        X.append(data_x[start:(end+1),:])\n",
        "        y.append(data_y[start])\n",
        "        start += window_size #without overlap (for 50% overlap use window_size//2)\n",
        "    return [np.asarray(X), np.asarray(y)]\n",
        "\n",
        "data = segment_signal(X_scaled.to_numpy(), y.to_numpy(), SLIDING_WINDOW_LENGTH)\n",
        "data_x, data_y = data[0], data[1]\n",
        "print(data_x.shape)\n",
        "print(data_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b0PmyPbdiOA",
        "outputId": "60419736-a05b-4e37-f56d-552346995786"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19214, 100, 36)\n",
            "(19214,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data is reshaped since the input of the network is a 4 dimension tensor\n",
        "data_x = data_x.reshape((-1, data_x.shape[1], data_x.shape[2], 1))\n",
        "print(data_x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUm7q-D7f_vX",
        "outputId": "b8173a51-c71b-461c-f6b3-c702c14c5aa6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19214, 100, 36, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/53731141/cifar10-randomize-train-and-test-set\n",
        "def shuffle_train_data(X_train, Y_train): \n",
        "    perm = np.random.permutation(len(Y_train)) \n",
        "    Xtr_shuf = X_train[perm] \n",
        "    Ytr_shuf = Y_train[perm] \n",
        "    return Xtr_shuf, Ytr_shuf \n",
        "X_shuffled, y_shuffled = shuffle_train_data(data_x, data_y) \n",
        "print(X_shuffled.shape) \n",
        "print(y_shuffled.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCmQDZA7gPGJ",
        "outputId": "c0c49183-0200-4cd2-dac3-2bb50a10bcc0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19214, 100, 36, 1)\n",
            "(19214,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://stackoverflow.com/questions/53731141/cifar10-randomize-train-and-test-set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_shuffled, y_shuffled, test_size=0.33, random_state=1234)\n",
        "print(\"X_train \" + str(X_train.shape) + \"\\ny_train \" + str(y_train.shape) + \"\\nX_test  \" + str(X_test.shape)+ \"\\ny_test  \" + str(y_test.shape)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOwmuLTKdu_4",
        "outputId": "167923eb-491d-409e-a5bb-d66c3c89e2a0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train (12873, 100, 36, 1)\n",
            "y_train (12873,)\n",
            "X_test  (6341, 100, 36, 1)\n",
            "y_test  (6341,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, LSTM, Flatten, Input, Conv2D, Permute, Reshape\n",
        "from keras import optimizers, losses, metrics, initializers\n",
        "\n",
        "from collections import Counter\n",
        "NUM_CLASSES = len(Counter(y_shuffled).keys())\n",
        "\n",
        "BATCH_SIZE = 50 \n",
        "NUM_FILTERS = 4 # Number filters convolutional layers\n",
        "FILTER_SIZE = 6 # Size filters convolutional layers\n",
        "NUM_UNITS_LSTM = 8 # Number of unit in the long short-term recurrent layers\n",
        "NB_SENSOR_CHANNELS = data_x.shape[2]\n",
        "SLIDING_WINDOW_LENGTH = data_x.shape[1]\n",
        "print (\"NUM_CLASSES: \" + str(NUM_CLASSES))"
      ],
      "metadata": {
        "id": "7iIHarpB2u13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19d94ba1-89e2-4fcc-c5b2-c08ed9c25494"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NUM_CLASSES: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model._name=\"Experiement1_CNNLSTM_without_Attention\"\n",
        "model.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS, 1)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "\n",
        "# CNN \n",
        "model.add(Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\", kernel_initializer = initializer))\n",
        "model.add(Conv2D(NUM_FILTERS*2, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model.add(Permute((2,1,3)))\n",
        "model.add(Reshape((int(model.layers[2].output_shape[1]), int(model.layers[2].output_shape[2]) * int(model.layers[2].output_shape[3]))))\n",
        "\n",
        "# LSTM \n",
        "model.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2)\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "0NVDN3J_S9Fj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23196874-b42c-4bf3-ae6c-4b144727e95c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement1_CNNLSTM_without_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 95, 36, 4)         28        \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 90, 36, 8)         200       \n",
            "                                                                 \n",
            " permute_1 (Permute)         (None, 36, 90, 8)         0         \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 36, 720)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 36, 8)             23328     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 288)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 12)                3468      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,024\n",
            "Trainable params: 27,024\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 4s 13ms/step - loss: 1.5601 - sparse_categorical_accuracy: 0.5329 - val_loss: 1.1276 - val_sparse_categorical_accuracy: 0.6831\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.9153 - sparse_categorical_accuracy: 0.7395 - val_loss: 0.8644 - val_sparse_categorical_accuracy: 0.7631\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.7316 - sparse_categorical_accuracy: 0.8037 - val_loss: 0.6963 - val_sparse_categorical_accuracy: 0.8198\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.6270 - sparse_categorical_accuracy: 0.8338 - val_loss: 0.6185 - val_sparse_categorical_accuracy: 0.8334\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.5511 - sparse_categorical_accuracy: 0.8520 - val_loss: 0.6092 - val_sparse_categorical_accuracy: 0.8326\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.5006 - sparse_categorical_accuracy: 0.8678 - val_loss: 0.5199 - val_sparse_categorical_accuracy: 0.8625\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.4569 - sparse_categorical_accuracy: 0.8774 - val_loss: 0.5008 - val_sparse_categorical_accuracy: 0.8637\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.4244 - sparse_categorical_accuracy: 0.8857 - val_loss: 0.4875 - val_sparse_categorical_accuracy: 0.8781\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3984 - sparse_categorical_accuracy: 0.8924 - val_loss: 0.4394 - val_sparse_categorical_accuracy: 0.8812\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3761 - sparse_categorical_accuracy: 0.8973 - val_loss: 0.4479 - val_sparse_categorical_accuracy: 0.8816\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3606 - sparse_categorical_accuracy: 0.9038 - val_loss: 0.4089 - val_sparse_categorical_accuracy: 0.8901\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3467 - sparse_categorical_accuracy: 0.9048 - val_loss: 0.4381 - val_sparse_categorical_accuracy: 0.8816\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3331 - sparse_categorical_accuracy: 0.9082 - val_loss: 0.3943 - val_sparse_categorical_accuracy: 0.8963\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3208 - sparse_categorical_accuracy: 0.9141 - val_loss: 0.3892 - val_sparse_categorical_accuracy: 0.8944\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3098 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.3933 - val_sparse_categorical_accuracy: 0.8940\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3005 - sparse_categorical_accuracy: 0.9193 - val_loss: 0.3651 - val_sparse_categorical_accuracy: 0.9002\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2901 - sparse_categorical_accuracy: 0.9222 - val_loss: 0.3701 - val_sparse_categorical_accuracy: 0.8994\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2807 - sparse_categorical_accuracy: 0.9229 - val_loss: 0.3516 - val_sparse_categorical_accuracy: 0.9029\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2767 - sparse_categorical_accuracy: 0.9231 - val_loss: 0.3412 - val_sparse_categorical_accuracy: 0.9049\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2667 - sparse_categorical_accuracy: 0.9247 - val_loss: 0.3379 - val_sparse_categorical_accuracy: 0.9049\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2615 - sparse_categorical_accuracy: 0.9277 - val_loss: 0.3323 - val_sparse_categorical_accuracy: 0.9068\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2557 - sparse_categorical_accuracy: 0.9308 - val_loss: 0.3308 - val_sparse_categorical_accuracy: 0.9049\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2480 - sparse_categorical_accuracy: 0.9319 - val_loss: 0.3248 - val_sparse_categorical_accuracy: 0.9080\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2416 - sparse_categorical_accuracy: 0.9335 - val_loss: 0.3192 - val_sparse_categorical_accuracy: 0.9111\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2347 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.3115 - val_sparse_categorical_accuracy: 0.9126\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2273 - sparse_categorical_accuracy: 0.9373 - val_loss: 0.3025 - val_sparse_categorical_accuracy: 0.9146\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2268 - sparse_categorical_accuracy: 0.9362 - val_loss: 0.3101 - val_sparse_categorical_accuracy: 0.9134\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2218 - sparse_categorical_accuracy: 0.9372 - val_loss: 0.3049 - val_sparse_categorical_accuracy: 0.9076\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.2175 - sparse_categorical_accuracy: 0.9374 - val_loss: 0.2973 - val_sparse_categorical_accuracy: 0.9118\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.2124 - sparse_categorical_accuracy: 0.9399 - val_loss: 0.2947 - val_sparse_categorical_accuracy: 0.9142\n",
            "199/199 [==============================] - 1s 5ms/step - loss: 0.2479 - sparse_categorical_accuracy: 0.9319\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.24792474508285522, 0.9318719506263733]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/EscVM/EscVM_YT/blob/master/Notebooks/0%20-%20TF2.X%20Tutorials/tf_2_visual_attention.ipynb\n",
        "\n",
        "from keras.layers import Layer, GlobalAveragePooling2D, GlobalMaxPooling2D, Add, Activation, Multiply\n",
        "\n",
        "class ChannelAttention(Layer):\n",
        "      def __init__(self, filters, ratio):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.filters = filters\n",
        "        self.ratio = ratio\n",
        "\n",
        "        def build(self, input_shape):\n",
        "            self.shared_layer_one = Dense(self.filters//self.ratio,\n",
        "                             activation='relu', kernel_initializer='he_normal', \n",
        "                              use_bias=True, \n",
        "                              bias_initializer='zeros')\n",
        "            self.shared_layer_two = Dense(self.filters,\n",
        "                             kernel_initializer='he_normal',\n",
        "                             use_bias=True,\n",
        "                             bias_initializer='zeros')\n",
        "\n",
        "        def call(self, inputs):\n",
        "            # AvgPool\n",
        "            avg_pool = GlobalAveragePooling2D()(inputs)\n",
        "            \n",
        "\n",
        "            avg_pool = self.shared_layer_one(avg_pool)\n",
        "            avg_pool = self.shared_layer_two(avg_pool)\n",
        "\n",
        "            # MaxPool\n",
        "            max_pool = GlobalMaxPooling2D()(inputs)\n",
        "            max_pool = Reshape((1,1,filters))(max_pool)\n",
        "\n",
        "            max_pool = shared_layer_one(max_pool)\n",
        "            max_pool = shared_layer_two(max_pool)\n",
        "\n",
        "\n",
        "            attention = Add()([avg_pool,max_pool])\n",
        "            attention = Activation('sigmoid')(attention)\n",
        "            \n",
        "            return Multiply()([inputs, attention])"
      ],
      "metadata": {
        "id": "xj6u1NOhTCEN"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/EscVM/EscVM_YT/blob/master/Notebooks/0%20-%20TF2.X%20Tutorials/tf_2_visual_attention.ipynb\n",
        "\n",
        "from keras.layers import Lambda, Concatenate, multiply\n",
        "from keras import backend\n",
        "\n",
        "class SpatialAttention(Layer):\n",
        "      def __init__(self, kernel_size):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        def build(self, input_shape):\n",
        "            self.conv2d = Conv2D(filters = 1,\n",
        "                    kernel_size=self.kernel_size,\n",
        "                    strides=1,\n",
        "                    padding='same',\n",
        "                    activation='sigmoid',\n",
        "                    kernel_initializer='he_normal',\n",
        "                    use_bias=False)\n",
        "\n",
        "        def call(self, inputs):\n",
        "            \n",
        "            # AvgPool\n",
        "            avg_pool = Lambda(lambda x: backend.mean(x, axis=3, keepdims=True))(inputs)\n",
        "            \n",
        "            # MaxPool\n",
        "            max_pool = Lambda(lambda x: backend.max(x, axis=3, keepdims=True))(inputs)\n",
        "\n",
        "            attention = Concatenate(axis=3)([avg_pool, max_pool])\n",
        "\n",
        "            attention = self.conv2d(attention)\n",
        "\n",
        "\n",
        "            return Multiply([inputs, attention]) "
      ],
      "metadata": {
        "id": "flCOjQcrTDn7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/ManzhuYu/Code-SpatioTemporalAttention-LSTM-main/blob/main/modelbase.py # temporal module and spatial module"
      ],
      "metadata": {
        "id": "tg_HoHN9jvZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = keras.Sequential()\n",
        "model_2._name=\"Experiement2_CNNLSTM_with_spatial_Attention\"\n",
        "model_2.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS, 1)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "\n",
        "# CNN \n",
        "model_2.add(Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\", kernel_initializer = initializer))\n",
        "SpatialAttention(3),\n",
        "model_2.add(Conv2D(NUM_FILTERS*2, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model_2.add(Permute((2,1,3)))\n",
        "model_2.add(Reshape((int(model_2.layers[2].output_shape[1]), int(model_2.layers[2].output_shape[2]) * int(model_2.layers[2].output_shape[3]))))\n",
        "\n",
        "# LSTM \n",
        "model_2.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_2.add(Flatten())\n",
        "\n",
        "model_2.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_2.summary()\n",
        "\n",
        "model_2.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_2.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2)\n",
        "model_2.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLmzEfqckhXD",
        "outputId": "61f3761c-7095-4763-fe19-d11062797ec6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement2_CNNLSTM_with_spatial_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 95, 36, 4)         28        \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 90, 36, 8)         200       \n",
            "                                                                 \n",
            " permute_2 (Permute)         (None, 36, 90, 8)         0         \n",
            "                                                                 \n",
            " reshape_2 (Reshape)         (None, 36, 720)           0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 36, 8)             23328     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 288)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 12)                3468      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,024\n",
            "Trainable params: 27,024\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 7s 19ms/step - loss: 1.4658 - sparse_categorical_accuracy: 0.5577 - val_loss: 0.9869 - val_sparse_categorical_accuracy: 0.7142\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.8057 - sparse_categorical_accuracy: 0.7844 - val_loss: 0.7269 - val_sparse_categorical_accuracy: 0.8019\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.6311 - sparse_categorical_accuracy: 0.8354 - val_loss: 0.6121 - val_sparse_categorical_accuracy: 0.8346\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.5412 - sparse_categorical_accuracy: 0.8573 - val_loss: 0.5536 - val_sparse_categorical_accuracy: 0.8497\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.4796 - sparse_categorical_accuracy: 0.8725 - val_loss: 0.5135 - val_sparse_categorical_accuracy: 0.8711\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.4377 - sparse_categorical_accuracy: 0.8826 - val_loss: 0.4583 - val_sparse_categorical_accuracy: 0.8781\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.4026 - sparse_categorical_accuracy: 0.8936 - val_loss: 0.4470 - val_sparse_categorical_accuracy: 0.8827\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3766 - sparse_categorical_accuracy: 0.8984 - val_loss: 0.4226 - val_sparse_categorical_accuracy: 0.8901\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.3525 - sparse_categorical_accuracy: 0.9070 - val_loss: 0.3894 - val_sparse_categorical_accuracy: 0.8975\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3320 - sparse_categorical_accuracy: 0.9116 - val_loss: 0.3746 - val_sparse_categorical_accuracy: 0.8979\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3133 - sparse_categorical_accuracy: 0.9193 - val_loss: 0.3545 - val_sparse_categorical_accuracy: 0.9068\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3017 - sparse_categorical_accuracy: 0.9206 - val_loss: 0.3464 - val_sparse_categorical_accuracy: 0.9017\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.2884 - sparse_categorical_accuracy: 0.9234 - val_loss: 0.3366 - val_sparse_categorical_accuracy: 0.9056\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.2799 - sparse_categorical_accuracy: 0.9253 - val_loss: 0.3214 - val_sparse_categorical_accuracy: 0.9165\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2675 - sparse_categorical_accuracy: 0.9281 - val_loss: 0.3134 - val_sparse_categorical_accuracy: 0.9142\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.2609 - sparse_categorical_accuracy: 0.9311 - val_loss: 0.3144 - val_sparse_categorical_accuracy: 0.9146\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2543 - sparse_categorical_accuracy: 0.9322 - val_loss: 0.3008 - val_sparse_categorical_accuracy: 0.9192\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.2429 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.3001 - val_sparse_categorical_accuracy: 0.9223\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2393 - sparse_categorical_accuracy: 0.9344 - val_loss: 0.2885 - val_sparse_categorical_accuracy: 0.9188\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2320 - sparse_categorical_accuracy: 0.9332 - val_loss: 0.2939 - val_sparse_categorical_accuracy: 0.9165\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.2286 - sparse_categorical_accuracy: 0.9386 - val_loss: 0.2815 - val_sparse_categorical_accuracy: 0.9262\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.2212 - sparse_categorical_accuracy: 0.9387 - val_loss: 0.2813 - val_sparse_categorical_accuracy: 0.9235\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2170 - sparse_categorical_accuracy: 0.9389 - val_loss: 0.2788 - val_sparse_categorical_accuracy: 0.9227\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.2142 - sparse_categorical_accuracy: 0.9377 - val_loss: 0.2807 - val_sparse_categorical_accuracy: 0.9192\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2096 - sparse_categorical_accuracy: 0.9421 - val_loss: 0.2672 - val_sparse_categorical_accuracy: 0.9274\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2074 - sparse_categorical_accuracy: 0.9399 - val_loss: 0.2768 - val_sparse_categorical_accuracy: 0.9247\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2002 - sparse_categorical_accuracy: 0.9433 - val_loss: 0.2556 - val_sparse_categorical_accuracy: 0.9293\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1978 - sparse_categorical_accuracy: 0.9436 - val_loss: 0.2724 - val_sparse_categorical_accuracy: 0.9243\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1954 - sparse_categorical_accuracy: 0.9458 - val_loss: 0.2633 - val_sparse_categorical_accuracy: 0.9270\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1906 - sparse_categorical_accuracy: 0.9475 - val_loss: 0.2611 - val_sparse_categorical_accuracy: 0.9270\n",
            "199/199 [==============================] - 1s 4ms/step - loss: 0.2312 - sparse_categorical_accuracy: 0.9322\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.23123647272586823, 0.9321873784065247]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = keras.Sequential()\n",
        "model_3._name=\"Experiement3_CNNLSTM_with_channel_Attention\"\n",
        "model_3.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS, 1)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "\n",
        "# CNN \n",
        "model_3.add(Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\", kernel_initializer = initializer))\n",
        "ChannelAttention(8, 4),\n",
        "model_3.add(Conv2D(NUM_FILTERS*2, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model_3.add(Permute((2,1,3)))\n",
        "model_3.add(Reshape((int(model_3.layers[2].output_shape[1]), int(model_3.layers[2].output_shape[2]) * int(model_3.layers[2].output_shape[3]))))\n",
        "\n",
        "# LSTM \n",
        "model_3.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_3.add(Flatten())\n",
        "\n",
        "model_3.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_3.summary()\n",
        "\n",
        "model_3.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_3.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2)\n",
        "model_3.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtqC30ktkv9J",
        "outputId": "0dd25f2b-9a12-4174-c717-d153654dde2f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement3_CNNLSTM_with_channel_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 95, 36, 4)         28        \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 90, 36, 8)         200       \n",
            "                                                                 \n",
            " permute_3 (Permute)         (None, 36, 90, 8)         0         \n",
            "                                                                 \n",
            " reshape_3 (Reshape)         (None, 36, 720)           0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 36, 8)             23328     \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 288)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 12)                3468      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,024\n",
            "Trainable params: 27,024\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 4s 13ms/step - loss: 1.4811 - sparse_categorical_accuracy: 0.5446 - val_loss: 1.0539 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.8981 - sparse_categorical_accuracy: 0.7468 - val_loss: 0.8211 - val_sparse_categorical_accuracy: 0.7573\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.7136 - sparse_categorical_accuracy: 0.8060 - val_loss: 0.6816 - val_sparse_categorical_accuracy: 0.8260\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.5988 - sparse_categorical_accuracy: 0.8446 - val_loss: 0.5822 - val_sparse_categorical_accuracy: 0.8559\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.5146 - sparse_categorical_accuracy: 0.8671 - val_loss: 0.5433 - val_sparse_categorical_accuracy: 0.8606\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.4579 - sparse_categorical_accuracy: 0.8800 - val_loss: 0.4668 - val_sparse_categorical_accuracy: 0.8773\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.4111 - sparse_categorical_accuracy: 0.8930 - val_loss: 0.4316 - val_sparse_categorical_accuracy: 0.8924\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3802 - sparse_categorical_accuracy: 0.9027 - val_loss: 0.3982 - val_sparse_categorical_accuracy: 0.9021\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3528 - sparse_categorical_accuracy: 0.9107 - val_loss: 0.3769 - val_sparse_categorical_accuracy: 0.9002\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3300 - sparse_categorical_accuracy: 0.9164 - val_loss: 0.3529 - val_sparse_categorical_accuracy: 0.9111\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3139 - sparse_categorical_accuracy: 0.9184 - val_loss: 0.3529 - val_sparse_categorical_accuracy: 0.9142\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.3013 - sparse_categorical_accuracy: 0.9221 - val_loss: 0.3354 - val_sparse_categorical_accuracy: 0.9126\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.2885 - sparse_categorical_accuracy: 0.9252 - val_loss: 0.3192 - val_sparse_categorical_accuracy: 0.9126\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.2721 - sparse_categorical_accuracy: 0.9287 - val_loss: 0.3184 - val_sparse_categorical_accuracy: 0.9126\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2646 - sparse_categorical_accuracy: 0.9290 - val_loss: 0.3045 - val_sparse_categorical_accuracy: 0.9184\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2562 - sparse_categorical_accuracy: 0.9311 - val_loss: 0.3015 - val_sparse_categorical_accuracy: 0.9216\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2498 - sparse_categorical_accuracy: 0.9324 - val_loss: 0.2954 - val_sparse_categorical_accuracy: 0.9181\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2416 - sparse_categorical_accuracy: 0.9362 - val_loss: 0.2856 - val_sparse_categorical_accuracy: 0.9231\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2360 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.2856 - val_sparse_categorical_accuracy: 0.9208\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2267 - sparse_categorical_accuracy: 0.9384 - val_loss: 0.2795 - val_sparse_categorical_accuracy: 0.9204\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2192 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.2787 - val_sparse_categorical_accuracy: 0.9227\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2177 - sparse_categorical_accuracy: 0.9399 - val_loss: 0.2694 - val_sparse_categorical_accuracy: 0.9262\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2086 - sparse_categorical_accuracy: 0.9427 - val_loss: 0.2620 - val_sparse_categorical_accuracy: 0.9239\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.2061 - sparse_categorical_accuracy: 0.9414 - val_loss: 0.2627 - val_sparse_categorical_accuracy: 0.9250\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.2017 - sparse_categorical_accuracy: 0.9430 - val_loss: 0.2558 - val_sparse_categorical_accuracy: 0.9285\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1979 - sparse_categorical_accuracy: 0.9435 - val_loss: 0.2540 - val_sparse_categorical_accuracy: 0.9293\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1931 - sparse_categorical_accuracy: 0.9450 - val_loss: 0.2557 - val_sparse_categorical_accuracy: 0.9278\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1885 - sparse_categorical_accuracy: 0.9474 - val_loss: 0.2525 - val_sparse_categorical_accuracy: 0.9239\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1860 - sparse_categorical_accuracy: 0.9450 - val_loss: 0.2525 - val_sparse_categorical_accuracy: 0.9208\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1820 - sparse_categorical_accuracy: 0.9469 - val_loss: 0.2517 - val_sparse_categorical_accuracy: 0.9266\n",
            "199/199 [==============================] - 1s 4ms/step - loss: 0.2295 - sparse_categorical_accuracy: 0.9380\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2295159101486206, 0.9380223751068115]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4 = keras.Sequential()\n",
        "model_4._name=\"Experiement4_CNNLSTM_with_temporal_Attention\"\n",
        "model_4.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS, 1)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "\n",
        "# CNN \n",
        "model_4.add(Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\", kernel_initializer = initializer))\n",
        "model_4.add(Conv2D(NUM_FILTERS*2, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model_4.add(Permute((2,1,3)))\n",
        "model_4.add(Reshape((int(model_4.layers[2].output_shape[1]), int(model_4.layers[2].output_shape[2]) * int(model_4.layers[2].output_shape[3]))))\n",
        "\n",
        "# LSTM \n",
        "model_4.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_4.add(Dense(NUM_UNITS_LSTM*SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # temporal module\n",
        "model_4.add(Flatten())\n",
        "\n",
        "model_4.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_4.summary()\n",
        "\n",
        "model_4.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_4.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2)\n",
        "model_4.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHcvD9hik7rF",
        "outputId": "0babd339-2b6b-4429-e3a8-5af5c75ee758"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement4_CNNLSTM_with_temporal_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 95, 36, 4)         28        \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 90, 36, 8)         200       \n",
            "                                                                 \n",
            " permute_4 (Permute)         (None, 36, 90, 8)         0         \n",
            "                                                                 \n",
            " reshape_4 (Reshape)         (None, 36, 720)           0         \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 36, 8)             23328     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 36, 800)           7200      \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 28800)             0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 12)                345612    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 376,368\n",
            "Trainable params: 376,368\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 5s 13ms/step - loss: 0.9801 - sparse_categorical_accuracy: 0.7006 - val_loss: 0.5905 - val_sparse_categorical_accuracy: 0.8276\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.4869 - sparse_categorical_accuracy: 0.8622 - val_loss: 0.4474 - val_sparse_categorical_accuracy: 0.8765\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3978 - sparse_categorical_accuracy: 0.8894 - val_loss: 0.3779 - val_sparse_categorical_accuracy: 0.8998\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3527 - sparse_categorical_accuracy: 0.9021 - val_loss: 0.3613 - val_sparse_categorical_accuracy: 0.9014\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3187 - sparse_categorical_accuracy: 0.9115 - val_loss: 0.3507 - val_sparse_categorical_accuracy: 0.8967\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2962 - sparse_categorical_accuracy: 0.9177 - val_loss: 0.3046 - val_sparse_categorical_accuracy: 0.9142\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2742 - sparse_categorical_accuracy: 0.9232 - val_loss: 0.3245 - val_sparse_categorical_accuracy: 0.9045\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2583 - sparse_categorical_accuracy: 0.9269 - val_loss: 0.2778 - val_sparse_categorical_accuracy: 0.9208\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2400 - sparse_categorical_accuracy: 0.9324 - val_loss: 0.2703 - val_sparse_categorical_accuracy: 0.9208\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2302 - sparse_categorical_accuracy: 0.9360 - val_loss: 0.2636 - val_sparse_categorical_accuracy: 0.9216\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2226 - sparse_categorical_accuracy: 0.9358 - val_loss: 0.2602 - val_sparse_categorical_accuracy: 0.9239\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2112 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.2773 - val_sparse_categorical_accuracy: 0.9243\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2077 - sparse_categorical_accuracy: 0.9393 - val_loss: 0.2535 - val_sparse_categorical_accuracy: 0.9262\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1961 - sparse_categorical_accuracy: 0.9430 - val_loss: 0.2914 - val_sparse_categorical_accuracy: 0.9138\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1919 - sparse_categorical_accuracy: 0.9423 - val_loss: 0.2533 - val_sparse_categorical_accuracy: 0.9309\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1876 - sparse_categorical_accuracy: 0.9428 - val_loss: 0.2443 - val_sparse_categorical_accuracy: 0.9297\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1828 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.2349 - val_sparse_categorical_accuracy: 0.9317\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1768 - sparse_categorical_accuracy: 0.9430 - val_loss: 0.2441 - val_sparse_categorical_accuracy: 0.9305\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1724 - sparse_categorical_accuracy: 0.9473 - val_loss: 0.2364 - val_sparse_categorical_accuracy: 0.9340\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1622 - sparse_categorical_accuracy: 0.9508 - val_loss: 0.2235 - val_sparse_categorical_accuracy: 0.9328\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.1600 - sparse_categorical_accuracy: 0.9487 - val_loss: 0.2521 - val_sparse_categorical_accuracy: 0.9278\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.1574 - sparse_categorical_accuracy: 0.9509 - val_loss: 0.2365 - val_sparse_categorical_accuracy: 0.9332\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1530 - sparse_categorical_accuracy: 0.9517 - val_loss: 0.2282 - val_sparse_categorical_accuracy: 0.9313\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1529 - sparse_categorical_accuracy: 0.9534 - val_loss: 0.2172 - val_sparse_categorical_accuracy: 0.9332\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1478 - sparse_categorical_accuracy: 0.9539 - val_loss: 0.2522 - val_sparse_categorical_accuracy: 0.9293\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1420 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.2313 - val_sparse_categorical_accuracy: 0.9336\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1431 - sparse_categorical_accuracy: 0.9546 - val_loss: 0.2193 - val_sparse_categorical_accuracy: 0.9332\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1369 - sparse_categorical_accuracy: 0.9547 - val_loss: 0.2553 - val_sparse_categorical_accuracy: 0.9266\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1368 - sparse_categorical_accuracy: 0.9559 - val_loss: 0.2361 - val_sparse_categorical_accuracy: 0.9309\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1346 - sparse_categorical_accuracy: 0.9579 - val_loss: 0.2478 - val_sparse_categorical_accuracy: 0.9289\n",
            "199/199 [==============================] - 1s 4ms/step - loss: 0.2257 - sparse_categorical_accuracy: 0.9409\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2256810963153839, 0.9408610463142395]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5 = keras.Sequential()\n",
        "model_5._name=\"Experiement5_CNNLSTM_with_spatial_channel_Attention\"\n",
        "model_5.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS, 1)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "\n",
        "# CNN \n",
        "model_5.add(Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\", kernel_initializer = initializer))\n",
        "ChannelAttention(8, 4)\n",
        "SpatialAttention(3)\n",
        "model_5.add(Conv2D(NUM_FILTERS*2, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model_5.add(Permute((2,1,3)))\n",
        "model_5.add(Reshape((int(model_5.layers[2].output_shape[1]), int(model_5.layers[2].output_shape[2]) * int(model_5.layers[2].output_shape[3]))))\n",
        "\n",
        "# LSTM \n",
        "model_5.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_5.add(Flatten())\n",
        "\n",
        "model_5.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_5.summary()\n",
        "\n",
        "model_5.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_5.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2)\n",
        "model_5.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "e3p_SJwslGy7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bf7286a-4216-4426-9862-e27c0e374ad9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement5_CNNLSTM_with_spatial_channel_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_10 (Conv2D)          (None, 95, 36, 4)         28        \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 90, 36, 8)         200       \n",
            "                                                                 \n",
            " permute_5 (Permute)         (None, 36, 90, 8)         0         \n",
            "                                                                 \n",
            " reshape_5 (Reshape)         (None, 36, 720)           0         \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 36, 8)             23328     \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 288)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 12)                3468      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,024\n",
            "Trainable params: 27,024\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 5s 12ms/step - loss: 1.5545 - sparse_categorical_accuracy: 0.5127 - val_loss: 1.0401 - val_sparse_categorical_accuracy: 0.6765\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.8807 - sparse_categorical_accuracy: 0.7346 - val_loss: 0.8511 - val_sparse_categorical_accuracy: 0.7495\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.6801 - sparse_categorical_accuracy: 0.8144 - val_loss: 0.6413 - val_sparse_categorical_accuracy: 0.8299\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.5636 - sparse_categorical_accuracy: 0.8530 - val_loss: 0.5746 - val_sparse_categorical_accuracy: 0.8458\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.4755 - sparse_categorical_accuracy: 0.8769 - val_loss: 0.5135 - val_sparse_categorical_accuracy: 0.8645\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.4243 - sparse_categorical_accuracy: 0.8898 - val_loss: 0.4471 - val_sparse_categorical_accuracy: 0.8901\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3870 - sparse_categorical_accuracy: 0.8971 - val_loss: 0.4152 - val_sparse_categorical_accuracy: 0.8885\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3716 - sparse_categorical_accuracy: 0.9024 - val_loss: 0.3918 - val_sparse_categorical_accuracy: 0.8959\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3414 - sparse_categorical_accuracy: 0.9075 - val_loss: 0.3955 - val_sparse_categorical_accuracy: 0.8874\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3225 - sparse_categorical_accuracy: 0.9128 - val_loss: 0.3594 - val_sparse_categorical_accuracy: 0.9037\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3072 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.3567 - val_sparse_categorical_accuracy: 0.9056\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2925 - sparse_categorical_accuracy: 0.9205 - val_loss: 0.3362 - val_sparse_categorical_accuracy: 0.9076\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2800 - sparse_categorical_accuracy: 0.9237 - val_loss: 0.3268 - val_sparse_categorical_accuracy: 0.9118\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2722 - sparse_categorical_accuracy: 0.9257 - val_loss: 0.3324 - val_sparse_categorical_accuracy: 0.9068\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2606 - sparse_categorical_accuracy: 0.9285 - val_loss: 0.3152 - val_sparse_categorical_accuracy: 0.9111\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2571 - sparse_categorical_accuracy: 0.9287 - val_loss: 0.3039 - val_sparse_categorical_accuracy: 0.9161\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2440 - sparse_categorical_accuracy: 0.9323 - val_loss: 0.3254 - val_sparse_categorical_accuracy: 0.9087\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.2404 - sparse_categorical_accuracy: 0.9331 - val_loss: 0.3113 - val_sparse_categorical_accuracy: 0.9126\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2330 - sparse_categorical_accuracy: 0.9337 - val_loss: 0.2970 - val_sparse_categorical_accuracy: 0.9122\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2271 - sparse_categorical_accuracy: 0.9373 - val_loss: 0.3017 - val_sparse_categorical_accuracy: 0.9153\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2200 - sparse_categorical_accuracy: 0.9370 - val_loss: 0.2758 - val_sparse_categorical_accuracy: 0.9219\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2176 - sparse_categorical_accuracy: 0.9385 - val_loss: 0.2786 - val_sparse_categorical_accuracy: 0.9216\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2119 - sparse_categorical_accuracy: 0.9404 - val_loss: 0.2829 - val_sparse_categorical_accuracy: 0.9188\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2058 - sparse_categorical_accuracy: 0.9429 - val_loss: 0.2741 - val_sparse_categorical_accuracy: 0.9243\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2011 - sparse_categorical_accuracy: 0.9423 - val_loss: 0.2662 - val_sparse_categorical_accuracy: 0.9258\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1979 - sparse_categorical_accuracy: 0.9433 - val_loss: 0.2854 - val_sparse_categorical_accuracy: 0.9184\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1946 - sparse_categorical_accuracy: 0.9443 - val_loss: 0.2495 - val_sparse_categorical_accuracy: 0.9289\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1893 - sparse_categorical_accuracy: 0.9453 - val_loss: 0.2623 - val_sparse_categorical_accuracy: 0.9239\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1862 - sparse_categorical_accuracy: 0.9472 - val_loss: 0.2466 - val_sparse_categorical_accuracy: 0.9293\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1805 - sparse_categorical_accuracy: 0.9480 - val_loss: 0.2545 - val_sparse_categorical_accuracy: 0.9262\n",
            "199/199 [==============================] - 1s 4ms/step - loss: 0.2168 - sparse_categorical_accuracy: 0.9366\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.21680068969726562, 0.9366030693054199]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6 = keras.Sequential()\n",
        "model_6._name=\"Experiement6_CNNLSTM_with_spatial_temporal_Attention\"\n",
        "model_6.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS, 1)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "\n",
        "# CNN \n",
        "model_6.add(Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\", kernel_initializer = initializer))\n",
        "SpatialAttention(3)\n",
        "model_6.add(Conv2D(NUM_FILTERS*2, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model_6.add(Permute((2,1,3)))\n",
        "model_6.add(Reshape((int(model_6.layers[2].output_shape[1]), int(model_6.layers[2].output_shape[2]) * int(model_6.layers[2].output_shape[3]))))\n",
        "\n",
        "# LSTM \n",
        "model_6.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_6.add(Dense(NUM_UNITS_LSTM*SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # temporal module\n",
        "model_6.add(Flatten())\n",
        "\n",
        "model_6.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_6.summary()\n",
        "\n",
        "model_6.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_6.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2)\n",
        "model_6.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yB__yIAlH0T",
        "outputId": "0b942cd8-25a2-4782-e463-9579721866d2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement6_CNNLSTM_with_spatial_temporal_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 95, 36, 4)         28        \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 90, 36, 8)         200       \n",
            "                                                                 \n",
            " permute_6 (Permute)         (None, 36, 90, 8)         0         \n",
            "                                                                 \n",
            " reshape_6 (Reshape)         (None, 36, 720)           0         \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 36, 8)             23328     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 36, 800)           7200      \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 28800)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 12)                345612    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 376,368\n",
            "Trainable params: 376,368\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 5s 13ms/step - loss: 0.9994 - sparse_categorical_accuracy: 0.6950 - val_loss: 0.5757 - val_sparse_categorical_accuracy: 0.8384\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.4877 - sparse_categorical_accuracy: 0.8627 - val_loss: 0.4497 - val_sparse_categorical_accuracy: 0.8742\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3880 - sparse_categorical_accuracy: 0.8930 - val_loss: 0.3652 - val_sparse_categorical_accuracy: 0.9021\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3303 - sparse_categorical_accuracy: 0.9067 - val_loss: 0.3354 - val_sparse_categorical_accuracy: 0.9080\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2940 - sparse_categorical_accuracy: 0.9170 - val_loss: 0.4578 - val_sparse_categorical_accuracy: 0.8583\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2667 - sparse_categorical_accuracy: 0.9250 - val_loss: 0.3091 - val_sparse_categorical_accuracy: 0.9153\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.2481 - sparse_categorical_accuracy: 0.9307 - val_loss: 0.2835 - val_sparse_categorical_accuracy: 0.9223\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2380 - sparse_categorical_accuracy: 0.9324 - val_loss: 0.2694 - val_sparse_categorical_accuracy: 0.9227\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2197 - sparse_categorical_accuracy: 0.9373 - val_loss: 0.2499 - val_sparse_categorical_accuracy: 0.9270\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2108 - sparse_categorical_accuracy: 0.9380 - val_loss: 0.2524 - val_sparse_categorical_accuracy: 0.9285\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2019 - sparse_categorical_accuracy: 0.9404 - val_loss: 0.2464 - val_sparse_categorical_accuracy: 0.9270\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1910 - sparse_categorical_accuracy: 0.9430 - val_loss: 0.2377 - val_sparse_categorical_accuracy: 0.9313\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1853 - sparse_categorical_accuracy: 0.9447 - val_loss: 0.2346 - val_sparse_categorical_accuracy: 0.9293\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1764 - sparse_categorical_accuracy: 0.9464 - val_loss: 0.2356 - val_sparse_categorical_accuracy: 0.9348\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1701 - sparse_categorical_accuracy: 0.9487 - val_loss: 0.2261 - val_sparse_categorical_accuracy: 0.9375\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1669 - sparse_categorical_accuracy: 0.9489 - val_loss: 0.2328 - val_sparse_categorical_accuracy: 0.9371\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1618 - sparse_categorical_accuracy: 0.9504 - val_loss: 0.2185 - val_sparse_categorical_accuracy: 0.9367\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1543 - sparse_categorical_accuracy: 0.9520 - val_loss: 0.2174 - val_sparse_categorical_accuracy: 0.9390\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1520 - sparse_categorical_accuracy: 0.9520 - val_loss: 0.2379 - val_sparse_categorical_accuracy: 0.9386\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1481 - sparse_categorical_accuracy: 0.9538 - val_loss: 0.2329 - val_sparse_categorical_accuracy: 0.9340\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1433 - sparse_categorical_accuracy: 0.9552 - val_loss: 0.2323 - val_sparse_categorical_accuracy: 0.9313\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1370 - sparse_categorical_accuracy: 0.9556 - val_loss: 0.2390 - val_sparse_categorical_accuracy: 0.9344\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1355 - sparse_categorical_accuracy: 0.9579 - val_loss: 0.2182 - val_sparse_categorical_accuracy: 0.9379\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1365 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.2285 - val_sparse_categorical_accuracy: 0.9355\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1290 - sparse_categorical_accuracy: 0.9581 - val_loss: 0.2282 - val_sparse_categorical_accuracy: 0.9355\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1281 - sparse_categorical_accuracy: 0.9583 - val_loss: 0.2261 - val_sparse_categorical_accuracy: 0.9406\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1257 - sparse_categorical_accuracy: 0.9603 - val_loss: 0.2261 - val_sparse_categorical_accuracy: 0.9351\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1265 - sparse_categorical_accuracy: 0.9586 - val_loss: 0.2428 - val_sparse_categorical_accuracy: 0.9328\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1217 - sparse_categorical_accuracy: 0.9579 - val_loss: 0.2103 - val_sparse_categorical_accuracy: 0.9398\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1178 - sparse_categorical_accuracy: 0.9617 - val_loss: 0.2318 - val_sparse_categorical_accuracy: 0.9328\n",
            "199/199 [==============================] - 1s 4ms/step - loss: 0.2086 - sparse_categorical_accuracy: 0.9467\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.20855584740638733, 0.9466961026191711]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_7 = keras.Sequential()\n",
        "model_7._name=\"Experiement7_CNNLSTM_with_channel_temporal_Attention\"\n",
        "model_7.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS, 1)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "\n",
        "# CNN \n",
        "model_7.add(Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\", kernel_initializer = initializer))\n",
        "ChannelAttention(8, 4)\n",
        "model_7.add(Conv2D(NUM_FILTERS*2, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model_7.add(Permute((2,1,3)))\n",
        "model_7.add(Reshape((int(model_7.layers[2].output_shape[1]), int(model_7.layers[2].output_shape[2]) * int(model_7.layers[2].output_shape[3]))))\n",
        "\n",
        "# LSTM \n",
        "model_7.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_7.add(Dense(NUM_UNITS_LSTM*SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # temporal module\n",
        "model_7.add(Flatten())\n",
        "\n",
        "model_7.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_7.summary()\n",
        "\n",
        "model_7.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_7.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2)\n",
        "model_7.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "QoycyVhLlY0P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac641b65-ef5b-4074-c555-8d7f3f8d97e7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement7_CNNLSTM_with_channel_temporal_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_14 (Conv2D)          (None, 95, 36, 4)         28        \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 90, 36, 8)         200       \n",
            "                                                                 \n",
            " permute_7 (Permute)         (None, 36, 90, 8)         0         \n",
            "                                                                 \n",
            " reshape_7 (Reshape)         (None, 36, 720)           0         \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 36, 8)             23328     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 36, 800)           7200      \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 28800)             0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 12)                345612    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 376,368\n",
            "Trainable params: 376,368\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 5s 14ms/step - loss: 1.0315 - sparse_categorical_accuracy: 0.6783 - val_loss: 0.6331 - val_sparse_categorical_accuracy: 0.8365\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.4649 - sparse_categorical_accuracy: 0.8720 - val_loss: 0.4436 - val_sparse_categorical_accuracy: 0.8784\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.3647 - sparse_categorical_accuracy: 0.8971 - val_loss: 0.3461 - val_sparse_categorical_accuracy: 0.9052\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.3121 - sparse_categorical_accuracy: 0.9134 - val_loss: 0.3267 - val_sparse_categorical_accuracy: 0.9142\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2807 - sparse_categorical_accuracy: 0.9220 - val_loss: 0.2929 - val_sparse_categorical_accuracy: 0.9184\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2586 - sparse_categorical_accuracy: 0.9246 - val_loss: 0.2730 - val_sparse_categorical_accuracy: 0.9223\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2440 - sparse_categorical_accuracy: 0.9282 - val_loss: 0.2861 - val_sparse_categorical_accuracy: 0.9161\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2258 - sparse_categorical_accuracy: 0.9341 - val_loss: 0.2568 - val_sparse_categorical_accuracy: 0.9309\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2154 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.2387 - val_sparse_categorical_accuracy: 0.9289\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2067 - sparse_categorical_accuracy: 0.9380 - val_loss: 0.2567 - val_sparse_categorical_accuracy: 0.9243\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1955 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.2445 - val_sparse_categorical_accuracy: 0.9309\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1836 - sparse_categorical_accuracy: 0.9433 - val_loss: 0.2407 - val_sparse_categorical_accuracy: 0.9297\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1820 - sparse_categorical_accuracy: 0.9447 - val_loss: 0.2256 - val_sparse_categorical_accuracy: 0.9336\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1698 - sparse_categorical_accuracy: 0.9490 - val_loss: 0.2413 - val_sparse_categorical_accuracy: 0.9278\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1680 - sparse_categorical_accuracy: 0.9452 - val_loss: 0.2430 - val_sparse_categorical_accuracy: 0.9266\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1567 - sparse_categorical_accuracy: 0.9520 - val_loss: 0.2628 - val_sparse_categorical_accuracy: 0.9223\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1567 - sparse_categorical_accuracy: 0.9489 - val_loss: 0.2336 - val_sparse_categorical_accuracy: 0.9351\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1499 - sparse_categorical_accuracy: 0.9530 - val_loss: 0.2195 - val_sparse_categorical_accuracy: 0.9355\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1461 - sparse_categorical_accuracy: 0.9533 - val_loss: 0.2276 - val_sparse_categorical_accuracy: 0.9320\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1419 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.2338 - val_sparse_categorical_accuracy: 0.9305\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.1373 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.2703 - val_sparse_categorical_accuracy: 0.9247\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.1357 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.2219 - val_sparse_categorical_accuracy: 0.9344\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1317 - sparse_categorical_accuracy: 0.9583 - val_loss: 0.2210 - val_sparse_categorical_accuracy: 0.9402\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1336 - sparse_categorical_accuracy: 0.9550 - val_loss: 0.2337 - val_sparse_categorical_accuracy: 0.9394\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1230 - sparse_categorical_accuracy: 0.9604 - val_loss: 0.2261 - val_sparse_categorical_accuracy: 0.9348\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1262 - sparse_categorical_accuracy: 0.9584 - val_loss: 0.2205 - val_sparse_categorical_accuracy: 0.9344\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1192 - sparse_categorical_accuracy: 0.9620 - val_loss: 0.2359 - val_sparse_categorical_accuracy: 0.9379\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1200 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.2511 - val_sparse_categorical_accuracy: 0.9363\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1213 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.2581 - val_sparse_categorical_accuracy: 0.9282\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1131 - sparse_categorical_accuracy: 0.9641 - val_loss: 0.2325 - val_sparse_categorical_accuracy: 0.9359\n",
            "199/199 [==============================] - 1s 4ms/step - loss: 0.2051 - sparse_categorical_accuracy: 0.9467\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.20505858957767487, 0.9466961026191711]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_8 = keras.Sequential()\n",
        "model_8._name=\"Experiement8_CNNLSTM_with_spatial_channel_temporal_Attention\"\n",
        "model_8.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS, 1)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "\n",
        "# CNN \n",
        "model_8.add(Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\", kernel_initializer = initializer))\n",
        "ChannelAttention(8, 4)\n",
        "SpatialAttention(3)\n",
        "model_8.add(Conv2D(NUM_FILTERS*2, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model_8.add(Permute((2,1,3)))\n",
        "model_8.add(Reshape((int(model_8.layers[2].output_shape[1]), int(model_8.layers[2].output_shape[2]) * int(model_8.layers[2].output_shape[3]))))\n",
        "\n",
        "# LSTM \n",
        "model_8.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_8.add(Dense(NUM_UNITS_LSTM*SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # temporal module\n",
        "model_8.add(Flatten())\n",
        "\n",
        "model_8.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_8.summary()\n",
        "\n",
        "model_8.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_8.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=50,validation_split=0.2)\n",
        "model_8.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "WAKRhsTwisGX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e0e78cf-b747-4f78-fd8b-dd2dd179b99f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement8_CNNLSTM_with_spatial_channel_temporal_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 95, 36, 4)         28        \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 90, 36, 8)         200       \n",
            "                                                                 \n",
            " permute_9 (Permute)         (None, 36, 90, 8)         0         \n",
            "                                                                 \n",
            " reshape_9 (Reshape)         (None, 36, 720)           0         \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 36, 8)             23328     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 36, 800)           7200      \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 28800)             0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 12)                345612    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 376,368\n",
            "Trainable params: 376,368\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "206/206 [==============================] - 5s 13ms/step - loss: 0.9640 - sparse_categorical_accuracy: 0.7092 - val_loss: 0.5561 - val_sparse_categorical_accuracy: 0.8548\n",
            "Epoch 2/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.4428 - sparse_categorical_accuracy: 0.8796 - val_loss: 0.3969 - val_sparse_categorical_accuracy: 0.8955\n",
            "Epoch 3/50\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.3515 - sparse_categorical_accuracy: 0.9056 - val_loss: 0.3650 - val_sparse_categorical_accuracy: 0.9010\n",
            "Epoch 4/50\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.3096 - sparse_categorical_accuracy: 0.9143 - val_loss: 0.3290 - val_sparse_categorical_accuracy: 0.9122\n",
            "Epoch 5/50\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2845 - sparse_categorical_accuracy: 0.9169 - val_loss: 0.3133 - val_sparse_categorical_accuracy: 0.9099\n",
            "Epoch 6/50\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2690 - sparse_categorical_accuracy: 0.9242 - val_loss: 0.2996 - val_sparse_categorical_accuracy: 0.9173\n",
            "Epoch 7/50\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2500 - sparse_categorical_accuracy: 0.9278 - val_loss: 0.2853 - val_sparse_categorical_accuracy: 0.9192\n",
            "Epoch 8/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2361 - sparse_categorical_accuracy: 0.9322 - val_loss: 0.2744 - val_sparse_categorical_accuracy: 0.9216\n",
            "Epoch 9/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2265 - sparse_categorical_accuracy: 0.9355 - val_loss: 0.2680 - val_sparse_categorical_accuracy: 0.9235\n",
            "Epoch 10/50\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2100 - sparse_categorical_accuracy: 0.9357 - val_loss: 0.2543 - val_sparse_categorical_accuracy: 0.9274\n",
            "Epoch 11/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2009 - sparse_categorical_accuracy: 0.9393 - val_loss: 0.2697 - val_sparse_categorical_accuracy: 0.9250\n",
            "Epoch 12/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1944 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.2616 - val_sparse_categorical_accuracy: 0.9223\n",
            "Epoch 13/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1916 - sparse_categorical_accuracy: 0.9411 - val_loss: 0.2443 - val_sparse_categorical_accuracy: 0.9313\n",
            "Epoch 14/50\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1791 - sparse_categorical_accuracy: 0.9469 - val_loss: 0.2718 - val_sparse_categorical_accuracy: 0.9274\n",
            "Epoch 15/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1773 - sparse_categorical_accuracy: 0.9448 - val_loss: 0.2347 - val_sparse_categorical_accuracy: 0.9332\n",
            "Epoch 16/50\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1714 - sparse_categorical_accuracy: 0.9467 - val_loss: 0.2319 - val_sparse_categorical_accuracy: 0.9351\n",
            "Epoch 17/50\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1645 - sparse_categorical_accuracy: 0.9490 - val_loss: 0.2538 - val_sparse_categorical_accuracy: 0.9270\n",
            "Epoch 18/50\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1563 - sparse_categorical_accuracy: 0.9511 - val_loss: 0.2278 - val_sparse_categorical_accuracy: 0.9340\n",
            "Epoch 19/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1529 - sparse_categorical_accuracy: 0.9525 - val_loss: 0.2360 - val_sparse_categorical_accuracy: 0.9344\n",
            "Epoch 20/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1547 - sparse_categorical_accuracy: 0.9521 - val_loss: 0.2208 - val_sparse_categorical_accuracy: 0.9367\n",
            "Epoch 21/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1425 - sparse_categorical_accuracy: 0.9545 - val_loss: 0.2294 - val_sparse_categorical_accuracy: 0.9359\n",
            "Epoch 22/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1444 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.2261 - val_sparse_categorical_accuracy: 0.9359\n",
            "Epoch 23/50\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1374 - sparse_categorical_accuracy: 0.9564 - val_loss: 0.2315 - val_sparse_categorical_accuracy: 0.9402\n",
            "Epoch 24/50\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1326 - sparse_categorical_accuracy: 0.9570 - val_loss: 0.2400 - val_sparse_categorical_accuracy: 0.9367\n",
            "Epoch 25/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1348 - sparse_categorical_accuracy: 0.9584 - val_loss: 0.2309 - val_sparse_categorical_accuracy: 0.9363\n",
            "Epoch 26/50\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1307 - sparse_categorical_accuracy: 0.9564 - val_loss: 0.2298 - val_sparse_categorical_accuracy: 0.9340\n",
            "Epoch 27/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1308 - sparse_categorical_accuracy: 0.9570 - val_loss: 0.2256 - val_sparse_categorical_accuracy: 0.9340\n",
            "Epoch 28/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1253 - sparse_categorical_accuracy: 0.9618 - val_loss: 0.2491 - val_sparse_categorical_accuracy: 0.9340\n",
            "Epoch 29/50\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1216 - sparse_categorical_accuracy: 0.9616 - val_loss: 0.2209 - val_sparse_categorical_accuracy: 0.9363\n",
            "Epoch 30/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1220 - sparse_categorical_accuracy: 0.9626 - val_loss: 0.2498 - val_sparse_categorical_accuracy: 0.9363\n",
            "Epoch 31/50\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1212 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.2230 - val_sparse_categorical_accuracy: 0.9363\n",
            "Epoch 32/50\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1169 - sparse_categorical_accuracy: 0.9633 - val_loss: 0.2298 - val_sparse_categorical_accuracy: 0.9359\n",
            "Epoch 33/50\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1155 - sparse_categorical_accuracy: 0.9640 - val_loss: 0.2300 - val_sparse_categorical_accuracy: 0.9386\n",
            "Epoch 34/50\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1158 - sparse_categorical_accuracy: 0.9621 - val_loss: 0.2384 - val_sparse_categorical_accuracy: 0.9324\n",
            "Epoch 35/50\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1094 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.2664 - val_sparse_categorical_accuracy: 0.9266\n",
            "Epoch 36/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1090 - sparse_categorical_accuracy: 0.9623 - val_loss: 0.2526 - val_sparse_categorical_accuracy: 0.9348\n",
            "Epoch 37/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1073 - sparse_categorical_accuracy: 0.9649 - val_loss: 0.2369 - val_sparse_categorical_accuracy: 0.9379\n",
            "Epoch 38/50\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1068 - sparse_categorical_accuracy: 0.9652 - val_loss: 0.2520 - val_sparse_categorical_accuracy: 0.9340\n",
            "Epoch 39/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1085 - sparse_categorical_accuracy: 0.9674 - val_loss: 0.2333 - val_sparse_categorical_accuracy: 0.9351\n",
            "Epoch 40/50\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1029 - sparse_categorical_accuracy: 0.9674 - val_loss: 0.2477 - val_sparse_categorical_accuracy: 0.9379\n",
            "Epoch 41/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.0953 - sparse_categorical_accuracy: 0.9698 - val_loss: 0.2461 - val_sparse_categorical_accuracy: 0.9375\n",
            "Epoch 42/50\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1023 - sparse_categorical_accuracy: 0.9669 - val_loss: 0.2577 - val_sparse_categorical_accuracy: 0.9328\n",
            "Epoch 43/50\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0981 - sparse_categorical_accuracy: 0.9678 - val_loss: 0.2719 - val_sparse_categorical_accuracy: 0.9371\n",
            "Epoch 44/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.0997 - sparse_categorical_accuracy: 0.9667 - val_loss: 0.2707 - val_sparse_categorical_accuracy: 0.9293\n",
            "Epoch 45/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.0939 - sparse_categorical_accuracy: 0.9697 - val_loss: 0.2445 - val_sparse_categorical_accuracy: 0.9402\n",
            "Epoch 46/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.0960 - sparse_categorical_accuracy: 0.9692 - val_loss: 0.2470 - val_sparse_categorical_accuracy: 0.9398\n",
            "Epoch 47/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.0951 - sparse_categorical_accuracy: 0.9681 - val_loss: 0.2747 - val_sparse_categorical_accuracy: 0.9363\n",
            "Epoch 48/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.0902 - sparse_categorical_accuracy: 0.9697 - val_loss: 0.2409 - val_sparse_categorical_accuracy: 0.9406\n",
            "Epoch 49/50\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0943 - sparse_categorical_accuracy: 0.9684 - val_loss: 0.2576 - val_sparse_categorical_accuracy: 0.9379\n",
            "Epoch 50/50\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.0917 - sparse_categorical_accuracy: 0.9702 - val_loss: 0.2517 - val_sparse_categorical_accuracy: 0.9441\n",
            "199/199 [==============================] - 1s 4ms/step - loss: 0.2305 - sparse_categorical_accuracy: 0.9418\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2304803729057312, 0.9418072700500488]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "VINyhKqw8Oq5"
      }
    }
  ]
}
