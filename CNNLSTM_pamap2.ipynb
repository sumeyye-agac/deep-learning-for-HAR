{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNLSTM_pamap2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**CNN-LSTM model for Human Activity Recognition**\n",
        "\n",
        "\n",
        "Experiements on [Pamap2](https://archive.ics.uci.edu/ml/datasets/pamap2+physical+activity+monitoring) dataset using different combinations of (with/without) x (channel, temporal and/or spatial attention). \n",
        "\n",
        "Baseline CNN-LSTM architecture used is proposed in [Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition](https://www.mdpi.com/1424-8220/16/1/115/htm).  "
      ],
      "metadata": {
        "id": "-hUwKQBBY40r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSzZmQw9QLlv",
        "outputId": "ab362ce5-c8d3-479b-d99a-03d0d4ad881e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml h5py  # Required to save models in HDF5 format\n",
        "!pip install -q tensorflow-addons\n",
        "!pip install keras\n",
        "!pip install pyts\n"
      ],
      "metadata": {
        "id": "UAFxJj4VR7Vf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "916bb6e4-6036-489a-80a7-b9bf29e8cc63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyts in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numba>=0.48.0 in /usr/local/lib/python3.7/dist-packages (from pyts) (0.51.2)\n",
            "Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pyts) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from pyts) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from pyts) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.5 in /usr/local/lib/python3.7/dist-packages (from pyts) (1.21.6)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts) (57.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->pyts) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/Debarshi-Bhattacharya/Ensem_HAR/blob/9d7769f34258185c56feb7c34f6059e07469030f/Implementation_on_PAMAP2/datapreprocessing.ipynb\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import h5py\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "'''\n",
        "0: 'transient', 1: 'lying', 2: 'sitting', 3: 'standing', 4: 'walking', 5: 'running', 6: 'cycling', 7: 'Nordic_walking', 9: 'watching_TV', \n",
        "10: 'computer_work', 11: 'car driving', 12: 'ascending_stairs', 13: 'descending_stairs', 16: 'vacuum_cleaning', 17: 'ironing', \n",
        "18: 'folding_laundry', 19: 'house_cleaning', 20: 'playing_soccer', 24: 'rope_jumping'\n",
        "'''\n",
        "\n",
        "def read_files():\n",
        "    list_of_files = ['Protocol/subject101.dat',\n",
        "                     'Protocol/subject102.dat',\n",
        "                     'Protocol/subject103.dat',\n",
        "                     'Protocol/subject104.dat',\n",
        "                     'Protocol/subject105.dat',\n",
        "                     'Protocol/subject106.dat',\n",
        "                     'Protocol/subject107.dat',\n",
        "                     'Protocol/subject108.dat',\n",
        "                     'Protocol/subject109.dat']\n",
        "    \n",
        "    subjectID = [1,2,3,4,5,6,7,8,9]\n",
        "    \n",
        "    # there are 54 columns in the data files\n",
        "    colNames = [\"timestamp\", \"activityID\",\"heartrate\"] # 1, 2, 3\n",
        "    IMUhand = ['handTemperature', \n",
        "               'handAcc16_1', 'handAcc16_2', 'handAcc16_3', \n",
        "               'handAcc6_1', 'handAcc6_2', 'handAcc6_3', \n",
        "               'handGyro1', 'handGyro2', 'handGyro3', \n",
        "               'handMagne1', 'handMagne2', 'handMagne3',\n",
        "               'handOrientation1', 'handOrientation2', 'handOrientation3', 'handOrientation4'] # 4-20\n",
        "    IMUchest = ['chestTemperature', \n",
        "               'chestAcc16_1', 'chestAcc16_2', 'chestAcc16_3', \n",
        "               'chestAcc6_1', 'chestAcc6_2', 'chestAcc6_3', \n",
        "               'chestGyro1', 'chestGyro2', 'chestGyro3', \n",
        "               'chestMagne1', 'chestMagne2', 'chestMagne3',\n",
        "               'chestOrientation1', 'chestOrientation2', 'chestOrientation3', 'chestOrientation4'] # 21-37\n",
        "    IMUankle = ['ankleTemperature', \n",
        "               'ankleAcc16_1', 'ankleAcc16_2', 'ankleAcc16_3', \n",
        "               'ankleAcc6_1', 'ankleAcc6_2', 'ankleAcc6_3', \n",
        "               'ankleGyro1', 'ankleGyro2', 'ankleGyro3', \n",
        "               'ankleMagne1', 'ankleMagne2', 'ankleMagne3',\n",
        "               'ankleOrientation1', 'ankleOrientation2', 'ankleOrientation3', 'ankleOrientation4'] # 38-54\n",
        "    \n",
        "    columns = colNames + IMUhand + IMUchest + IMUankle\n",
        "    \n",
        "    dataCollection = pd.DataFrame()\n",
        "\n",
        "    for file in list_of_files:\n",
        "        print(file)\n",
        "        procData = pd.read_table(file, header=None, sep='\\s+')\n",
        "        procData.columns = columns\n",
        "        procData['subject_id'] = int(file[-5])\n",
        "        dataCollection = dataCollection.append(procData, ignore_index=True) \n",
        "        \n",
        "    dataCollection.reset_index(drop=True, inplace=True)\n",
        "    \n",
        "    return dataCollection\n",
        "\n",
        "data = read_files()\n",
        "data.head()\n",
        "\n",
        "def dataCleaning(dataCollection):\n",
        "    dataCollection = dataCollection.drop(['timestamp', 'handOrientation1', 'handOrientation2', 'handOrientation3', 'handOrientation4',\n",
        "                                         'chestOrientation1', 'chestOrientation2', 'chestOrientation3', 'chestOrientation4',\n",
        "                                         'ankleOrientation1', 'ankleOrientation2', 'ankleOrientation3', 'ankleOrientation4'],\n",
        "                                         axis = 1)  # removal of orientation columns as they are not needed\n",
        "    dataCollection = dataCollection.drop(dataCollection[dataCollection.activityID == 0].index) # removal of any row of activity 0 as it is transient activity which it is not used\n",
        "    dataCollection = dataCollection.apply(pd.to_numeric, errors = 'coerce') # removal of non numeric data in cells\n",
        "    dataCollection = dataCollection.drop(['heartrate'], axis = 1)\n",
        "    dataCollection = dataCollection.dropna()\n",
        "\n",
        "    dataCollection = dataCollection.drop(['handTemperature', 'chestTemperature', 'ankleTemperature'],\n",
        "                                         axis = 1)  # removal of temperature columns as they are not needed - sumeyye\n",
        "    print(\"data cleaned!\")\n",
        "    return dataCollection\n",
        "\n",
        "cleaned_data = dataCleaning(data)\n",
        "print(cleaned_data['activityID'].value_counts())\n",
        "cleaned_data.head(10)\n",
        "\n",
        "def reset_label(dataCollection): \n",
        "    # Convert original labels {1, 2, 3, 4, 5, 6, 7, 12, 13, 16, 17, 24} to new labels. \n",
        "    mapping = {24:0,1:1,2:2,3:3,4:4,5:5,6:6,7:7,12:8,13:9,16:10,17:11} # old activity Id to new activity Id \n",
        "    for i in [24,12,13,16,17]:\n",
        "        dataCollection.loc[dataCollection.activityID == i, 'activityID'] = mapping[i]\n",
        "\n",
        "    return dataCollection\n",
        "data_reset = reset_label(cleaned_data)  \n",
        "data_reset.head(10)\n",
        "\n",
        "X=data_reset.drop(['activityID'],axis=1)\n",
        "y=data_reset['activityID']\n",
        "\n",
        "X.head()\n",
        "\n",
        "X_subID=X['subject_id']\n",
        "\n",
        "def scale(df): # minmax scale\n",
        "    features=df.columns[0:X.shape[1]]\n",
        "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "    df[features]=scaler.fit_transform(df[features])\n",
        "    return df\n",
        "\n",
        "data_scaled =scale(X)\n",
        "data_scaled.shape\n",
        "X_scaled=pd.concat([pd.DataFrame(y,columns = ['activityID']),pd.DataFrame(data_scaled)],axis=1)\n",
        "X_scaled=pd.concat([pd.DataFrame(X_scaled),pd.DataFrame(X_subID,columns = ['subject_id'])],axis=1)\n",
        "\n",
        "X_scaled.head(10)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "id": "0i885Vw0dYAk",
        "outputId": "df13f0de-f9ca-4d2c-890f-2e06106ed9fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Protocol/subject101.dat\n",
            "Protocol/subject102.dat\n",
            "Protocol/subject103.dat\n",
            "Protocol/subject104.dat\n",
            "Protocol/subject105.dat\n",
            "Protocol/subject106.dat\n",
            "Protocol/subject107.dat\n",
            "Protocol/subject108.dat\n",
            "Protocol/subject109.dat\n",
            "data cleaned!\n",
            "17    237902\n",
            "4     229709\n",
            "1     192290\n",
            "3     188984\n",
            "2     184645\n",
            "7     184444\n",
            "16    174976\n",
            "6     163302\n",
            "12    117094\n",
            "13    104865\n",
            "5      95641\n",
            "24     47579\n",
            "Name: activityID, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      activityID  handAcc16_1  handAcc16_2  handAcc16_3  handAcc6_1  \\\n",
              "2928           1     0.417516    -0.133999    -0.174116    0.113009   \n",
              "2929           1     0.418253    -0.138662    -0.172903    0.113480   \n",
              "2930           1     0.418242    -0.142743    -0.172296    0.113408   \n",
              "2931           1     0.417542    -0.142733    -0.171710    0.112568   \n",
              "2932           1     0.418340    -0.141849    -0.170219    0.112313   \n",
              "2933           1     0.416137    -0.141841    -0.170839    0.112053   \n",
              "2934           1     0.419401    -0.139240    -0.171403    0.112886   \n",
              "2935           1     0.418600    -0.138959    -0.173195    0.114232   \n",
              "2936           1     0.417859    -0.137792    -0.173802    0.113701   \n",
              "2937           1     0.416803    -0.139818    -0.172620    0.114210   \n",
              "\n",
              "      handAcc6_2  handAcc6_3  handGyro1  handGyro2  handGyro3  ...  \\\n",
              "2928    0.134484    0.093285   0.031349  -0.125912  -0.003356  ...   \n",
              "2929    0.127909    0.093543   0.025227  -0.126503  -0.003244  ...   \n",
              "2930    0.120122    0.093560   0.022788  -0.127200  -0.002519  ...   \n",
              "2931    0.113557    0.095039   0.024450  -0.126817  -0.001641  ...   \n",
              "2932    0.113316    0.096259   0.028958  -0.128644  -0.002256  ...   \n",
              "2933    0.112832    0.097235   0.033865  -0.127398  -0.000850  ...   \n",
              "2934    0.116965    0.097469   0.038519  -0.127596   0.000134  ...   \n",
              "2935    0.119876    0.097218   0.038867  -0.128201   0.002218  ...   \n",
              "2936    0.120852    0.095997   0.039005  -0.131084   0.000920  ...   \n",
              "2937    0.121090    0.093558   0.037803  -0.130456  -0.001068  ...   \n",
              "\n",
              "      ankleAcc6_2  ankleAcc6_3  ankleGyro1  ankleGyro2  ankleGyro3  \\\n",
              "2928    -0.029670     0.015502    0.186908    0.141361   -0.082024   \n",
              "2929    -0.029426     0.015259    0.187797    0.143168   -0.081745   \n",
              "2930    -0.029180     0.016977    0.185013    0.139803   -0.082458   \n",
              "2931    -0.029913     0.016243    0.185156    0.141920   -0.080374   \n",
              "2932    -0.029425     0.015991    0.186831    0.140026   -0.082553   \n",
              "2933    -0.029425     0.016241    0.186951    0.141412   -0.081868   \n",
              "2934    -0.029668     0.016480    0.188585    0.141073   -0.082588   \n",
              "2935    -0.029669     0.016486    0.186252    0.142060   -0.081710   \n",
              "2936    -0.028937     0.016483    0.188710    0.144395   -0.082916   \n",
              "2937    -0.028692     0.016481    0.188241    0.142430   -0.081802   \n",
              "\n",
              "      ankleMagne1  ankleMagne2  ankleMagne3  subject_id  subject_id  \n",
              "2928    -0.154691    -0.129512    -0.644683        -1.0           1  \n",
              "2929    -0.153053    -0.124827    -0.644651        -1.0           1  \n",
              "2930    -0.148886    -0.120213    -0.646624        -1.0           1  \n",
              "2931    -0.152093    -0.131573    -0.640759        -1.0           1  \n",
              "2932    -0.147852    -0.131743    -0.640798        -1.0           1  \n",
              "2933    -0.156337    -0.130467    -0.639719        -1.0           1  \n",
              "2934    -0.158048    -0.130370    -0.641687        -1.0           1  \n",
              "2935    -0.158213    -0.123558    -0.652528        -1.0           1  \n",
              "2936    -0.159728    -0.132190    -0.642682        -1.0           1  \n",
              "2937    -0.152118    -0.134311    -0.648720        -1.0           1  \n",
              "\n",
              "[10 rows x 39 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0b5ef40-b160-4918-9cd5-e07122480522\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>activityID</th>\n",
              "      <th>handAcc16_1</th>\n",
              "      <th>handAcc16_2</th>\n",
              "      <th>handAcc16_3</th>\n",
              "      <th>handAcc6_1</th>\n",
              "      <th>handAcc6_2</th>\n",
              "      <th>handAcc6_3</th>\n",
              "      <th>handGyro1</th>\n",
              "      <th>handGyro2</th>\n",
              "      <th>handGyro3</th>\n",
              "      <th>...</th>\n",
              "      <th>ankleAcc6_2</th>\n",
              "      <th>ankleAcc6_3</th>\n",
              "      <th>ankleGyro1</th>\n",
              "      <th>ankleGyro2</th>\n",
              "      <th>ankleGyro3</th>\n",
              "      <th>ankleMagne1</th>\n",
              "      <th>ankleMagne2</th>\n",
              "      <th>ankleMagne3</th>\n",
              "      <th>subject_id</th>\n",
              "      <th>subject_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2928</th>\n",
              "      <td>1</td>\n",
              "      <td>0.417516</td>\n",
              "      <td>-0.133999</td>\n",
              "      <td>-0.174116</td>\n",
              "      <td>0.113009</td>\n",
              "      <td>0.134484</td>\n",
              "      <td>0.093285</td>\n",
              "      <td>0.031349</td>\n",
              "      <td>-0.125912</td>\n",
              "      <td>-0.003356</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.029670</td>\n",
              "      <td>0.015502</td>\n",
              "      <td>0.186908</td>\n",
              "      <td>0.141361</td>\n",
              "      <td>-0.082024</td>\n",
              "      <td>-0.154691</td>\n",
              "      <td>-0.129512</td>\n",
              "      <td>-0.644683</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2929</th>\n",
              "      <td>1</td>\n",
              "      <td>0.418253</td>\n",
              "      <td>-0.138662</td>\n",
              "      <td>-0.172903</td>\n",
              "      <td>0.113480</td>\n",
              "      <td>0.127909</td>\n",
              "      <td>0.093543</td>\n",
              "      <td>0.025227</td>\n",
              "      <td>-0.126503</td>\n",
              "      <td>-0.003244</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.029426</td>\n",
              "      <td>0.015259</td>\n",
              "      <td>0.187797</td>\n",
              "      <td>0.143168</td>\n",
              "      <td>-0.081745</td>\n",
              "      <td>-0.153053</td>\n",
              "      <td>-0.124827</td>\n",
              "      <td>-0.644651</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2930</th>\n",
              "      <td>1</td>\n",
              "      <td>0.418242</td>\n",
              "      <td>-0.142743</td>\n",
              "      <td>-0.172296</td>\n",
              "      <td>0.113408</td>\n",
              "      <td>0.120122</td>\n",
              "      <td>0.093560</td>\n",
              "      <td>0.022788</td>\n",
              "      <td>-0.127200</td>\n",
              "      <td>-0.002519</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.029180</td>\n",
              "      <td>0.016977</td>\n",
              "      <td>0.185013</td>\n",
              "      <td>0.139803</td>\n",
              "      <td>-0.082458</td>\n",
              "      <td>-0.148886</td>\n",
              "      <td>-0.120213</td>\n",
              "      <td>-0.646624</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2931</th>\n",
              "      <td>1</td>\n",
              "      <td>0.417542</td>\n",
              "      <td>-0.142733</td>\n",
              "      <td>-0.171710</td>\n",
              "      <td>0.112568</td>\n",
              "      <td>0.113557</td>\n",
              "      <td>0.095039</td>\n",
              "      <td>0.024450</td>\n",
              "      <td>-0.126817</td>\n",
              "      <td>-0.001641</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.029913</td>\n",
              "      <td>0.016243</td>\n",
              "      <td>0.185156</td>\n",
              "      <td>0.141920</td>\n",
              "      <td>-0.080374</td>\n",
              "      <td>-0.152093</td>\n",
              "      <td>-0.131573</td>\n",
              "      <td>-0.640759</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2932</th>\n",
              "      <td>1</td>\n",
              "      <td>0.418340</td>\n",
              "      <td>-0.141849</td>\n",
              "      <td>-0.170219</td>\n",
              "      <td>0.112313</td>\n",
              "      <td>0.113316</td>\n",
              "      <td>0.096259</td>\n",
              "      <td>0.028958</td>\n",
              "      <td>-0.128644</td>\n",
              "      <td>-0.002256</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.029425</td>\n",
              "      <td>0.015991</td>\n",
              "      <td>0.186831</td>\n",
              "      <td>0.140026</td>\n",
              "      <td>-0.082553</td>\n",
              "      <td>-0.147852</td>\n",
              "      <td>-0.131743</td>\n",
              "      <td>-0.640798</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2933</th>\n",
              "      <td>1</td>\n",
              "      <td>0.416137</td>\n",
              "      <td>-0.141841</td>\n",
              "      <td>-0.170839</td>\n",
              "      <td>0.112053</td>\n",
              "      <td>0.112832</td>\n",
              "      <td>0.097235</td>\n",
              "      <td>0.033865</td>\n",
              "      <td>-0.127398</td>\n",
              "      <td>-0.000850</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.029425</td>\n",
              "      <td>0.016241</td>\n",
              "      <td>0.186951</td>\n",
              "      <td>0.141412</td>\n",
              "      <td>-0.081868</td>\n",
              "      <td>-0.156337</td>\n",
              "      <td>-0.130467</td>\n",
              "      <td>-0.639719</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2934</th>\n",
              "      <td>1</td>\n",
              "      <td>0.419401</td>\n",
              "      <td>-0.139240</td>\n",
              "      <td>-0.171403</td>\n",
              "      <td>0.112886</td>\n",
              "      <td>0.116965</td>\n",
              "      <td>0.097469</td>\n",
              "      <td>0.038519</td>\n",
              "      <td>-0.127596</td>\n",
              "      <td>0.000134</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.029668</td>\n",
              "      <td>0.016480</td>\n",
              "      <td>0.188585</td>\n",
              "      <td>0.141073</td>\n",
              "      <td>-0.082588</td>\n",
              "      <td>-0.158048</td>\n",
              "      <td>-0.130370</td>\n",
              "      <td>-0.641687</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2935</th>\n",
              "      <td>1</td>\n",
              "      <td>0.418600</td>\n",
              "      <td>-0.138959</td>\n",
              "      <td>-0.173195</td>\n",
              "      <td>0.114232</td>\n",
              "      <td>0.119876</td>\n",
              "      <td>0.097218</td>\n",
              "      <td>0.038867</td>\n",
              "      <td>-0.128201</td>\n",
              "      <td>0.002218</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.029669</td>\n",
              "      <td>0.016486</td>\n",
              "      <td>0.186252</td>\n",
              "      <td>0.142060</td>\n",
              "      <td>-0.081710</td>\n",
              "      <td>-0.158213</td>\n",
              "      <td>-0.123558</td>\n",
              "      <td>-0.652528</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2936</th>\n",
              "      <td>1</td>\n",
              "      <td>0.417859</td>\n",
              "      <td>-0.137792</td>\n",
              "      <td>-0.173802</td>\n",
              "      <td>0.113701</td>\n",
              "      <td>0.120852</td>\n",
              "      <td>0.095997</td>\n",
              "      <td>0.039005</td>\n",
              "      <td>-0.131084</td>\n",
              "      <td>0.000920</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028937</td>\n",
              "      <td>0.016483</td>\n",
              "      <td>0.188710</td>\n",
              "      <td>0.144395</td>\n",
              "      <td>-0.082916</td>\n",
              "      <td>-0.159728</td>\n",
              "      <td>-0.132190</td>\n",
              "      <td>-0.642682</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2937</th>\n",
              "      <td>1</td>\n",
              "      <td>0.416803</td>\n",
              "      <td>-0.139818</td>\n",
              "      <td>-0.172620</td>\n",
              "      <td>0.114210</td>\n",
              "      <td>0.121090</td>\n",
              "      <td>0.093558</td>\n",
              "      <td>0.037803</td>\n",
              "      <td>-0.130456</td>\n",
              "      <td>-0.001068</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028692</td>\n",
              "      <td>0.016481</td>\n",
              "      <td>0.188241</td>\n",
              "      <td>0.142430</td>\n",
              "      <td>-0.081802</td>\n",
              "      <td>-0.152118</td>\n",
              "      <td>-0.134311</td>\n",
              "      <td>-0.648720</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 39 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0b5ef40-b160-4918-9cd5-e07122480522')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0b5ef40-b160-4918-9cd5-e07122480522 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0b5ef40-b160-4918-9cd5-e07122480522');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SLIDING_WINDOW_LENGTH = 100\n",
        "\n",
        "def segment_signal(data, window_size): # data is numpy array\n",
        "    n = len(data)\n",
        "    X, y = [], []\n",
        "    start, end = 0, 0\n",
        "    while start + window_size - 1 < n:\n",
        "        end = start + window_size-1\n",
        "        # if the frame contains the same activity and from the same object\n",
        "        X.append(data[start:(end+1),1:-1])\n",
        "        y.append(data[start][0])\n",
        "        start += window_size #without overlap (for 50% overlap use window_size//2)\n",
        "    print(np.asarray(X).shape, np.asarray(y).shape)\n",
        "    return {'inputs' : np.asarray(X), 'labels': np.asarray(y,dtype=int)}\n",
        "\n",
        "data_segmented=segment_signal(X_scaled.to_numpy(),SLIDING_WINDOW_LENGTH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b0PmyPbdiOA",
        "outputId": "abf6d2aa-c8e7-444c-f31b-e229cabe4ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19214, 100, 37) (19214,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_data(data,file_name): # save the data in h5 format\n",
        "    f = h5py.File(file_name,'w')\n",
        "    for key in data:\n",
        "        f.create_dataset(key,data = data[key])       \n",
        "    f.close()   \n",
        "\n",
        "file_name = 'pamap_scaled_segmented_100.h5'\n",
        "\n",
        "save_data(data_segmented, file_name)\n",
        "print(\"File is saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkM7h-JTdmf0",
        "outputId": "3e8102d1-f910-4d0b-875d-ba4f7075e465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File is saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "path = \"pamap_scaled_segmented_100.h5\"\n",
        "\n",
        "f = h5py.File(path, 'r')\n",
        "\n",
        "data_x = np.array(f[\"inputs\"][:]) \n",
        "data_y = np.array(f[\"labels\"][:])\n",
        "\n",
        "print(data_x.shape)\n",
        "print(data_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1YorXCydps_",
        "outputId": "cf6c34d1-ec19-42a5-8409-52ac30a404fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19214, 100, 37)\n",
            "(19214,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data is reshaped since the input of the network is a 4 dimension tensor\n",
        "data_x = data_x.reshape((-1, data_x.shape[1], data_x.shape[2], 1))\n",
        "print(data_x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUm7q-D7f_vX",
        "outputId": "803a3102-52b9-464f-c047-5a9ab04e44bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19214, 100, 37, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/53731141/cifar10-randomize-train-and-test-set\n",
        "def shuffle_train_data(X_train, Y_train): \n",
        "    \"\"\"called after each epoch\"\"\" \n",
        "    perm = np.random.permutation(len(Y_train)) \n",
        "    Xtr_shuf = X_train[perm] \n",
        "    Ytr_shuf = Y_train[perm] \n",
        "    return Xtr_shuf, Ytr_shuf \n",
        "X_shuffled, y_shuffled = shuffle_train_data(data_x, data_y) \n",
        "print(X_shuffled.shape) \n",
        "print(y_shuffled.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCmQDZA7gPGJ",
        "outputId": "836a8b94-c741-4e55-e228-3b38b453e01a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19214, 100, 37, 1)\n",
            "(19214,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://stackoverflow.com/questions/53731141/cifar10-randomize-train-and-test-set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_shuffled, y_shuffled, test_size=0.33, random_state=1234)\n",
        "# Check shape\n",
        "print(X_train.shape) \n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOwmuLTKdu_4",
        "outputId": "9c3e881a-23fe-4f62-f0d4-660aede1fecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12873, 100, 37, 1)\n",
            "(12873,)\n",
            "(6341, 100, 37, 1)\n",
            "(6341,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, LSTM, Flatten, Input, Conv2D, Permute, Reshape\n",
        "from keras import optimizers, losses, metrics, initializers\n",
        "\n",
        "from collections import Counter\n",
        "NUM_CLASSES = len(Counter(y_shuffled).keys())\n",
        "BATCH_SIZE = 50 \n",
        "NUM_FILTERS = 8 # Number filters convolutional layers\n",
        "FILTER_SIZE = 6 # Size filters convolutional layers\n",
        "NUM_UNITS_LSTM = 16 # Number of unit in the long short-term recurrent layers\n",
        "NB_SENSOR_CHANNELS = data_x.shape[2]\n",
        "SLIDING_WINDOW_LENGTH = data_x.shape[1]"
      ],
      "metadata": {
        "id": "7iIHarpB2u13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model._name=\"Experiement1_CNNLSTM_without_Attention\"\n",
        "model.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS, 1)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "\n",
        "# CNN \n",
        "model.add(Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\", kernel_initializer = initializer))\n",
        "model.add(Conv2D(NUM_FILTERS*2, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model.add(Permute((2,1,3)))\n",
        "model.add(Reshape((int(model.layers[2].output_shape[1]), int(model.layers[2].output_shape[2]) * int(model.layers[2].output_shape[3]))))\n",
        "\n",
        "# LSTM \n",
        "model.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2)\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "0NVDN3J_S9Fj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d39e580b-975d-4590-ac76-eebc103e2f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement1_CNNLSTM_without_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 95, 37, 8)         56        \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 90, 37, 16)        784       \n",
            "                                                                 \n",
            " permute_1 (Permute)         (None, 37, 90, 16)        0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 37, 1440)          0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 37, 16)            93248     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 592)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 12)                7116      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,204\n",
            "Trainable params: 101,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 17s 14ms/step - loss: 1.1695 - sparse_categorical_accuracy: 0.6359 - val_loss: 0.7353 - val_sparse_categorical_accuracy: 0.7973\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.6182 - sparse_categorical_accuracy: 0.8265 - val_loss: 0.5610 - val_sparse_categorical_accuracy: 0.8400\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.4759 - sparse_categorical_accuracy: 0.8693 - val_loss: 0.4377 - val_sparse_categorical_accuracy: 0.8874\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3917 - sparse_categorical_accuracy: 0.8963 - val_loss: 0.3716 - val_sparse_categorical_accuracy: 0.9025\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.3401 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.3350 - val_sparse_categorical_accuracy: 0.9142\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.2983 - sparse_categorical_accuracy: 0.9215 - val_loss: 0.3243 - val_sparse_categorical_accuracy: 0.9087\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2718 - sparse_categorical_accuracy: 0.9291 - val_loss: 0.3211 - val_sparse_categorical_accuracy: 0.9153\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2503 - sparse_categorical_accuracy: 0.9310 - val_loss: 0.2786 - val_sparse_categorical_accuracy: 0.9243\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2308 - sparse_categorical_accuracy: 0.9372 - val_loss: 0.2814 - val_sparse_categorical_accuracy: 0.9243\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2158 - sparse_categorical_accuracy: 0.9399 - val_loss: 0.2454 - val_sparse_categorical_accuracy: 0.9336\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.1993 - sparse_categorical_accuracy: 0.9460 - val_loss: 0.2533 - val_sparse_categorical_accuracy: 0.9328\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.1901 - sparse_categorical_accuracy: 0.9459 - val_loss: 0.2445 - val_sparse_categorical_accuracy: 0.9320\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.1761 - sparse_categorical_accuracy: 0.9497 - val_loss: 0.2283 - val_sparse_categorical_accuracy: 0.9371\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.1678 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.2203 - val_sparse_categorical_accuracy: 0.9398\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1624 - sparse_categorical_accuracy: 0.9539 - val_loss: 0.2174 - val_sparse_categorical_accuracy: 0.9417\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1524 - sparse_categorical_accuracy: 0.9574 - val_loss: 0.1988 - val_sparse_categorical_accuracy: 0.9429\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1447 - sparse_categorical_accuracy: 0.9570 - val_loss: 0.1986 - val_sparse_categorical_accuracy: 0.9425\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1371 - sparse_categorical_accuracy: 0.9596 - val_loss: 0.1980 - val_sparse_categorical_accuracy: 0.9414\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.1291 - sparse_categorical_accuracy: 0.9626 - val_loss: 0.2040 - val_sparse_categorical_accuracy: 0.9417\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.1286 - sparse_categorical_accuracy: 0.9640 - val_loss: 0.1943 - val_sparse_categorical_accuracy: 0.9449\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.1185 - sparse_categorical_accuracy: 0.9665 - val_loss: 0.2058 - val_sparse_categorical_accuracy: 0.9398\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1160 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.1881 - val_sparse_categorical_accuracy: 0.9476\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1111 - sparse_categorical_accuracy: 0.9666 - val_loss: 0.1877 - val_sparse_categorical_accuracy: 0.9483\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1045 - sparse_categorical_accuracy: 0.9686 - val_loss: 0.1821 - val_sparse_categorical_accuracy: 0.9464\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.0999 - sparse_categorical_accuracy: 0.9715 - val_loss: 0.1797 - val_sparse_categorical_accuracy: 0.9452\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.0965 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.1874 - val_sparse_categorical_accuracy: 0.9445\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.0917 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.1809 - val_sparse_categorical_accuracy: 0.9452\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.0893 - sparse_categorical_accuracy: 0.9732 - val_loss: 0.1717 - val_sparse_categorical_accuracy: 0.9499\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.0853 - sparse_categorical_accuracy: 0.9749 - val_loss: 0.2033 - val_sparse_categorical_accuracy: 0.9402\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.0804 - sparse_categorical_accuracy: 0.9761 - val_loss: 0.1718 - val_sparse_categorical_accuracy: 0.9480\n",
            "199/199 [==============================] - 1s 5ms/step - loss: 0.1814 - sparse_categorical_accuracy: 0.9467\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1814473271369934, 0.9466961026191711]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/EscVM/EscVM_YT/blob/master/Notebooks/0%20-%20TF2.X%20Tutorials/tf_2_visual_attention.ipynb\n",
        "\n",
        "from keras.layers import Layer, GlobalAveragePooling2D, GlobalMaxPooling2D, Add, Activation, Multiply\n",
        "\n",
        "class ChannelAttention(Layer):\n",
        "      def __init__(self, filters, ratio):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.filters = filters\n",
        "        self.ratio = ratio\n",
        "\n",
        "        def build(self, input_shape):\n",
        "            self.shared_layer_one = Dense(self.filters//self.ratio,\n",
        "                             activation='relu', kernel_initializer='he_normal', \n",
        "                              use_bias=True, \n",
        "                              bias_initializer='zeros')\n",
        "            self.shared_layer_two = Dense(self.filters,\n",
        "                             kernel_initializer='he_normal',\n",
        "                             use_bias=True,\n",
        "                             bias_initializer='zeros')\n",
        "\n",
        "        def call(self, inputs):\n",
        "            # AvgPool\n",
        "            avg_pool = GlobalAveragePooling2D()(inputs)\n",
        "            \n",
        "\n",
        "            avg_pool = self.shared_layer_one(avg_pool)\n",
        "            avg_pool = self.shared_layer_two(avg_pool)\n",
        "\n",
        "            # MaxPool\n",
        "            max_pool = GlobalMaxPooling2D()(inputs)\n",
        "            max_pool = Reshape((1,1,filters))(max_pool)\n",
        "\n",
        "            max_pool = shared_layer_one(max_pool)\n",
        "            max_pool = shared_layer_two(max_pool)\n",
        "\n",
        "\n",
        "            attention = Add()([avg_pool,max_pool])\n",
        "            attention = Activation('sigmoid')(attention)\n",
        "            \n",
        "            return Multiply()([inputs, attention])"
      ],
      "metadata": {
        "id": "xj6u1NOhTCEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/EscVM/EscVM_YT/blob/master/Notebooks/0%20-%20TF2.X%20Tutorials/tf_2_visual_attention.ipynb\n",
        "\n",
        "from keras.layers import Lambda, Concatenate, multiply\n",
        "from keras import backend\n",
        "\n",
        "class SpatialAttention(Layer):\n",
        "      def __init__(self, kernel_size):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        def build(self, input_shape):\n",
        "            self.conv2d = Conv2D(filters = 1,\n",
        "                    kernel_size=self.kernel_size,\n",
        "                    strides=1,\n",
        "                    padding='same',\n",
        "                    activation='sigmoid',\n",
        "                    kernel_initializer='he_normal',\n",
        "                    use_bias=False)\n",
        "\n",
        "        def call(self, inputs):\n",
        "            \n",
        "            # AvgPool\n",
        "            avg_pool = Lambda(lambda x: backend.mean(x, axis=3, keepdims=True))(inputs)\n",
        "            \n",
        "            # MaxPool\n",
        "            max_pool = Lambda(lambda x: backend.max(x, axis=3, keepdims=True))(inputs)\n",
        "\n",
        "            attention = Concatenate(axis=3)([avg_pool, max_pool])\n",
        "\n",
        "            attention = self.conv2d(attention)\n",
        "\n",
        "\n",
        "            return Multiply([inputs, attention]) "
      ],
      "metadata": {
        "id": "flCOjQcrTDn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/ManzhuYu/Code-SpatioTemporalAttention-LSTM-main/blob/main/modelbase.py # temporal module and spatial module"
      ],
      "metadata": {
        "id": "tg_HoHN9jvZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = keras.Sequential()\n",
        "model_2._name=\"Experiement2_CNNLSTM_with_spatial_Attention\"\n",
        "model_2.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS, 1)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "\n",
        "# CNN \n",
        "model_2.add(Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\", kernel_initializer = initializer))\n",
        "SpatialAttention(3),\n",
        "model_2.add(Conv2D(NUM_FILTERS*2, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model_2.add(Permute((2,1,3)))\n",
        "model_2.add(Reshape((int(model_2.layers[2].output_shape[1]), int(model_2.layers[2].output_shape[2]) * int(model_2.layers[2].output_shape[3]))))\n",
        "\n",
        "# LSTM \n",
        "model_2.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_2.add(Flatten())\n",
        "\n",
        "model_2.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_2.summary()\n",
        "\n",
        "model_2.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_2.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2)\n",
        "model_2.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLmzEfqckhXD",
        "outputId": "07f3aaee-33c8-4a0a-e54c-327dae7fa03b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement2_CNNLSTM_with_spatial_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_24 (Conv2D)          (None, 95, 37, 8)         56        \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 90, 37, 16)        784       \n",
            "                                                                 \n",
            " permute_12 (Permute)        (None, 37, 90, 16)        0         \n",
            "                                                                 \n",
            " reshape_11 (Reshape)        (None, 37, 1440)          0         \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 37, 16)            93248     \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 592)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 12)                7116      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,204\n",
            "Trainable params: 101,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 8s 21ms/step - loss: 1.1463 - sparse_categorical_accuracy: 0.6620 - val_loss: 0.6836 - val_sparse_categorical_accuracy: 0.8159\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 3s 17ms/step - loss: 0.5256 - sparse_categorical_accuracy: 0.8606 - val_loss: 0.4673 - val_sparse_categorical_accuracy: 0.8827\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.3989 - sparse_categorical_accuracy: 0.8921 - val_loss: 0.3879 - val_sparse_categorical_accuracy: 0.8975\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3346 - sparse_categorical_accuracy: 0.9091 - val_loss: 0.3393 - val_sparse_categorical_accuracy: 0.9091\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2940 - sparse_categorical_accuracy: 0.9203 - val_loss: 0.2959 - val_sparse_categorical_accuracy: 0.9231\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2647 - sparse_categorical_accuracy: 0.9284 - val_loss: 0.3028 - val_sparse_categorical_accuracy: 0.9204\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.2435 - sparse_categorical_accuracy: 0.9337 - val_loss: 0.2621 - val_sparse_categorical_accuracy: 0.9297\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.2255 - sparse_categorical_accuracy: 0.9387 - val_loss: 0.2595 - val_sparse_categorical_accuracy: 0.9328\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.2105 - sparse_categorical_accuracy: 0.9423 - val_loss: 0.2377 - val_sparse_categorical_accuracy: 0.9386\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 4s 18ms/step - loss: 0.1988 - sparse_categorical_accuracy: 0.9458 - val_loss: 0.2360 - val_sparse_categorical_accuracy: 0.9367\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.1870 - sparse_categorical_accuracy: 0.9473 - val_loss: 0.2139 - val_sparse_categorical_accuracy: 0.9456\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1737 - sparse_categorical_accuracy: 0.9519 - val_loss: 0.2349 - val_sparse_categorical_accuracy: 0.9383\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1645 - sparse_categorical_accuracy: 0.9521 - val_loss: 0.2180 - val_sparse_categorical_accuracy: 0.9414\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1560 - sparse_categorical_accuracy: 0.9549 - val_loss: 0.2227 - val_sparse_categorical_accuracy: 0.9379\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1498 - sparse_categorical_accuracy: 0.9581 - val_loss: 0.2030 - val_sparse_categorical_accuracy: 0.9472\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1419 - sparse_categorical_accuracy: 0.9597 - val_loss: 0.2207 - val_sparse_categorical_accuracy: 0.9394\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1360 - sparse_categorical_accuracy: 0.9608 - val_loss: 0.1901 - val_sparse_categorical_accuracy: 0.9499\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1288 - sparse_categorical_accuracy: 0.9630 - val_loss: 0.1814 - val_sparse_categorical_accuracy: 0.9511\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.1224 - sparse_categorical_accuracy: 0.9667 - val_loss: 0.1884 - val_sparse_categorical_accuracy: 0.9483\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.1167 - sparse_categorical_accuracy: 0.9669 - val_loss: 0.1863 - val_sparse_categorical_accuracy: 0.9522\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1132 - sparse_categorical_accuracy: 0.9669 - val_loss: 0.1915 - val_sparse_categorical_accuracy: 0.9491\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1088 - sparse_categorical_accuracy: 0.9685 - val_loss: 0.1712 - val_sparse_categorical_accuracy: 0.9546\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1004 - sparse_categorical_accuracy: 0.9717 - val_loss: 0.1796 - val_sparse_categorical_accuracy: 0.9511\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0996 - sparse_categorical_accuracy: 0.9715 - val_loss: 0.1764 - val_sparse_categorical_accuracy: 0.9522\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.0955 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.1653 - val_sparse_categorical_accuracy: 0.9546\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.0905 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.1712 - val_sparse_categorical_accuracy: 0.9553\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.0882 - sparse_categorical_accuracy: 0.9751 - val_loss: 0.1661 - val_sparse_categorical_accuracy: 0.9542\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.0847 - sparse_categorical_accuracy: 0.9759 - val_loss: 0.1791 - val_sparse_categorical_accuracy: 0.9480\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.0801 - sparse_categorical_accuracy: 0.9767 - val_loss: 0.1702 - val_sparse_categorical_accuracy: 0.9522\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0796 - sparse_categorical_accuracy: 0.9782 - val_loss: 0.1789 - val_sparse_categorical_accuracy: 0.9522\n",
            "199/199 [==============================] - 1s 4ms/step - loss: 0.1857 - sparse_categorical_accuracy: 0.9456\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1857251226902008, 0.9455921649932861]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = keras.Sequential()\n",
        "model_3._name=\"Experiement3_CNNLSTM_with_channel_Attention\"\n",
        "model_3.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS, 1)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "\n",
        "# CNN \n",
        "model_3.add(Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\", kernel_initializer = initializer))\n",
        "ChannelAttention(8, 4),\n",
        "model_3.add(Conv2D(NUM_FILTERS*2, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model_3.add(Permute((2,1,3)))\n",
        "model_3.add(Reshape((int(model_3.layers[2].output_shape[1]), int(model_3.layers[2].output_shape[2]) * int(model_3.layers[2].output_shape[3]))))\n",
        "\n",
        "# LSTM \n",
        "model_3.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_3.add(Flatten())\n",
        "\n",
        "model_3.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_3.summary()\n",
        "\n",
        "model_3.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_3.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2)\n",
        "model_3.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtqC30ktkv9J",
        "outputId": "aefab7b0-1b1b-4c49-e9f2-650fb62a3c67"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement3_CNNLSTM_with_channel_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_26 (Conv2D)          (None, 95, 37, 8)         56        \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 90, 37, 16)        784       \n",
            "                                                                 \n",
            " permute_13 (Permute)        (None, 37, 90, 16)        0         \n",
            "                                                                 \n",
            " reshape_12 (Reshape)        (None, 37, 1440)          0         \n",
            "                                                                 \n",
            " lstm_12 (LSTM)              (None, 37, 16)            93248     \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 592)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 12)                7116      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,204\n",
            "Trainable params: 101,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 8s 20ms/step - loss: 1.1664 - sparse_categorical_accuracy: 0.6481 - val_loss: 0.7105 - val_sparse_categorical_accuracy: 0.8027\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.6042 - sparse_categorical_accuracy: 0.8379 - val_loss: 0.5067 - val_sparse_categorical_accuracy: 0.8649\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.4581 - sparse_categorical_accuracy: 0.8812 - val_loss: 0.4088 - val_sparse_categorical_accuracy: 0.8932\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.3748 - sparse_categorical_accuracy: 0.9000 - val_loss: 0.3646 - val_sparse_categorical_accuracy: 0.8994\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.3224 - sparse_categorical_accuracy: 0.9150 - val_loss: 0.3328 - val_sparse_categorical_accuracy: 0.9056\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2910 - sparse_categorical_accuracy: 0.9216 - val_loss: 0.2976 - val_sparse_categorical_accuracy: 0.9216\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2650 - sparse_categorical_accuracy: 0.9266 - val_loss: 0.3015 - val_sparse_categorical_accuracy: 0.9192\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2406 - sparse_categorical_accuracy: 0.9357 - val_loss: 0.2717 - val_sparse_categorical_accuracy: 0.9293\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2263 - sparse_categorical_accuracy: 0.9390 - val_loss: 0.2488 - val_sparse_categorical_accuracy: 0.9386\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2083 - sparse_categorical_accuracy: 0.9430 - val_loss: 0.2759 - val_sparse_categorical_accuracy: 0.9320\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1981 - sparse_categorical_accuracy: 0.9458 - val_loss: 0.2486 - val_sparse_categorical_accuracy: 0.9367\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1862 - sparse_categorical_accuracy: 0.9485 - val_loss: 0.2456 - val_sparse_categorical_accuracy: 0.9390\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1779 - sparse_categorical_accuracy: 0.9501 - val_loss: 0.2259 - val_sparse_categorical_accuracy: 0.9417\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1689 - sparse_categorical_accuracy: 0.9535 - val_loss: 0.2290 - val_sparse_categorical_accuracy: 0.9406\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1623 - sparse_categorical_accuracy: 0.9537 - val_loss: 0.2148 - val_sparse_categorical_accuracy: 0.9425\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1543 - sparse_categorical_accuracy: 0.9558 - val_loss: 0.2200 - val_sparse_categorical_accuracy: 0.9398\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1472 - sparse_categorical_accuracy: 0.9552 - val_loss: 0.2243 - val_sparse_categorical_accuracy: 0.9379\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1398 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.2149 - val_sparse_categorical_accuracy: 0.9437\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1372 - sparse_categorical_accuracy: 0.9612 - val_loss: 0.2160 - val_sparse_categorical_accuracy: 0.9402\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1294 - sparse_categorical_accuracy: 0.9621 - val_loss: 0.2592 - val_sparse_categorical_accuracy: 0.9212\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1231 - sparse_categorical_accuracy: 0.9641 - val_loss: 0.2070 - val_sparse_categorical_accuracy: 0.9429\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1209 - sparse_categorical_accuracy: 0.9664 - val_loss: 0.2166 - val_sparse_categorical_accuracy: 0.9390\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1154 - sparse_categorical_accuracy: 0.9662 - val_loss: 0.2258 - val_sparse_categorical_accuracy: 0.9398\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1094 - sparse_categorical_accuracy: 0.9669 - val_loss: 0.2173 - val_sparse_categorical_accuracy: 0.9375\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1066 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.2081 - val_sparse_categorical_accuracy: 0.9394\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1023 - sparse_categorical_accuracy: 0.9715 - val_loss: 0.2141 - val_sparse_categorical_accuracy: 0.9414\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.0999 - sparse_categorical_accuracy: 0.9708 - val_loss: 0.2165 - val_sparse_categorical_accuracy: 0.9414\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0919 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.1942 - val_sparse_categorical_accuracy: 0.9483\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.0935 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.2209 - val_sparse_categorical_accuracy: 0.9367\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.0875 - sparse_categorical_accuracy: 0.9741 - val_loss: 0.2165 - val_sparse_categorical_accuracy: 0.9383\n",
            "199/199 [==============================] - 1s 4ms/step - loss: 0.2141 - sparse_categorical_accuracy: 0.9375\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2141396403312683, 0.9375492930412292]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4 = keras.Sequential()\n",
        "model_4._name=\"Experiement4_CNNLSTM_with_temporal_Attention\"\n",
        "model_4.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS, 1)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "\n",
        "# CNN \n",
        "model_4.add(Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\", kernel_initializer = initializer))\n",
        "model_4.add(Conv2D(NUM_FILTERS*2, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model_4.add(Permute((2,1,3)))\n",
        "model_4.add(Reshape((int(model_4.layers[2].output_shape[1]), int(model_4.layers[2].output_shape[2]) * int(model_4.layers[2].output_shape[3]))))\n",
        "\n",
        "# LSTM \n",
        "model_4.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_4.add(Dense(NUM_UNITS_LSTM*SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # temporal module\n",
        "model_4.add(Flatten())\n",
        "\n",
        "model_4.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_4.summary()\n",
        "\n",
        "model_4.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_4.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2)\n",
        "model_4.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHcvD9hik7rF",
        "outputId": "20442d9d-931b-449b-a113-5f40bd4c1258"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement4_CNNLSTM_with_temporal_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_28 (Conv2D)          (None, 95, 37, 8)         56        \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 90, 37, 16)        784       \n",
            "                                                                 \n",
            " permute_14 (Permute)        (None, 37, 90, 16)        0         \n",
            "                                                                 \n",
            " reshape_13 (Reshape)        (None, 37, 1440)          0         \n",
            "                                                                 \n",
            " lstm_13 (LSTM)              (None, 37, 16)            93248     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 37, 1600)          27200     \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (None, 59200)             0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 12)                710412    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 831,700\n",
            "Trainable params: 831,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 5s 15ms/step - loss: 0.9067 - sparse_categorical_accuracy: 0.7284 - val_loss: 0.6384 - val_sparse_categorical_accuracy: 0.7934\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.3840 - sparse_categorical_accuracy: 0.8960 - val_loss: 0.3538 - val_sparse_categorical_accuracy: 0.9014\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2976 - sparse_categorical_accuracy: 0.9174 - val_loss: 0.2902 - val_sparse_categorical_accuracy: 0.9231\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2606 - sparse_categorical_accuracy: 0.9283 - val_loss: 0.2788 - val_sparse_categorical_accuracy: 0.9227\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.2299 - sparse_categorical_accuracy: 0.9343 - val_loss: 0.2470 - val_sparse_categorical_accuracy: 0.9344\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.2107 - sparse_categorical_accuracy: 0.9366 - val_loss: 0.2569 - val_sparse_categorical_accuracy: 0.9289\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1937 - sparse_categorical_accuracy: 0.9452 - val_loss: 0.2137 - val_sparse_categorical_accuracy: 0.9398\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.1757 - sparse_categorical_accuracy: 0.9473 - val_loss: 0.2292 - val_sparse_categorical_accuracy: 0.9371\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1611 - sparse_categorical_accuracy: 0.9506 - val_loss: 0.2086 - val_sparse_categorical_accuracy: 0.9371\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1527 - sparse_categorical_accuracy: 0.9536 - val_loss: 0.2264 - val_sparse_categorical_accuracy: 0.9367\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1409 - sparse_categorical_accuracy: 0.9559 - val_loss: 0.1996 - val_sparse_categorical_accuracy: 0.9414\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1340 - sparse_categorical_accuracy: 0.9587 - val_loss: 0.2557 - val_sparse_categorical_accuracy: 0.9328\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1280 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.2138 - val_sparse_categorical_accuracy: 0.9410\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1168 - sparse_categorical_accuracy: 0.9629 - val_loss: 0.2200 - val_sparse_categorical_accuracy: 0.9379\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1133 - sparse_categorical_accuracy: 0.9674 - val_loss: 0.2106 - val_sparse_categorical_accuracy: 0.9452\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1048 - sparse_categorical_accuracy: 0.9679 - val_loss: 0.2207 - val_sparse_categorical_accuracy: 0.9406\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1048 - sparse_categorical_accuracy: 0.9654 - val_loss: 0.2212 - val_sparse_categorical_accuracy: 0.9375\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0960 - sparse_categorical_accuracy: 0.9707 - val_loss: 0.2122 - val_sparse_categorical_accuracy: 0.9425\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.0925 - sparse_categorical_accuracy: 0.9717 - val_loss: 0.2122 - val_sparse_categorical_accuracy: 0.9468\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0845 - sparse_categorical_accuracy: 0.9728 - val_loss: 0.2152 - val_sparse_categorical_accuracy: 0.9480\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0884 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.2309 - val_sparse_categorical_accuracy: 0.9445\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0856 - sparse_categorical_accuracy: 0.9713 - val_loss: 0.2194 - val_sparse_categorical_accuracy: 0.9456\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0788 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.2339 - val_sparse_categorical_accuracy: 0.9456\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.0723 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.2271 - val_sparse_categorical_accuracy: 0.9503\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0764 - sparse_categorical_accuracy: 0.9752 - val_loss: 0.2539 - val_sparse_categorical_accuracy: 0.9452\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.0694 - sparse_categorical_accuracy: 0.9779 - val_loss: 0.2290 - val_sparse_categorical_accuracy: 0.9487\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0659 - sparse_categorical_accuracy: 0.9791 - val_loss: 0.2429 - val_sparse_categorical_accuracy: 0.9406\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0640 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.2670 - val_sparse_categorical_accuracy: 0.9449\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0615 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.2632 - val_sparse_categorical_accuracy: 0.9456\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0617 - sparse_categorical_accuracy: 0.9790 - val_loss: 0.2648 - val_sparse_categorical_accuracy: 0.9476\n",
            "199/199 [==============================] - 1s 4ms/step - loss: 0.2818 - sparse_categorical_accuracy: 0.9475\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2817949056625366, 0.9474846124649048]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5 = keras.Sequential()\n",
        "model_5._name=\"Experiement5_CNNLSTM_with_spatial_channel_Attention\"\n",
        "model_5.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS, 1)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "\n",
        "# CNN \n",
        "model_5.add(Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\", kernel_initializer = initializer))\n",
        "ChannelAttention(8, 4)\n",
        "SpatialAttention(3)\n",
        "model_5.add(Conv2D(NUM_FILTERS*2, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model_5.add(Permute((2,1,3)))\n",
        "model_5.add(Reshape((int(model_5.layers[2].output_shape[1]), int(model_5.layers[2].output_shape[2]) * int(model_5.layers[2].output_shape[3]))))\n",
        "\n",
        "# LSTM \n",
        "model_5.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_5.add(Flatten())\n",
        "\n",
        "model_5.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_5.summary()\n",
        "\n",
        "model_5.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_5.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2)\n",
        "model_5.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "e3p_SJwslGy7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54de9ce7-4ee2-45c1-82e0-e575265e29ab"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement5_CNNLSTM_with_spatial_channel_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_34 (Conv2D)          (None, 95, 37, 8)         56        \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (None, 90, 37, 16)        784       \n",
            "                                                                 \n",
            " permute_17 (Permute)        (None, 37, 90, 16)        0         \n",
            "                                                                 \n",
            " reshape_16 (Reshape)        (None, 37, 1440)          0         \n",
            "                                                                 \n",
            " lstm_16 (LSTM)              (None, 37, 16)            93248     \n",
            "                                                                 \n",
            " flatten_16 (Flatten)        (None, 592)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 12)                7116      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,204\n",
            "Trainable params: 101,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 7s 20ms/step - loss: 1.2283 - sparse_categorical_accuracy: 0.6212 - val_loss: 0.7454 - val_sparse_categorical_accuracy: 0.7825\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.6211 - sparse_categorical_accuracy: 0.8328 - val_loss: 0.5360 - val_sparse_categorical_accuracy: 0.8489\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.4519 - sparse_categorical_accuracy: 0.8794 - val_loss: 0.4283 - val_sparse_categorical_accuracy: 0.8963\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.3633 - sparse_categorical_accuracy: 0.9012 - val_loss: 0.3440 - val_sparse_categorical_accuracy: 0.9118\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3083 - sparse_categorical_accuracy: 0.9162 - val_loss: 0.3188 - val_sparse_categorical_accuracy: 0.9192\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2756 - sparse_categorical_accuracy: 0.9262 - val_loss: 0.3014 - val_sparse_categorical_accuracy: 0.9204\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.2481 - sparse_categorical_accuracy: 0.9334 - val_loss: 0.2867 - val_sparse_categorical_accuracy: 0.9270\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.2247 - sparse_categorical_accuracy: 0.9387 - val_loss: 0.2603 - val_sparse_categorical_accuracy: 0.9254\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.2114 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.2515 - val_sparse_categorical_accuracy: 0.9309\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1939 - sparse_categorical_accuracy: 0.9463 - val_loss: 0.2505 - val_sparse_categorical_accuracy: 0.9313\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1834 - sparse_categorical_accuracy: 0.9481 - val_loss: 0.2269 - val_sparse_categorical_accuracy: 0.9383\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1706 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.2181 - val_sparse_categorical_accuracy: 0.9390\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1593 - sparse_categorical_accuracy: 0.9547 - val_loss: 0.2115 - val_sparse_categorical_accuracy: 0.9410\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1495 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.2207 - val_sparse_categorical_accuracy: 0.9390\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1408 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.2344 - val_sparse_categorical_accuracy: 0.9332\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1356 - sparse_categorical_accuracy: 0.9599 - val_loss: 0.2172 - val_sparse_categorical_accuracy: 0.9394\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1285 - sparse_categorical_accuracy: 0.9621 - val_loss: 0.2094 - val_sparse_categorical_accuracy: 0.9402\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1233 - sparse_categorical_accuracy: 0.9628 - val_loss: 0.1890 - val_sparse_categorical_accuracy: 0.9441\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1177 - sparse_categorical_accuracy: 0.9650 - val_loss: 0.1880 - val_sparse_categorical_accuracy: 0.9429\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1121 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.1880 - val_sparse_categorical_accuracy: 0.9449\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1071 - sparse_categorical_accuracy: 0.9690 - val_loss: 0.1902 - val_sparse_categorical_accuracy: 0.9468\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.1009 - sparse_categorical_accuracy: 0.9685 - val_loss: 0.1884 - val_sparse_categorical_accuracy: 0.9483\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0968 - sparse_categorical_accuracy: 0.9710 - val_loss: 0.1885 - val_sparse_categorical_accuracy: 0.9483\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.0899 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.1918 - val_sparse_categorical_accuracy: 0.9476\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.0878 - sparse_categorical_accuracy: 0.9741 - val_loss: 0.1890 - val_sparse_categorical_accuracy: 0.9487\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.0852 - sparse_categorical_accuracy: 0.9761 - val_loss: 0.2008 - val_sparse_categorical_accuracy: 0.9460\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.0817 - sparse_categorical_accuracy: 0.9756 - val_loss: 0.1984 - val_sparse_categorical_accuracy: 0.9472\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0773 - sparse_categorical_accuracy: 0.9777 - val_loss: 0.1823 - val_sparse_categorical_accuracy: 0.9468\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0750 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.1825 - val_sparse_categorical_accuracy: 0.9483\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.0721 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.1834 - val_sparse_categorical_accuracy: 0.9522\n",
            "199/199 [==============================] - 1s 4ms/step - loss: 0.1974 - sparse_categorical_accuracy: 0.9454\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.19744755327701569, 0.9454344511032104]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6 = keras.Sequential()\n",
        "model_6._name=\"Experiement6_CNNLSTM_with_spatial_temporal_Attention\"\n",
        "model_6.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS, 1)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "\n",
        "# CNN \n",
        "model_6.add(Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\", kernel_initializer = initializer))\n",
        "SpatialAttention(3)\n",
        "model_6.add(Conv2D(NUM_FILTERS*2, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model_6.add(Permute((2,1,3)))\n",
        "model_6.add(Reshape((int(model_6.layers[2].output_shape[1]), int(model_6.layers[2].output_shape[2]) * int(model_6.layers[2].output_shape[3]))))\n",
        "\n",
        "# LSTM \n",
        "model_6.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_6.add(Dense(NUM_UNITS_LSTM*SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # temporal module\n",
        "model_6.add(Flatten())\n",
        "\n",
        "model_6.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_6.summary()\n",
        "\n",
        "model_6.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_6.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2)\n",
        "model_6.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yB__yIAlH0T",
        "outputId": "0f9e1e61-636a-4a81-944c-3ef0932e8d2d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement6_CNNLSTM_with_spatial_temporal_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_36 (Conv2D)          (None, 95, 37, 8)         56        \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 90, 37, 16)        784       \n",
            "                                                                 \n",
            " permute_18 (Permute)        (None, 37, 90, 16)        0         \n",
            "                                                                 \n",
            " reshape_17 (Reshape)        (None, 37, 1440)          0         \n",
            "                                                                 \n",
            " lstm_17 (LSTM)              (None, 37, 16)            93248     \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 37, 1600)          27200     \n",
            "                                                                 \n",
            " flatten_17 (Flatten)        (None, 59200)             0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 12)                710412    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 831,700\n",
            "Trainable params: 831,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 5s 14ms/step - loss: 0.9363 - sparse_categorical_accuracy: 0.7106 - val_loss: 0.4257 - val_sparse_categorical_accuracy: 0.8909\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.3673 - sparse_categorical_accuracy: 0.8989 - val_loss: 0.3659 - val_sparse_categorical_accuracy: 0.8936\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2955 - sparse_categorical_accuracy: 0.9168 - val_loss: 0.3227 - val_sparse_categorical_accuracy: 0.9126\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2569 - sparse_categorical_accuracy: 0.9286 - val_loss: 0.3273 - val_sparse_categorical_accuracy: 0.9083\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.2272 - sparse_categorical_accuracy: 0.9346 - val_loss: 0.2409 - val_sparse_categorical_accuracy: 0.9324\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2044 - sparse_categorical_accuracy: 0.9395 - val_loss: 0.2431 - val_sparse_categorical_accuracy: 0.9344\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1869 - sparse_categorical_accuracy: 0.9434 - val_loss: 0.2313 - val_sparse_categorical_accuracy: 0.9274\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1741 - sparse_categorical_accuracy: 0.9490 - val_loss: 0.2088 - val_sparse_categorical_accuracy: 0.9410\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1584 - sparse_categorical_accuracy: 0.9523 - val_loss: 0.1977 - val_sparse_categorical_accuracy: 0.9445\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1481 - sparse_categorical_accuracy: 0.9540 - val_loss: 0.2455 - val_sparse_categorical_accuracy: 0.9254\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1401 - sparse_categorical_accuracy: 0.9587 - val_loss: 0.2283 - val_sparse_categorical_accuracy: 0.9394\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1309 - sparse_categorical_accuracy: 0.9596 - val_loss: 0.2010 - val_sparse_categorical_accuracy: 0.9476\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1205 - sparse_categorical_accuracy: 0.9624 - val_loss: 0.2173 - val_sparse_categorical_accuracy: 0.9355\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1137 - sparse_categorical_accuracy: 0.9631 - val_loss: 0.2221 - val_sparse_categorical_accuracy: 0.9375\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.1057 - sparse_categorical_accuracy: 0.9642 - val_loss: 0.2199 - val_sparse_categorical_accuracy: 0.9449\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.0970 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.2099 - val_sparse_categorical_accuracy: 0.9483\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0964 - sparse_categorical_accuracy: 0.9711 - val_loss: 0.2013 - val_sparse_categorical_accuracy: 0.9476\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0891 - sparse_categorical_accuracy: 0.9715 - val_loss: 0.2100 - val_sparse_categorical_accuracy: 0.9511\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0860 - sparse_categorical_accuracy: 0.9723 - val_loss: 0.2099 - val_sparse_categorical_accuracy: 0.9449\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0862 - sparse_categorical_accuracy: 0.9726 - val_loss: 0.2047 - val_sparse_categorical_accuracy: 0.9472\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0741 - sparse_categorical_accuracy: 0.9763 - val_loss: 0.2409 - val_sparse_categorical_accuracy: 0.9425\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0737 - sparse_categorical_accuracy: 0.9772 - val_loss: 0.2560 - val_sparse_categorical_accuracy: 0.9410\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0737 - sparse_categorical_accuracy: 0.9767 - val_loss: 0.2817 - val_sparse_categorical_accuracy: 0.9386\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0643 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.2350 - val_sparse_categorical_accuracy: 0.9491\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0664 - sparse_categorical_accuracy: 0.9797 - val_loss: 0.2377 - val_sparse_categorical_accuracy: 0.9499\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0623 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.2442 - val_sparse_categorical_accuracy: 0.9468\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0576 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.3159 - val_sparse_categorical_accuracy: 0.9351\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0609 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.2637 - val_sparse_categorical_accuracy: 0.9491\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0578 - sparse_categorical_accuracy: 0.9824 - val_loss: 0.2573 - val_sparse_categorical_accuracy: 0.9460\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0510 - sparse_categorical_accuracy: 0.9824 - val_loss: 0.2616 - val_sparse_categorical_accuracy: 0.9499\n",
            "199/199 [==============================] - 1s 5ms/step - loss: 0.2534 - sparse_categorical_accuracy: 0.9532\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.25338760018348694, 0.9531619548797607]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_7 = keras.Sequential()\n",
        "model_7._name=\"Experiement7_CNNLSTM_with_channel_temporal_Attention\"\n",
        "model_7.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS, 1)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "\n",
        "# CNN \n",
        "model_7.add(Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\", kernel_initializer = initializer))\n",
        "ChannelAttention(8, 4)\n",
        "model_7.add(Conv2D(NUM_FILTERS*2, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model_7.add(Permute((2,1,3)))\n",
        "model_7.add(Reshape((int(model_7.layers[2].output_shape[1]), int(model_7.layers[2].output_shape[2]) * int(model_7.layers[2].output_shape[3]))))\n",
        "\n",
        "# LSTM \n",
        "model_7.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_7.add(Dense(NUM_UNITS_LSTM*SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # temporal module\n",
        "model_7.add(Flatten())\n",
        "\n",
        "model_7.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_7.summary()\n",
        "\n",
        "model_7.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_7.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2)\n",
        "model_7.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "QoycyVhLlY0P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "802a006e-a15a-460d-d89b-d598a96d1aaf"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement7_CNNLSTM_with_channel_temporal_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_38 (Conv2D)          (None, 95, 37, 8)         56        \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 90, 37, 16)        784       \n",
            "                                                                 \n",
            " permute_19 (Permute)        (None, 37, 90, 16)        0         \n",
            "                                                                 \n",
            " reshape_18 (Reshape)        (None, 37, 1440)          0         \n",
            "                                                                 \n",
            " lstm_18 (LSTM)              (None, 37, 16)            93248     \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 37, 1600)          27200     \n",
            "                                                                 \n",
            " flatten_18 (Flatten)        (None, 59200)             0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 12)                710412    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 831,700\n",
            "Trainable params: 831,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 5s 14ms/step - loss: 0.9872 - sparse_categorical_accuracy: 0.7012 - val_loss: 0.4197 - val_sparse_categorical_accuracy: 0.8928\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.3675 - sparse_categorical_accuracy: 0.8997 - val_loss: 0.3197 - val_sparse_categorical_accuracy: 0.9157\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2970 - sparse_categorical_accuracy: 0.9170 - val_loss: 0.2919 - val_sparse_categorical_accuracy: 0.9177\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2585 - sparse_categorical_accuracy: 0.9273 - val_loss: 0.2597 - val_sparse_categorical_accuracy: 0.9254\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2270 - sparse_categorical_accuracy: 0.9351 - val_loss: 0.2525 - val_sparse_categorical_accuracy: 0.9301\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2055 - sparse_categorical_accuracy: 0.9404 - val_loss: 0.2536 - val_sparse_categorical_accuracy: 0.9274\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1893 - sparse_categorical_accuracy: 0.9450 - val_loss: 0.2381 - val_sparse_categorical_accuracy: 0.9328\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1761 - sparse_categorical_accuracy: 0.9469 - val_loss: 0.2438 - val_sparse_categorical_accuracy: 0.9313\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1656 - sparse_categorical_accuracy: 0.9506 - val_loss: 0.2146 - val_sparse_categorical_accuracy: 0.9359\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1523 - sparse_categorical_accuracy: 0.9523 - val_loss: 0.2146 - val_sparse_categorical_accuracy: 0.9394\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1414 - sparse_categorical_accuracy: 0.9563 - val_loss: 0.2222 - val_sparse_categorical_accuracy: 0.9386\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.1367 - sparse_categorical_accuracy: 0.9585 - val_loss: 0.2310 - val_sparse_categorical_accuracy: 0.9324\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1278 - sparse_categorical_accuracy: 0.9602 - val_loss: 0.2283 - val_sparse_categorical_accuracy: 0.9390\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1220 - sparse_categorical_accuracy: 0.9623 - val_loss: 0.2240 - val_sparse_categorical_accuracy: 0.9371\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1122 - sparse_categorical_accuracy: 0.9655 - val_loss: 0.2126 - val_sparse_categorical_accuracy: 0.9449\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1026 - sparse_categorical_accuracy: 0.9684 - val_loss: 0.2301 - val_sparse_categorical_accuracy: 0.9367\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0994 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.2343 - val_sparse_categorical_accuracy: 0.9425\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.0974 - sparse_categorical_accuracy: 0.9685 - val_loss: 0.2214 - val_sparse_categorical_accuracy: 0.9445\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0940 - sparse_categorical_accuracy: 0.9709 - val_loss: 0.2312 - val_sparse_categorical_accuracy: 0.9398\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0911 - sparse_categorical_accuracy: 0.9711 - val_loss: 0.2495 - val_sparse_categorical_accuracy: 0.9429\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0831 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.2174 - val_sparse_categorical_accuracy: 0.9445\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.0824 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.2325 - val_sparse_categorical_accuracy: 0.9441\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0777 - sparse_categorical_accuracy: 0.9754 - val_loss: 0.2586 - val_sparse_categorical_accuracy: 0.9410\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.0737 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.2444 - val_sparse_categorical_accuracy: 0.9460\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.0727 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.2464 - val_sparse_categorical_accuracy: 0.9456\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0661 - sparse_categorical_accuracy: 0.9780 - val_loss: 0.2568 - val_sparse_categorical_accuracy: 0.9456\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0657 - sparse_categorical_accuracy: 0.9777 - val_loss: 0.2528 - val_sparse_categorical_accuracy: 0.9421\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0682 - sparse_categorical_accuracy: 0.9790 - val_loss: 0.2607 - val_sparse_categorical_accuracy: 0.9437\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0625 - sparse_categorical_accuracy: 0.9790 - val_loss: 0.2944 - val_sparse_categorical_accuracy: 0.9425\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0644 - sparse_categorical_accuracy: 0.9796 - val_loss: 0.2706 - val_sparse_categorical_accuracy: 0.9406\n",
            "199/199 [==============================] - 1s 5ms/step - loss: 0.2981 - sparse_categorical_accuracy: 0.9410\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2980833351612091, 0.9410187602043152]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_8 = keras.Sequential()\n",
        "model_8._name=\"Experiement8_CNNLSTM_with_spatial_channel_temporal_Attention\"\n",
        "model_8.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS, 1)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "\n",
        "# CNN \n",
        "model_8.add(Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\", kernel_initializer = initializer))\n",
        "ChannelAttention(8, 4)\n",
        "SpatialAttention(3)\n",
        "model_8.add(Conv2D(NUM_FILTERS*2, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model_8.add(Permute((2,1,3)))\n",
        "model_8.add(Reshape((int(model_8.layers[2].output_shape[1]), int(model_8.layers[2].output_shape[2]) * int(model_8.layers[2].output_shape[3]))))\n",
        "\n",
        "# LSTM \n",
        "model_8.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_8.add(Dense(NUM_UNITS_LSTM*SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # temporal module\n",
        "model_8.add(Flatten())\n",
        "\n",
        "model_8.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_8.summary()\n",
        "\n",
        "model_8.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_8.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2)\n",
        "model_8.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "WAKRhsTwisGX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14b510a7-8e12-4a4d-c321-388519411354"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement8_CNNLSTM_with_spatial_channel_temporal_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_40 (Conv2D)          (None, 95, 37, 8)         56        \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 90, 37, 16)        784       \n",
            "                                                                 \n",
            " permute_20 (Permute)        (None, 37, 90, 16)        0         \n",
            "                                                                 \n",
            " reshape_19 (Reshape)        (None, 37, 1440)          0         \n",
            "                                                                 \n",
            " lstm_19 (LSTM)              (None, 37, 16)            93248     \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 37, 1600)          27200     \n",
            "                                                                 \n",
            " flatten_19 (Flatten)        (None, 59200)             0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 12)                710412    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 831,700\n",
            "Trainable params: 831,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 5s 14ms/step - loss: 0.9340 - sparse_categorical_accuracy: 0.7106 - val_loss: 0.4539 - val_sparse_categorical_accuracy: 0.8781\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.4000 - sparse_categorical_accuracy: 0.8881 - val_loss: 0.3361 - val_sparse_categorical_accuracy: 0.9130\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.3059 - sparse_categorical_accuracy: 0.9142 - val_loss: 0.2789 - val_sparse_categorical_accuracy: 0.9216\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2572 - sparse_categorical_accuracy: 0.9266 - val_loss: 0.2643 - val_sparse_categorical_accuracy: 0.9274\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2331 - sparse_categorical_accuracy: 0.9320 - val_loss: 0.2487 - val_sparse_categorical_accuracy: 0.9355\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2099 - sparse_categorical_accuracy: 0.9394 - val_loss: 0.2382 - val_sparse_categorical_accuracy: 0.9336\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1954 - sparse_categorical_accuracy: 0.9437 - val_loss: 0.2554 - val_sparse_categorical_accuracy: 0.9355\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1855 - sparse_categorical_accuracy: 0.9447 - val_loss: 0.2335 - val_sparse_categorical_accuracy: 0.9355\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.1663 - sparse_categorical_accuracy: 0.9509 - val_loss: 0.2280 - val_sparse_categorical_accuracy: 0.9441\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.1598 - sparse_categorical_accuracy: 0.9508 - val_loss: 0.2174 - val_sparse_categorical_accuracy: 0.9433\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.1486 - sparse_categorical_accuracy: 0.9547 - val_loss: 0.2446 - val_sparse_categorical_accuracy: 0.9355\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1457 - sparse_categorical_accuracy: 0.9545 - val_loss: 0.2124 - val_sparse_categorical_accuracy: 0.9402\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1341 - sparse_categorical_accuracy: 0.9597 - val_loss: 0.2096 - val_sparse_categorical_accuracy: 0.9402\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.1271 - sparse_categorical_accuracy: 0.9595 - val_loss: 0.2197 - val_sparse_categorical_accuracy: 0.9367\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1153 - sparse_categorical_accuracy: 0.9640 - val_loss: 0.2028 - val_sparse_categorical_accuracy: 0.9437\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1115 - sparse_categorical_accuracy: 0.9643 - val_loss: 0.2363 - val_sparse_categorical_accuracy: 0.9332\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.1088 - sparse_categorical_accuracy: 0.9652 - val_loss: 0.2266 - val_sparse_categorical_accuracy: 0.9421\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0974 - sparse_categorical_accuracy: 0.9690 - val_loss: 0.2552 - val_sparse_categorical_accuracy: 0.9301\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0945 - sparse_categorical_accuracy: 0.9685 - val_loss: 0.2385 - val_sparse_categorical_accuracy: 0.9433\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0893 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.2441 - val_sparse_categorical_accuracy: 0.9406\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.0870 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.2344 - val_sparse_categorical_accuracy: 0.9437\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0826 - sparse_categorical_accuracy: 0.9735 - val_loss: 0.2336 - val_sparse_categorical_accuracy: 0.9452\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0801 - sparse_categorical_accuracy: 0.9747 - val_loss: 0.2590 - val_sparse_categorical_accuracy: 0.9449\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.0751 - sparse_categorical_accuracy: 0.9752 - val_loss: 0.2595 - val_sparse_categorical_accuracy: 0.9433\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0775 - sparse_categorical_accuracy: 0.9744 - val_loss: 0.2494 - val_sparse_categorical_accuracy: 0.9414\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0738 - sparse_categorical_accuracy: 0.9745 - val_loss: 0.2449 - val_sparse_categorical_accuracy: 0.9483\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0673 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.2656 - val_sparse_categorical_accuracy: 0.9476\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0679 - sparse_categorical_accuracy: 0.9782 - val_loss: 0.2508 - val_sparse_categorical_accuracy: 0.9480\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0621 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.2780 - val_sparse_categorical_accuracy: 0.9394\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.0646 - sparse_categorical_accuracy: 0.9788 - val_loss: 0.2722 - val_sparse_categorical_accuracy: 0.9480\n",
            "199/199 [==============================] - 1s 4ms/step - loss: 0.2636 - sparse_categorical_accuracy: 0.9439\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.263556569814682, 0.9438574314117432]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "VINyhKqw8Oq5"
      }
    }
  ]
}