{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_pamap2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM model for Human Activity Recognition**\n",
        "\n",
        "\n",
        "Experiements on [Pamap2](https://archive.ics.uci.edu/ml/datasets/pamap2+physical+activity+monitoring) dataset using different combinations of  *with/without x temporal and/or spatial attention x 1 or 2 LSTM layer(s)*\n"
      ],
      "metadata": {
        "id": "-hUwKQBBY40r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSzZmQw9QLlv",
        "outputId": "09eff22f-1e23-4a7c-aea3-f7699d796dba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml h5py  # Required to save models in HDF5 format\n",
        "!pip install -q tensorflow-addons\n",
        "!pip install keras\n",
        "!pip install pyts\n"
      ],
      "metadata": {
        "id": "UAFxJj4VR7Vf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6f3f2ce-57af-4e99-9526-f41fe6560045"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyts in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from pyts) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.5 in /usr/local/lib/python3.7/dist-packages (from pyts) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from pyts) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pyts) (1.7.3)\n",
            "Requirement already satisfied: numba>=0.48.0 in /usr/local/lib/python3.7/dist-packages (from pyts) (0.56.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts) (0.39.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts) (4.12.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->pyts) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.48.0->pyts) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.48.0->pyts) (3.8.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/Debarshi-Bhattacharya/Ensem_HAR/blob/9d7769f34258185c56feb7c34f6059e07469030f/Implementation_on_PAMAP2/datapreprocessing.ipynb\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import h5py\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "'''\n",
        "0: 'transient', 1: 'lying', 2: 'sitting', 3: 'standing', 4: 'walking', 5: 'running', 6: 'cycling', 7: 'Nordic_walking', 9: 'watching_TV', \n",
        "10: 'computer_work', 11: 'car driving', 12: 'ascending_stairs', 13: 'descending_stairs', 16: 'vacuum_cleaning', 17: 'ironing', \n",
        "18: 'folding_laundry', 19: 'house_cleaning', 20: 'playing_soccer', 24: 'rope_jumping'\n",
        "'''\n",
        "\n",
        "def read_files():\n",
        "    list_of_files = ['Protocol/subject101.dat',\n",
        "                     'Protocol/subject102.dat',\n",
        "                     'Protocol/subject103.dat',\n",
        "                     'Protocol/subject104.dat',\n",
        "                     'Protocol/subject105.dat',\n",
        "                     'Protocol/subject106.dat',\n",
        "                     'Protocol/subject107.dat',\n",
        "                     'Protocol/subject108.dat',\n",
        "                     'Protocol/subject109.dat']\n",
        "    \n",
        "    subjectID = [1,2,3,4,5,6,7,8,9]\n",
        "    \n",
        "    # there are 54 columns in the data files\n",
        "    colNames = [\"timestamp\", \"activityID\",\"heartrate\"] # 1, 2, 3\n",
        "    IMUhand = ['handTemperature', \n",
        "               'handAcc16_1', 'handAcc16_2', 'handAcc16_3', \n",
        "               'handAcc6_1', 'handAcc6_2', 'handAcc6_3', \n",
        "               'handGyro1', 'handGyro2', 'handGyro3', \n",
        "               'handMagne1', 'handMagne2', 'handMagne3',\n",
        "               'handOrientation1', 'handOrientation2', 'handOrientation3', 'handOrientation4'] # 4-20\n",
        "    IMUchest = ['chestTemperature', \n",
        "               'chestAcc16_1', 'chestAcc16_2', 'chestAcc16_3', \n",
        "               'chestAcc6_1', 'chestAcc6_2', 'chestAcc6_3', \n",
        "               'chestGyro1', 'chestGyro2', 'chestGyro3', \n",
        "               'chestMagne1', 'chestMagne2', 'chestMagne3',\n",
        "               'chestOrientation1', 'chestOrientation2', 'chestOrientation3', 'chestOrientation4'] # 21-37\n",
        "    IMUankle = ['ankleTemperature', \n",
        "               'ankleAcc16_1', 'ankleAcc16_2', 'ankleAcc16_3', \n",
        "               'ankleAcc6_1', 'ankleAcc6_2', 'ankleAcc6_3', \n",
        "               'ankleGyro1', 'ankleGyro2', 'ankleGyro3', \n",
        "               'ankleMagne1', 'ankleMagne2', 'ankleMagne3',\n",
        "               'ankleOrientation1', 'ankleOrientation2', 'ankleOrientation3', 'ankleOrientation4'] # 38-54\n",
        "    \n",
        "    columns = colNames + IMUhand + IMUchest + IMUankle\n",
        "    \n",
        "    dataCollection = pd.DataFrame()\n",
        "\n",
        "    for file in list_of_files:\n",
        "        print(file)\n",
        "        procData = pd.read_table(file, header=None, sep='\\s+')\n",
        "        procData.columns = columns\n",
        "        dataCollection = dataCollection.append(procData, ignore_index=True) \n",
        "        \n",
        "    dataCollection.reset_index(drop=True, inplace=True)\n",
        "    \n",
        "    return dataCollection\n",
        "\n",
        "data = read_files()\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "YbmYrB20AkyI",
        "outputId": "29350628-a0c2-423c-e7f1-22fcec13bb59"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Protocol/subject101.dat\n",
            "Protocol/subject102.dat\n",
            "Protocol/subject103.dat\n",
            "Protocol/subject104.dat\n",
            "Protocol/subject105.dat\n",
            "Protocol/subject106.dat\n",
            "Protocol/subject107.dat\n",
            "Protocol/subject108.dat\n",
            "Protocol/subject109.dat\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   timestamp  activityID  heartrate  handTemperature  handAcc16_1  \\\n",
              "0       8.38           0      104.0             30.0      2.37223   \n",
              "1       8.39           0        NaN             30.0      2.18837   \n",
              "2       8.40           0        NaN             30.0      2.37357   \n",
              "3       8.41           0        NaN             30.0      2.07473   \n",
              "4       8.42           0        NaN             30.0      2.22936   \n",
              "\n",
              "   handAcc16_2  handAcc16_3  handAcc6_1  handAcc6_2  handAcc6_3  ...  \\\n",
              "0      8.60074      3.51048     2.43954     8.76165     3.35465  ...   \n",
              "1      8.56560      3.66179     2.39494     8.55081     3.64207  ...   \n",
              "2      8.60107      3.54898     2.30514     8.53644     3.73280  ...   \n",
              "3      8.52853      3.66021     2.33528     8.53622     3.73277  ...   \n",
              "4      8.83122      3.70000     2.23055     8.59741     3.76295  ...   \n",
              "\n",
              "   ankleGyro1  ankleGyro2  ankleGyro3  ankleMagne1  ankleMagne2  ankleMagne3  \\\n",
              "0    0.008300    0.009250   -0.017580     -61.1888     -38.9599     -58.1438   \n",
              "1   -0.006577   -0.004638    0.000368     -59.8479     -38.8919     -58.5253   \n",
              "2    0.003014    0.000148    0.022495     -60.7361     -39.4138     -58.3999   \n",
              "3    0.003175   -0.020301    0.011275     -60.4091     -38.7635     -58.3956   \n",
              "4    0.012698   -0.014303   -0.002823     -61.5199     -39.3879     -58.2694   \n",
              "\n",
              "   ankleOrientation1  ankleOrientation2  ankleOrientation3  ankleOrientation4  \n",
              "0                1.0                0.0                0.0                0.0  \n",
              "1                1.0                0.0                0.0                0.0  \n",
              "2                1.0                0.0                0.0                0.0  \n",
              "3                1.0                0.0                0.0                0.0  \n",
              "4                1.0                0.0                0.0                0.0  \n",
              "\n",
              "[5 rows x 54 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3cfc07ac-742b-489a-bb4a-141036121c2b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>activityID</th>\n",
              "      <th>heartrate</th>\n",
              "      <th>handTemperature</th>\n",
              "      <th>handAcc16_1</th>\n",
              "      <th>handAcc16_2</th>\n",
              "      <th>handAcc16_3</th>\n",
              "      <th>handAcc6_1</th>\n",
              "      <th>handAcc6_2</th>\n",
              "      <th>handAcc6_3</th>\n",
              "      <th>...</th>\n",
              "      <th>ankleGyro1</th>\n",
              "      <th>ankleGyro2</th>\n",
              "      <th>ankleGyro3</th>\n",
              "      <th>ankleMagne1</th>\n",
              "      <th>ankleMagne2</th>\n",
              "      <th>ankleMagne3</th>\n",
              "      <th>ankleOrientation1</th>\n",
              "      <th>ankleOrientation2</th>\n",
              "      <th>ankleOrientation3</th>\n",
              "      <th>ankleOrientation4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.38</td>\n",
              "      <td>0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>2.37223</td>\n",
              "      <td>8.60074</td>\n",
              "      <td>3.51048</td>\n",
              "      <td>2.43954</td>\n",
              "      <td>8.76165</td>\n",
              "      <td>3.35465</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008300</td>\n",
              "      <td>0.009250</td>\n",
              "      <td>-0.017580</td>\n",
              "      <td>-61.1888</td>\n",
              "      <td>-38.9599</td>\n",
              "      <td>-58.1438</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.39</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.0</td>\n",
              "      <td>2.18837</td>\n",
              "      <td>8.56560</td>\n",
              "      <td>3.66179</td>\n",
              "      <td>2.39494</td>\n",
              "      <td>8.55081</td>\n",
              "      <td>3.64207</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.006577</td>\n",
              "      <td>-0.004638</td>\n",
              "      <td>0.000368</td>\n",
              "      <td>-59.8479</td>\n",
              "      <td>-38.8919</td>\n",
              "      <td>-58.5253</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.40</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.0</td>\n",
              "      <td>2.37357</td>\n",
              "      <td>8.60107</td>\n",
              "      <td>3.54898</td>\n",
              "      <td>2.30514</td>\n",
              "      <td>8.53644</td>\n",
              "      <td>3.73280</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003014</td>\n",
              "      <td>0.000148</td>\n",
              "      <td>0.022495</td>\n",
              "      <td>-60.7361</td>\n",
              "      <td>-39.4138</td>\n",
              "      <td>-58.3999</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.41</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.0</td>\n",
              "      <td>2.07473</td>\n",
              "      <td>8.52853</td>\n",
              "      <td>3.66021</td>\n",
              "      <td>2.33528</td>\n",
              "      <td>8.53622</td>\n",
              "      <td>3.73277</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003175</td>\n",
              "      <td>-0.020301</td>\n",
              "      <td>0.011275</td>\n",
              "      <td>-60.4091</td>\n",
              "      <td>-38.7635</td>\n",
              "      <td>-58.3956</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.42</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.0</td>\n",
              "      <td>2.22936</td>\n",
              "      <td>8.83122</td>\n",
              "      <td>3.70000</td>\n",
              "      <td>2.23055</td>\n",
              "      <td>8.59741</td>\n",
              "      <td>3.76295</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012698</td>\n",
              "      <td>-0.014303</td>\n",
              "      <td>-0.002823</td>\n",
              "      <td>-61.5199</td>\n",
              "      <td>-39.3879</td>\n",
              "      <td>-58.2694</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 54 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cfc07ac-742b-489a-bb4a-141036121c2b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3cfc07ac-742b-489a-bb4a-141036121c2b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3cfc07ac-742b-489a-bb4a-141036121c2b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dataCleaning(dataCollection):\n",
        "    dataCollection = dataCollection.drop(['timestamp', 'handOrientation1', 'handOrientation2', 'handOrientation3', 'handOrientation4',\n",
        "                                         'chestOrientation1', 'chestOrientation2', 'chestOrientation3', 'chestOrientation4',\n",
        "                                         'ankleOrientation1', 'ankleOrientation2', 'ankleOrientation3', 'ankleOrientation4'],\n",
        "                                         axis = 1)  # removal of orientation columns as they are not needed\n",
        "    dataCollection = dataCollection.drop(dataCollection[dataCollection.activityID == 0].index) # removal of any row of activity 0 as it is transient activity which it is not used\n",
        "    dataCollection = dataCollection.apply(pd.to_numeric, errors = 'coerce') # removal of non numeric data in cells\n",
        "    dataCollection = dataCollection.drop(['heartrate'], axis = 1)\n",
        "    dataCollection = dataCollection.dropna()\n",
        "\n",
        "    dataCollection = dataCollection.drop(['handTemperature', 'chestTemperature', 'ankleTemperature'],\n",
        "                                         axis = 1)  # removal of temperature columns as they are not needed - sumeyye\n",
        "    print(\"data cleaned!\")\n",
        "    return dataCollection\n",
        "\n",
        "cleaned_data = dataCleaning(data)\n",
        "print(cleaned_data['activityID'].value_counts())\n",
        "cleaned_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "IGCabJ_FAnEJ",
        "outputId": "d8176b9b-d244-4b81-bd44-d61059838d1e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data cleaned!\n",
            "17    237902\n",
            "4     229709\n",
            "1     192290\n",
            "3     188984\n",
            "2     184645\n",
            "7     184444\n",
            "16    174976\n",
            "6     163302\n",
            "12    117094\n",
            "13    104865\n",
            "5      95641\n",
            "24     47579\n",
            "Name: activityID, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      activityID  handAcc16_1  handAcc16_2  handAcc16_3  handAcc6_1  \\\n",
              "2928           1      2.21530      8.27915      5.58753     2.24689   \n",
              "2929           1      2.29196      7.67288      5.74467     2.27373   \n",
              "2930           1      2.29090      7.14240      5.82342     2.26966   \n",
              "2931           1      2.21800      7.14365      5.89930     2.22177   \n",
              "2932           1      2.30106      7.25857      6.09259     2.20720   \n",
              "\n",
              "      handAcc6_2  handAcc6_3  handGyro1  handGyro2  handGyro3  ...  \\\n",
              "2928     8.55387     5.77143  -0.004750   0.037579  -0.011145  ...   \n",
              "2929     8.14592     5.78739  -0.171710   0.025479  -0.009538  ...   \n",
              "2930     7.66268     5.78846  -0.238241   0.011214   0.000831  ...   \n",
              "2931     7.25535     5.88000  -0.192912   0.019053   0.013374  ...   \n",
              "2932     7.24042     5.95555  -0.069961  -0.018328   0.004582  ...   \n",
              "\n",
              "      ankleAcc16_3  ankleAcc6_1  ankleAcc6_2  ankleAcc6_3  ankleGyro1  \\\n",
              "2928      0.095156      9.63162     -1.76757     0.265761    0.002908   \n",
              "2929     -0.020804      9.58649     -1.75247     0.250816    0.020882   \n",
              "2930     -0.059173      9.60196     -1.73721     0.356632   -0.035392   \n",
              "2931      0.094385      9.58674     -1.78264     0.311453   -0.032514   \n",
              "2932      0.095775      9.64677     -1.75240     0.295902    0.001351   \n",
              "\n",
              "      ankleGyro2  ankleGyro3  ankleMagne1  ankleMagne2  ankleMagne3  \n",
              "2928   -0.027714    0.001752     -61.1081     -36.8636     -58.3696  \n",
              "2929    0.000945    0.006007     -60.8916     -36.3197     -58.3656  \n",
              "2930   -0.052422   -0.004882     -60.3407     -35.7842     -58.6119  \n",
              "2931   -0.018844    0.026950     -60.7646     -37.1028     -57.8799  \n",
              "2932   -0.048878   -0.006328     -60.2040     -37.1225     -57.8847  \n",
              "\n",
              "[5 rows x 37 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79d9f72d-c3ea-433b-9582-2df47cfc1f57\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>activityID</th>\n",
              "      <th>handAcc16_1</th>\n",
              "      <th>handAcc16_2</th>\n",
              "      <th>handAcc16_3</th>\n",
              "      <th>handAcc6_1</th>\n",
              "      <th>handAcc6_2</th>\n",
              "      <th>handAcc6_3</th>\n",
              "      <th>handGyro1</th>\n",
              "      <th>handGyro2</th>\n",
              "      <th>handGyro3</th>\n",
              "      <th>...</th>\n",
              "      <th>ankleAcc16_3</th>\n",
              "      <th>ankleAcc6_1</th>\n",
              "      <th>ankleAcc6_2</th>\n",
              "      <th>ankleAcc6_3</th>\n",
              "      <th>ankleGyro1</th>\n",
              "      <th>ankleGyro2</th>\n",
              "      <th>ankleGyro3</th>\n",
              "      <th>ankleMagne1</th>\n",
              "      <th>ankleMagne2</th>\n",
              "      <th>ankleMagne3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2928</th>\n",
              "      <td>1</td>\n",
              "      <td>2.21530</td>\n",
              "      <td>8.27915</td>\n",
              "      <td>5.58753</td>\n",
              "      <td>2.24689</td>\n",
              "      <td>8.55387</td>\n",
              "      <td>5.77143</td>\n",
              "      <td>-0.004750</td>\n",
              "      <td>0.037579</td>\n",
              "      <td>-0.011145</td>\n",
              "      <td>...</td>\n",
              "      <td>0.095156</td>\n",
              "      <td>9.63162</td>\n",
              "      <td>-1.76757</td>\n",
              "      <td>0.265761</td>\n",
              "      <td>0.002908</td>\n",
              "      <td>-0.027714</td>\n",
              "      <td>0.001752</td>\n",
              "      <td>-61.1081</td>\n",
              "      <td>-36.8636</td>\n",
              "      <td>-58.3696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2929</th>\n",
              "      <td>1</td>\n",
              "      <td>2.29196</td>\n",
              "      <td>7.67288</td>\n",
              "      <td>5.74467</td>\n",
              "      <td>2.27373</td>\n",
              "      <td>8.14592</td>\n",
              "      <td>5.78739</td>\n",
              "      <td>-0.171710</td>\n",
              "      <td>0.025479</td>\n",
              "      <td>-0.009538</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.020804</td>\n",
              "      <td>9.58649</td>\n",
              "      <td>-1.75247</td>\n",
              "      <td>0.250816</td>\n",
              "      <td>0.020882</td>\n",
              "      <td>0.000945</td>\n",
              "      <td>0.006007</td>\n",
              "      <td>-60.8916</td>\n",
              "      <td>-36.3197</td>\n",
              "      <td>-58.3656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2930</th>\n",
              "      <td>1</td>\n",
              "      <td>2.29090</td>\n",
              "      <td>7.14240</td>\n",
              "      <td>5.82342</td>\n",
              "      <td>2.26966</td>\n",
              "      <td>7.66268</td>\n",
              "      <td>5.78846</td>\n",
              "      <td>-0.238241</td>\n",
              "      <td>0.011214</td>\n",
              "      <td>0.000831</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.059173</td>\n",
              "      <td>9.60196</td>\n",
              "      <td>-1.73721</td>\n",
              "      <td>0.356632</td>\n",
              "      <td>-0.035392</td>\n",
              "      <td>-0.052422</td>\n",
              "      <td>-0.004882</td>\n",
              "      <td>-60.3407</td>\n",
              "      <td>-35.7842</td>\n",
              "      <td>-58.6119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2931</th>\n",
              "      <td>1</td>\n",
              "      <td>2.21800</td>\n",
              "      <td>7.14365</td>\n",
              "      <td>5.89930</td>\n",
              "      <td>2.22177</td>\n",
              "      <td>7.25535</td>\n",
              "      <td>5.88000</td>\n",
              "      <td>-0.192912</td>\n",
              "      <td>0.019053</td>\n",
              "      <td>0.013374</td>\n",
              "      <td>...</td>\n",
              "      <td>0.094385</td>\n",
              "      <td>9.58674</td>\n",
              "      <td>-1.78264</td>\n",
              "      <td>0.311453</td>\n",
              "      <td>-0.032514</td>\n",
              "      <td>-0.018844</td>\n",
              "      <td>0.026950</td>\n",
              "      <td>-60.7646</td>\n",
              "      <td>-37.1028</td>\n",
              "      <td>-57.8799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2932</th>\n",
              "      <td>1</td>\n",
              "      <td>2.30106</td>\n",
              "      <td>7.25857</td>\n",
              "      <td>6.09259</td>\n",
              "      <td>2.20720</td>\n",
              "      <td>7.24042</td>\n",
              "      <td>5.95555</td>\n",
              "      <td>-0.069961</td>\n",
              "      <td>-0.018328</td>\n",
              "      <td>0.004582</td>\n",
              "      <td>...</td>\n",
              "      <td>0.095775</td>\n",
              "      <td>9.64677</td>\n",
              "      <td>-1.75240</td>\n",
              "      <td>0.295902</td>\n",
              "      <td>0.001351</td>\n",
              "      <td>-0.048878</td>\n",
              "      <td>-0.006328</td>\n",
              "      <td>-60.2040</td>\n",
              "      <td>-37.1225</td>\n",
              "      <td>-57.8847</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 37 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79d9f72d-c3ea-433b-9582-2df47cfc1f57')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-79d9f72d-c3ea-433b-9582-2df47cfc1f57 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-79d9f72d-c3ea-433b-9582-2df47cfc1f57');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reset_label(dataCollection): \n",
        "    # Convert original labels {1, 2, 3, 4, 5, 6, 7, 12, 13, 16, 17, 24} to new labels. \n",
        "    mapping = {24:0,1:1,2:2,3:3,4:4,5:5,6:6,7:7,12:8,13:9,16:10,17:11} # old activity Id to new activity Id \n",
        "    for i in [24,12,13,16,17]:\n",
        "        dataCollection.loc[dataCollection.activityID == i, 'activityID'] = mapping[i]\n",
        "\n",
        "    return dataCollection\n",
        "data_reset = reset_label(cleaned_data)  \n",
        "data_reset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "g1XksDiFApxb",
        "outputId": "519ff6ac-a2f5-4934-a832-4d581d5bf736"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      activityID  handAcc16_1  handAcc16_2  handAcc16_3  handAcc6_1  \\\n",
              "2928           1      2.21530      8.27915      5.58753     2.24689   \n",
              "2929           1      2.29196      7.67288      5.74467     2.27373   \n",
              "2930           1      2.29090      7.14240      5.82342     2.26966   \n",
              "2931           1      2.21800      7.14365      5.89930     2.22177   \n",
              "2932           1      2.30106      7.25857      6.09259     2.20720   \n",
              "\n",
              "      handAcc6_2  handAcc6_3  handGyro1  handGyro2  handGyro3  ...  \\\n",
              "2928     8.55387     5.77143  -0.004750   0.037579  -0.011145  ...   \n",
              "2929     8.14592     5.78739  -0.171710   0.025479  -0.009538  ...   \n",
              "2930     7.66268     5.78846  -0.238241   0.011214   0.000831  ...   \n",
              "2931     7.25535     5.88000  -0.192912   0.019053   0.013374  ...   \n",
              "2932     7.24042     5.95555  -0.069961  -0.018328   0.004582  ...   \n",
              "\n",
              "      ankleAcc16_3  ankleAcc6_1  ankleAcc6_2  ankleAcc6_3  ankleGyro1  \\\n",
              "2928      0.095156      9.63162     -1.76757     0.265761    0.002908   \n",
              "2929     -0.020804      9.58649     -1.75247     0.250816    0.020882   \n",
              "2930     -0.059173      9.60196     -1.73721     0.356632   -0.035392   \n",
              "2931      0.094385      9.58674     -1.78264     0.311453   -0.032514   \n",
              "2932      0.095775      9.64677     -1.75240     0.295902    0.001351   \n",
              "\n",
              "      ankleGyro2  ankleGyro3  ankleMagne1  ankleMagne2  ankleMagne3  \n",
              "2928   -0.027714    0.001752     -61.1081     -36.8636     -58.3696  \n",
              "2929    0.000945    0.006007     -60.8916     -36.3197     -58.3656  \n",
              "2930   -0.052422   -0.004882     -60.3407     -35.7842     -58.6119  \n",
              "2931   -0.018844    0.026950     -60.7646     -37.1028     -57.8799  \n",
              "2932   -0.048878   -0.006328     -60.2040     -37.1225     -57.8847  \n",
              "\n",
              "[5 rows x 37 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72da69b0-5794-4c5a-83d5-03ca826c5a06\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>activityID</th>\n",
              "      <th>handAcc16_1</th>\n",
              "      <th>handAcc16_2</th>\n",
              "      <th>handAcc16_3</th>\n",
              "      <th>handAcc6_1</th>\n",
              "      <th>handAcc6_2</th>\n",
              "      <th>handAcc6_3</th>\n",
              "      <th>handGyro1</th>\n",
              "      <th>handGyro2</th>\n",
              "      <th>handGyro3</th>\n",
              "      <th>...</th>\n",
              "      <th>ankleAcc16_3</th>\n",
              "      <th>ankleAcc6_1</th>\n",
              "      <th>ankleAcc6_2</th>\n",
              "      <th>ankleAcc6_3</th>\n",
              "      <th>ankleGyro1</th>\n",
              "      <th>ankleGyro2</th>\n",
              "      <th>ankleGyro3</th>\n",
              "      <th>ankleMagne1</th>\n",
              "      <th>ankleMagne2</th>\n",
              "      <th>ankleMagne3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2928</th>\n",
              "      <td>1</td>\n",
              "      <td>2.21530</td>\n",
              "      <td>8.27915</td>\n",
              "      <td>5.58753</td>\n",
              "      <td>2.24689</td>\n",
              "      <td>8.55387</td>\n",
              "      <td>5.77143</td>\n",
              "      <td>-0.004750</td>\n",
              "      <td>0.037579</td>\n",
              "      <td>-0.011145</td>\n",
              "      <td>...</td>\n",
              "      <td>0.095156</td>\n",
              "      <td>9.63162</td>\n",
              "      <td>-1.76757</td>\n",
              "      <td>0.265761</td>\n",
              "      <td>0.002908</td>\n",
              "      <td>-0.027714</td>\n",
              "      <td>0.001752</td>\n",
              "      <td>-61.1081</td>\n",
              "      <td>-36.8636</td>\n",
              "      <td>-58.3696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2929</th>\n",
              "      <td>1</td>\n",
              "      <td>2.29196</td>\n",
              "      <td>7.67288</td>\n",
              "      <td>5.74467</td>\n",
              "      <td>2.27373</td>\n",
              "      <td>8.14592</td>\n",
              "      <td>5.78739</td>\n",
              "      <td>-0.171710</td>\n",
              "      <td>0.025479</td>\n",
              "      <td>-0.009538</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.020804</td>\n",
              "      <td>9.58649</td>\n",
              "      <td>-1.75247</td>\n",
              "      <td>0.250816</td>\n",
              "      <td>0.020882</td>\n",
              "      <td>0.000945</td>\n",
              "      <td>0.006007</td>\n",
              "      <td>-60.8916</td>\n",
              "      <td>-36.3197</td>\n",
              "      <td>-58.3656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2930</th>\n",
              "      <td>1</td>\n",
              "      <td>2.29090</td>\n",
              "      <td>7.14240</td>\n",
              "      <td>5.82342</td>\n",
              "      <td>2.26966</td>\n",
              "      <td>7.66268</td>\n",
              "      <td>5.78846</td>\n",
              "      <td>-0.238241</td>\n",
              "      <td>0.011214</td>\n",
              "      <td>0.000831</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.059173</td>\n",
              "      <td>9.60196</td>\n",
              "      <td>-1.73721</td>\n",
              "      <td>0.356632</td>\n",
              "      <td>-0.035392</td>\n",
              "      <td>-0.052422</td>\n",
              "      <td>-0.004882</td>\n",
              "      <td>-60.3407</td>\n",
              "      <td>-35.7842</td>\n",
              "      <td>-58.6119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2931</th>\n",
              "      <td>1</td>\n",
              "      <td>2.21800</td>\n",
              "      <td>7.14365</td>\n",
              "      <td>5.89930</td>\n",
              "      <td>2.22177</td>\n",
              "      <td>7.25535</td>\n",
              "      <td>5.88000</td>\n",
              "      <td>-0.192912</td>\n",
              "      <td>0.019053</td>\n",
              "      <td>0.013374</td>\n",
              "      <td>...</td>\n",
              "      <td>0.094385</td>\n",
              "      <td>9.58674</td>\n",
              "      <td>-1.78264</td>\n",
              "      <td>0.311453</td>\n",
              "      <td>-0.032514</td>\n",
              "      <td>-0.018844</td>\n",
              "      <td>0.026950</td>\n",
              "      <td>-60.7646</td>\n",
              "      <td>-37.1028</td>\n",
              "      <td>-57.8799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2932</th>\n",
              "      <td>1</td>\n",
              "      <td>2.30106</td>\n",
              "      <td>7.25857</td>\n",
              "      <td>6.09259</td>\n",
              "      <td>2.20720</td>\n",
              "      <td>7.24042</td>\n",
              "      <td>5.95555</td>\n",
              "      <td>-0.069961</td>\n",
              "      <td>-0.018328</td>\n",
              "      <td>0.004582</td>\n",
              "      <td>...</td>\n",
              "      <td>0.095775</td>\n",
              "      <td>9.64677</td>\n",
              "      <td>-1.75240</td>\n",
              "      <td>0.295902</td>\n",
              "      <td>0.001351</td>\n",
              "      <td>-0.048878</td>\n",
              "      <td>-0.006328</td>\n",
              "      <td>-60.2040</td>\n",
              "      <td>-37.1225</td>\n",
              "      <td>-57.8847</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 37 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72da69b0-5794-4c5a-83d5-03ca826c5a06')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72da69b0-5794-4c5a-83d5-03ca826c5a06 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72da69b0-5794-4c5a-83d5-03ca826c5a06');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=data_reset.drop(['activityID'],axis=1)\n",
        "y=data_reset['activityID']\n",
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "2LRpqMLWtvX6",
        "outputId": "27731cea-ae16-4aee-8f35-97d54d471420"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      handAcc16_1  handAcc16_2  handAcc16_3  handAcc6_1  handAcc6_2  \\\n",
              "2928      2.21530      8.27915      5.58753     2.24689     8.55387   \n",
              "2929      2.29196      7.67288      5.74467     2.27373     8.14592   \n",
              "2930      2.29090      7.14240      5.82342     2.26966     7.66268   \n",
              "2931      2.21800      7.14365      5.89930     2.22177     7.25535   \n",
              "2932      2.30106      7.25857      6.09259     2.20720     7.24042   \n",
              "\n",
              "      handAcc6_3  handGyro1  handGyro2  handGyro3  handMagne1  ...  \\\n",
              "2928     5.77143  -0.004750   0.037579  -0.011145     8.93200  ...   \n",
              "2929     5.78739  -0.171710   0.025479  -0.009538     9.58300  ...   \n",
              "2930     5.78846  -0.238241   0.011214   0.000831     9.05516  ...   \n",
              "2931     5.88000  -0.192912   0.019053   0.013374     9.92698  ...   \n",
              "2932     5.95555  -0.069961  -0.018328   0.004582     9.15626  ...   \n",
              "\n",
              "      ankleAcc16_3  ankleAcc6_1  ankleAcc6_2  ankleAcc6_3  ankleGyro1  \\\n",
              "2928      0.095156      9.63162     -1.76757     0.265761    0.002908   \n",
              "2929     -0.020804      9.58649     -1.75247     0.250816    0.020882   \n",
              "2930     -0.059173      9.60196     -1.73721     0.356632   -0.035392   \n",
              "2931      0.094385      9.58674     -1.78264     0.311453   -0.032514   \n",
              "2932      0.095775      9.64677     -1.75240     0.295902    0.001351   \n",
              "\n",
              "      ankleGyro2  ankleGyro3  ankleMagne1  ankleMagne2  ankleMagne3  \n",
              "2928   -0.027714    0.001752     -61.1081     -36.8636     -58.3696  \n",
              "2929    0.000945    0.006007     -60.8916     -36.3197     -58.3656  \n",
              "2930   -0.052422   -0.004882     -60.3407     -35.7842     -58.6119  \n",
              "2931   -0.018844    0.026950     -60.7646     -37.1028     -57.8799  \n",
              "2932   -0.048878   -0.006328     -60.2040     -37.1225     -57.8847  \n",
              "\n",
              "[5 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eef0d047-fa43-4eeb-80da-bb1b8ca3fdc0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>handAcc16_1</th>\n",
              "      <th>handAcc16_2</th>\n",
              "      <th>handAcc16_3</th>\n",
              "      <th>handAcc6_1</th>\n",
              "      <th>handAcc6_2</th>\n",
              "      <th>handAcc6_3</th>\n",
              "      <th>handGyro1</th>\n",
              "      <th>handGyro2</th>\n",
              "      <th>handGyro3</th>\n",
              "      <th>handMagne1</th>\n",
              "      <th>...</th>\n",
              "      <th>ankleAcc16_3</th>\n",
              "      <th>ankleAcc6_1</th>\n",
              "      <th>ankleAcc6_2</th>\n",
              "      <th>ankleAcc6_3</th>\n",
              "      <th>ankleGyro1</th>\n",
              "      <th>ankleGyro2</th>\n",
              "      <th>ankleGyro3</th>\n",
              "      <th>ankleMagne1</th>\n",
              "      <th>ankleMagne2</th>\n",
              "      <th>ankleMagne3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2928</th>\n",
              "      <td>2.21530</td>\n",
              "      <td>8.27915</td>\n",
              "      <td>5.58753</td>\n",
              "      <td>2.24689</td>\n",
              "      <td>8.55387</td>\n",
              "      <td>5.77143</td>\n",
              "      <td>-0.004750</td>\n",
              "      <td>0.037579</td>\n",
              "      <td>-0.011145</td>\n",
              "      <td>8.93200</td>\n",
              "      <td>...</td>\n",
              "      <td>0.095156</td>\n",
              "      <td>9.63162</td>\n",
              "      <td>-1.76757</td>\n",
              "      <td>0.265761</td>\n",
              "      <td>0.002908</td>\n",
              "      <td>-0.027714</td>\n",
              "      <td>0.001752</td>\n",
              "      <td>-61.1081</td>\n",
              "      <td>-36.8636</td>\n",
              "      <td>-58.3696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2929</th>\n",
              "      <td>2.29196</td>\n",
              "      <td>7.67288</td>\n",
              "      <td>5.74467</td>\n",
              "      <td>2.27373</td>\n",
              "      <td>8.14592</td>\n",
              "      <td>5.78739</td>\n",
              "      <td>-0.171710</td>\n",
              "      <td>0.025479</td>\n",
              "      <td>-0.009538</td>\n",
              "      <td>9.58300</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.020804</td>\n",
              "      <td>9.58649</td>\n",
              "      <td>-1.75247</td>\n",
              "      <td>0.250816</td>\n",
              "      <td>0.020882</td>\n",
              "      <td>0.000945</td>\n",
              "      <td>0.006007</td>\n",
              "      <td>-60.8916</td>\n",
              "      <td>-36.3197</td>\n",
              "      <td>-58.3656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2930</th>\n",
              "      <td>2.29090</td>\n",
              "      <td>7.14240</td>\n",
              "      <td>5.82342</td>\n",
              "      <td>2.26966</td>\n",
              "      <td>7.66268</td>\n",
              "      <td>5.78846</td>\n",
              "      <td>-0.238241</td>\n",
              "      <td>0.011214</td>\n",
              "      <td>0.000831</td>\n",
              "      <td>9.05516</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.059173</td>\n",
              "      <td>9.60196</td>\n",
              "      <td>-1.73721</td>\n",
              "      <td>0.356632</td>\n",
              "      <td>-0.035392</td>\n",
              "      <td>-0.052422</td>\n",
              "      <td>-0.004882</td>\n",
              "      <td>-60.3407</td>\n",
              "      <td>-35.7842</td>\n",
              "      <td>-58.6119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2931</th>\n",
              "      <td>2.21800</td>\n",
              "      <td>7.14365</td>\n",
              "      <td>5.89930</td>\n",
              "      <td>2.22177</td>\n",
              "      <td>7.25535</td>\n",
              "      <td>5.88000</td>\n",
              "      <td>-0.192912</td>\n",
              "      <td>0.019053</td>\n",
              "      <td>0.013374</td>\n",
              "      <td>9.92698</td>\n",
              "      <td>...</td>\n",
              "      <td>0.094385</td>\n",
              "      <td>9.58674</td>\n",
              "      <td>-1.78264</td>\n",
              "      <td>0.311453</td>\n",
              "      <td>-0.032514</td>\n",
              "      <td>-0.018844</td>\n",
              "      <td>0.026950</td>\n",
              "      <td>-60.7646</td>\n",
              "      <td>-37.1028</td>\n",
              "      <td>-57.8799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2932</th>\n",
              "      <td>2.30106</td>\n",
              "      <td>7.25857</td>\n",
              "      <td>6.09259</td>\n",
              "      <td>2.20720</td>\n",
              "      <td>7.24042</td>\n",
              "      <td>5.95555</td>\n",
              "      <td>-0.069961</td>\n",
              "      <td>-0.018328</td>\n",
              "      <td>0.004582</td>\n",
              "      <td>9.15626</td>\n",
              "      <td>...</td>\n",
              "      <td>0.095775</td>\n",
              "      <td>9.64677</td>\n",
              "      <td>-1.75240</td>\n",
              "      <td>0.295902</td>\n",
              "      <td>0.001351</td>\n",
              "      <td>-0.048878</td>\n",
              "      <td>-0.006328</td>\n",
              "      <td>-60.2040</td>\n",
              "      <td>-37.1225</td>\n",
              "      <td>-57.8847</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 36 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eef0d047-fa43-4eeb-80da-bb1b8ca3fdc0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eef0d047-fa43-4eeb-80da-bb1b8ca3fdc0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eef0d047-fa43-4eeb-80da-bb1b8ca3fdc0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scale(df): # minmax scale\n",
        "    features=df.columns[0:X.shape[1]]\n",
        "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "    df[features]=scaler.fit_transform(df[features])\n",
        "    return df\n",
        "\n",
        "X_scaled = scale(X)\n",
        "X_scaled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "fshxU5tnAuRu",
        "outputId": "6c0cb23b-490b-4547-b4f9-65694124005d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      handAcc16_1  handAcc16_2  handAcc16_3  handAcc6_1  handAcc6_2  \\\n",
              "2928     0.417516    -0.133999    -0.174116    0.113009    0.134484   \n",
              "2929     0.418253    -0.138662    -0.172903    0.113480    0.127909   \n",
              "2930     0.418242    -0.142743    -0.172296    0.113408    0.120122   \n",
              "2931     0.417542    -0.142733    -0.171710    0.112568    0.113557   \n",
              "2932     0.418340    -0.141849    -0.170219    0.112313    0.113316   \n",
              "\n",
              "      handAcc6_3  handGyro1  handGyro2  handGyro3  handMagne1  ...  \\\n",
              "2928    0.093285   0.031349  -0.125912  -0.003356   -0.065176  ...   \n",
              "2929    0.093543   0.025227  -0.126503  -0.003244   -0.059784  ...   \n",
              "2930    0.093560   0.022788  -0.127200  -0.002519   -0.064156  ...   \n",
              "2931    0.095039   0.024450  -0.126817  -0.001641   -0.056935  ...   \n",
              "2932    0.096259   0.028958  -0.128644  -0.002256   -0.063319  ...   \n",
              "\n",
              "      ankleAcc16_3  ankleAcc6_1  ankleAcc6_2  ankleAcc6_3  ankleGyro1  \\\n",
              "2928      0.000769     0.143942    -0.029670     0.015502    0.186908   \n",
              "2929      0.000039     0.143204    -0.029426     0.015259    0.187797   \n",
              "2930     -0.000202     0.143457    -0.029180     0.016977    0.185013   \n",
              "2931      0.000764     0.143208    -0.029913     0.016243    0.185156   \n",
              "2932      0.000773     0.144190    -0.029425     0.015991    0.186831   \n",
              "\n",
              "      ankleGyro2  ankleGyro3  ankleMagne1  ankleMagne2  ankleMagne3  \n",
              "2928    0.141361   -0.082024    -0.154691    -0.129512    -0.644683  \n",
              "2929    0.143168   -0.081745    -0.153053    -0.124827    -0.644651  \n",
              "2930    0.139803   -0.082458    -0.148886    -0.120213    -0.646624  \n",
              "2931    0.141920   -0.080374    -0.152093    -0.131573    -0.640759  \n",
              "2932    0.140026   -0.082553    -0.147852    -0.131743    -0.640798  \n",
              "\n",
              "[5 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f33a3f3c-31c8-44a1-8885-49820b25b53f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>handAcc16_1</th>\n",
              "      <th>handAcc16_2</th>\n",
              "      <th>handAcc16_3</th>\n",
              "      <th>handAcc6_1</th>\n",
              "      <th>handAcc6_2</th>\n",
              "      <th>handAcc6_3</th>\n",
              "      <th>handGyro1</th>\n",
              "      <th>handGyro2</th>\n",
              "      <th>handGyro3</th>\n",
              "      <th>handMagne1</th>\n",
              "      <th>...</th>\n",
              "      <th>ankleAcc16_3</th>\n",
              "      <th>ankleAcc6_1</th>\n",
              "      <th>ankleAcc6_2</th>\n",
              "      <th>ankleAcc6_3</th>\n",
              "      <th>ankleGyro1</th>\n",
              "      <th>ankleGyro2</th>\n",
              "      <th>ankleGyro3</th>\n",
              "      <th>ankleMagne1</th>\n",
              "      <th>ankleMagne2</th>\n",
              "      <th>ankleMagne3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2928</th>\n",
              "      <td>0.417516</td>\n",
              "      <td>-0.133999</td>\n",
              "      <td>-0.174116</td>\n",
              "      <td>0.113009</td>\n",
              "      <td>0.134484</td>\n",
              "      <td>0.093285</td>\n",
              "      <td>0.031349</td>\n",
              "      <td>-0.125912</td>\n",
              "      <td>-0.003356</td>\n",
              "      <td>-0.065176</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000769</td>\n",
              "      <td>0.143942</td>\n",
              "      <td>-0.029670</td>\n",
              "      <td>0.015502</td>\n",
              "      <td>0.186908</td>\n",
              "      <td>0.141361</td>\n",
              "      <td>-0.082024</td>\n",
              "      <td>-0.154691</td>\n",
              "      <td>-0.129512</td>\n",
              "      <td>-0.644683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2929</th>\n",
              "      <td>0.418253</td>\n",
              "      <td>-0.138662</td>\n",
              "      <td>-0.172903</td>\n",
              "      <td>0.113480</td>\n",
              "      <td>0.127909</td>\n",
              "      <td>0.093543</td>\n",
              "      <td>0.025227</td>\n",
              "      <td>-0.126503</td>\n",
              "      <td>-0.003244</td>\n",
              "      <td>-0.059784</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>0.143204</td>\n",
              "      <td>-0.029426</td>\n",
              "      <td>0.015259</td>\n",
              "      <td>0.187797</td>\n",
              "      <td>0.143168</td>\n",
              "      <td>-0.081745</td>\n",
              "      <td>-0.153053</td>\n",
              "      <td>-0.124827</td>\n",
              "      <td>-0.644651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2930</th>\n",
              "      <td>0.418242</td>\n",
              "      <td>-0.142743</td>\n",
              "      <td>-0.172296</td>\n",
              "      <td>0.113408</td>\n",
              "      <td>0.120122</td>\n",
              "      <td>0.093560</td>\n",
              "      <td>0.022788</td>\n",
              "      <td>-0.127200</td>\n",
              "      <td>-0.002519</td>\n",
              "      <td>-0.064156</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000202</td>\n",
              "      <td>0.143457</td>\n",
              "      <td>-0.029180</td>\n",
              "      <td>0.016977</td>\n",
              "      <td>0.185013</td>\n",
              "      <td>0.139803</td>\n",
              "      <td>-0.082458</td>\n",
              "      <td>-0.148886</td>\n",
              "      <td>-0.120213</td>\n",
              "      <td>-0.646624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2931</th>\n",
              "      <td>0.417542</td>\n",
              "      <td>-0.142733</td>\n",
              "      <td>-0.171710</td>\n",
              "      <td>0.112568</td>\n",
              "      <td>0.113557</td>\n",
              "      <td>0.095039</td>\n",
              "      <td>0.024450</td>\n",
              "      <td>-0.126817</td>\n",
              "      <td>-0.001641</td>\n",
              "      <td>-0.056935</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000764</td>\n",
              "      <td>0.143208</td>\n",
              "      <td>-0.029913</td>\n",
              "      <td>0.016243</td>\n",
              "      <td>0.185156</td>\n",
              "      <td>0.141920</td>\n",
              "      <td>-0.080374</td>\n",
              "      <td>-0.152093</td>\n",
              "      <td>-0.131573</td>\n",
              "      <td>-0.640759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2932</th>\n",
              "      <td>0.418340</td>\n",
              "      <td>-0.141849</td>\n",
              "      <td>-0.170219</td>\n",
              "      <td>0.112313</td>\n",
              "      <td>0.113316</td>\n",
              "      <td>0.096259</td>\n",
              "      <td>0.028958</td>\n",
              "      <td>-0.128644</td>\n",
              "      <td>-0.002256</td>\n",
              "      <td>-0.063319</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000773</td>\n",
              "      <td>0.144190</td>\n",
              "      <td>-0.029425</td>\n",
              "      <td>0.015991</td>\n",
              "      <td>0.186831</td>\n",
              "      <td>0.140026</td>\n",
              "      <td>-0.082553</td>\n",
              "      <td>-0.147852</td>\n",
              "      <td>-0.131743</td>\n",
              "      <td>-0.640798</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 36 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f33a3f3c-31c8-44a1-8885-49820b25b53f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f33a3f3c-31c8-44a1-8885-49820b25b53f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f33a3f3c-31c8-44a1-8885-49820b25b53f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INITIAL_SAMPLING_RATE = 100 #Hz\n",
        "WINDOW_SIZE = 1 #second\n",
        "\n",
        "SLIDING_WINDOW_LENGTH = INITIAL_SAMPLING_RATE*WINDOW_SIZE\n",
        "\n",
        "def segment_signal(data_x, data_y, window_size): # data is numpy array\n",
        "    X, y = [], []\n",
        "    start, end = 0, 0\n",
        "    while start + window_size - 1 < data_x.shape[0]:\n",
        "        end = start + window_size - 1\n",
        "        # if the frame contains the same activity and from the same object\n",
        "        X.append(data_x[start:(end+1),:])\n",
        "        y.append(data_y[start])\n",
        "        start += window_size #without overlap (for 50% overlap use window_size//2)\n",
        "    return [np.asarray(X), np.asarray(y)]\n",
        "\n",
        "data = segment_signal(X_scaled.to_numpy(), y.to_numpy(), SLIDING_WINDOW_LENGTH)\n",
        "data_x, data_y = data[0], data[1]\n",
        "print(data_x.shape)\n",
        "print(data_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b0PmyPbdiOA",
        "outputId": "5a0f2286-f3b0-4bb8-a439-02174cba1fda"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19214, 100, 36)\n",
            "(19214,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data is reshaped since the input of the network is a 4 dimension tensor\n",
        "data_x = data_x.reshape((-1, data_x.shape[1], data_x.shape[2], 1))\n",
        "print(data_x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUm7q-D7f_vX",
        "outputId": "74609b7b-9f96-49f8-b215-cbcaeed43daf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19214, 100, 36, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/53731141/cifar10-randomize-train-and-test-set\n",
        "def shuffle_train_data(X_train, Y_train): \n",
        "    perm = np.random.permutation(len(Y_train)) \n",
        "    Xtr_shuf = X_train[perm] \n",
        "    Ytr_shuf = Y_train[perm] \n",
        "    return Xtr_shuf, Ytr_shuf \n",
        "X_shuffled, y_shuffled = shuffle_train_data(data_x, data_y) \n",
        "print(X_shuffled.shape) \n",
        "print(y_shuffled.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCmQDZA7gPGJ",
        "outputId": "9c727b2a-825a-433f-de35-022daf5d292b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19214, 100, 36, 1)\n",
            "(19214,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://stackoverflow.com/questions/53731141/cifar10-randomize-train-and-test-set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_shuffled, y_shuffled, test_size=0.33, random_state=1234)\n",
        "print(\"X_train \" + str(X_train.shape) + \"\\ny_train \" + str(y_train.shape) + \"\\nX_test  \" + str(X_test.shape)+ \"\\ny_test  \" + str(y_test.shape)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOwmuLTKdu_4",
        "outputId": "355abb3f-08d9-45a0-f6ef-349cf92be5de"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train (12873, 100, 36, 1)\n",
            "y_train (12873,)\n",
            "X_test  (6341, 100, 36, 1)\n",
            "y_test  (6341,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, LSTM, Flatten, Input\n",
        "from keras import optimizers, losses, metrics, initializers\n",
        "\n",
        "from collections import Counter\n",
        "NUM_CLASSES = len(Counter(y_shuffled).keys())\n",
        "\n",
        "BATCH_SIZE = 50 # Batch Size\n",
        "NUM_UNITS_LSTM = 16 # Number of unit in the long short-term recurrent layers\n",
        "NB_SENSOR_CHANNELS = data_x.shape[2]\n",
        "SLIDING_WINDOW_LENGTH = data_x.shape[1]"
      ],
      "metadata": {
        "id": "vRLfOHnc6EfC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model._name=\"Experiement1_1LSTM_without_Attention\"\n",
        "model.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "model.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2)\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZegptvD6YAL",
        "outputId": "a8f8265f-aa8f-4bf0-efc5-1df4edc32cee"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement1_1LSTM_without_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 100, 16)           3392      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 12)                19212     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,604\n",
            "Trainable params: 22,604\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 8s 11ms/step - loss: 1.4336 - sparse_categorical_accuracy: 0.5632 - val_loss: 1.0751 - val_sparse_categorical_accuracy: 0.6831\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 2s 8ms/step - loss: 0.9891 - sparse_categorical_accuracy: 0.7036 - val_loss: 0.9000 - val_sparse_categorical_accuracy: 0.7375\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 2s 8ms/step - loss: 0.8255 - sparse_categorical_accuracy: 0.7613 - val_loss: 0.7571 - val_sparse_categorical_accuracy: 0.7872\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.7275 - sparse_categorical_accuracy: 0.7937 - val_loss: 0.7691 - val_sparse_categorical_accuracy: 0.7868\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.6562 - sparse_categorical_accuracy: 0.8151 - val_loss: 0.6245 - val_sparse_categorical_accuracy: 0.8252\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 2s 8ms/step - loss: 0.6054 - sparse_categorical_accuracy: 0.8264 - val_loss: 0.5986 - val_sparse_categorical_accuracy: 0.8303\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 2s 8ms/step - loss: 0.5589 - sparse_categorical_accuracy: 0.8410 - val_loss: 0.6213 - val_sparse_categorical_accuracy: 0.8252\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 2s 8ms/step - loss: 0.5345 - sparse_categorical_accuracy: 0.8445 - val_loss: 0.5490 - val_sparse_categorical_accuracy: 0.8431\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 2s 8ms/step - loss: 0.5072 - sparse_categorical_accuracy: 0.8535 - val_loss: 0.5469 - val_sparse_categorical_accuracy: 0.8458\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.4825 - sparse_categorical_accuracy: 0.8620 - val_loss: 0.5242 - val_sparse_categorical_accuracy: 0.8493\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.4634 - sparse_categorical_accuracy: 0.8654 - val_loss: 0.5627 - val_sparse_categorical_accuracy: 0.8233\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 2s 8ms/step - loss: 0.4373 - sparse_categorical_accuracy: 0.8722 - val_loss: 0.4971 - val_sparse_categorical_accuracy: 0.8583\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 2s 8ms/step - loss: 0.4262 - sparse_categorical_accuracy: 0.8747 - val_loss: 0.4718 - val_sparse_categorical_accuracy: 0.8649\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.4102 - sparse_categorical_accuracy: 0.8782 - val_loss: 0.4644 - val_sparse_categorical_accuracy: 0.8610\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.4041 - sparse_categorical_accuracy: 0.8788 - val_loss: 0.4403 - val_sparse_categorical_accuracy: 0.8660\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 2s 8ms/step - loss: 0.3801 - sparse_categorical_accuracy: 0.8854 - val_loss: 0.4888 - val_sparse_categorical_accuracy: 0.8602\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 2s 8ms/step - loss: 0.3759 - sparse_categorical_accuracy: 0.8881 - val_loss: 0.4133 - val_sparse_categorical_accuracy: 0.8839\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 2s 8ms/step - loss: 0.3689 - sparse_categorical_accuracy: 0.8916 - val_loss: 0.4357 - val_sparse_categorical_accuracy: 0.8734\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.3591 - sparse_categorical_accuracy: 0.8936 - val_loss: 0.4024 - val_sparse_categorical_accuracy: 0.8917\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 2s 8ms/step - loss: 0.3597 - sparse_categorical_accuracy: 0.8931 - val_loss: 0.4388 - val_sparse_categorical_accuracy: 0.8823\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.3361 - sparse_categorical_accuracy: 0.8968 - val_loss: 0.4124 - val_sparse_categorical_accuracy: 0.8866\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.3349 - sparse_categorical_accuracy: 0.8992 - val_loss: 0.4538 - val_sparse_categorical_accuracy: 0.8683\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 2s 8ms/step - loss: 0.3405 - sparse_categorical_accuracy: 0.8970 - val_loss: 0.4145 - val_sparse_categorical_accuracy: 0.8796\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3309 - sparse_categorical_accuracy: 0.9022 - val_loss: 0.4062 - val_sparse_categorical_accuracy: 0.8784\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.3228 - sparse_categorical_accuracy: 0.9032 - val_loss: 0.4240 - val_sparse_categorical_accuracy: 0.8753\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.3235 - sparse_categorical_accuracy: 0.9008 - val_loss: 0.3771 - val_sparse_categorical_accuracy: 0.8944\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.3177 - sparse_categorical_accuracy: 0.9045 - val_loss: 0.3750 - val_sparse_categorical_accuracy: 0.8917\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.3113 - sparse_categorical_accuracy: 0.9052 - val_loss: 0.3971 - val_sparse_categorical_accuracy: 0.8816\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.3019 - sparse_categorical_accuracy: 0.9056 - val_loss: 0.4272 - val_sparse_categorical_accuracy: 0.8784\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.3003 - sparse_categorical_accuracy: 0.9092 - val_loss: 0.4008 - val_sparse_categorical_accuracy: 0.8808\n",
            "199/199 [==============================] - 1s 5ms/step - loss: 0.3556 - sparse_categorical_accuracy: 0.8980\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.35555127263069153, 0.8979656100273132]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/ManzhuYu/Code-SpatioTemporalAttention-LSTM-main/blob/main/modelbase.py\n",
        "\n",
        "model_2 = Sequential()\n",
        "model_2._name=\"Experiement2_1LSTM_with_temporal_Attention\"\n",
        "model_2.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "model_2.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_2.add(Dense(NUM_UNITS_LSTM*SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # temporal module\n",
        "model_2.add(Flatten())\n",
        "\n",
        "model_2.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_2.summary()\n",
        "\n",
        "model_2.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_2.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2) \n",
        "model_2.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_yaPwcv6cmz",
        "outputId": "923234cc-adf0-4f02-d76a-19c95e2abe4b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement2_1LSTM_with_temporal_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_1 (LSTM)               (None, 100, 16)           3392      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100, 1600)         27200     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 160000)            0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 12)                1920012   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,950,604\n",
            "Trainable params: 1,950,604\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 5s 15ms/step - loss: 1.4440 - sparse_categorical_accuracy: 0.5575 - val_loss: 1.1356 - val_sparse_categorical_accuracy: 0.6346\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 1.0840 - sparse_categorical_accuracy: 0.6667 - val_loss: 0.9713 - val_sparse_categorical_accuracy: 0.7150\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.9197 - sparse_categorical_accuracy: 0.7207 - val_loss: 0.9081 - val_sparse_categorical_accuracy: 0.7351\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.8293 - sparse_categorical_accuracy: 0.7585 - val_loss: 0.7545 - val_sparse_categorical_accuracy: 0.7786\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.7462 - sparse_categorical_accuracy: 0.7850 - val_loss: 0.6794 - val_sparse_categorical_accuracy: 0.8101\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.6923 - sparse_categorical_accuracy: 0.8004 - val_loss: 0.6419 - val_sparse_categorical_accuracy: 0.8260\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.6467 - sparse_categorical_accuracy: 0.8147 - val_loss: 0.6772 - val_sparse_categorical_accuracy: 0.8085\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.6096 - sparse_categorical_accuracy: 0.8258 - val_loss: 0.6716 - val_sparse_categorical_accuracy: 0.8070\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.5754 - sparse_categorical_accuracy: 0.8351 - val_loss: 0.6436 - val_sparse_categorical_accuracy: 0.8225\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.5525 - sparse_categorical_accuracy: 0.8444 - val_loss: 0.5328 - val_sparse_categorical_accuracy: 0.8517\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 3s 17ms/step - loss: 0.5206 - sparse_categorical_accuracy: 0.8490 - val_loss: 0.5387 - val_sparse_categorical_accuracy: 0.8431\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.5014 - sparse_categorical_accuracy: 0.8556 - val_loss: 0.5656 - val_sparse_categorical_accuracy: 0.8357\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.4859 - sparse_categorical_accuracy: 0.8598 - val_loss: 0.5045 - val_sparse_categorical_accuracy: 0.8571\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.4673 - sparse_categorical_accuracy: 0.8651 - val_loss: 0.4498 - val_sparse_categorical_accuracy: 0.8808\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 3s 17ms/step - loss: 0.4460 - sparse_categorical_accuracy: 0.8749 - val_loss: 0.4957 - val_sparse_categorical_accuracy: 0.8575\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.4379 - sparse_categorical_accuracy: 0.8735 - val_loss: 0.5045 - val_sparse_categorical_accuracy: 0.8718\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 4s 18ms/step - loss: 0.4198 - sparse_categorical_accuracy: 0.8804 - val_loss: 0.4732 - val_sparse_categorical_accuracy: 0.8699\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.4191 - sparse_categorical_accuracy: 0.8812 - val_loss: 0.4868 - val_sparse_categorical_accuracy: 0.8664\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.4080 - sparse_categorical_accuracy: 0.8821 - val_loss: 0.4706 - val_sparse_categorical_accuracy: 0.8668\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.4013 - sparse_categorical_accuracy: 0.8853 - val_loss: 0.4985 - val_sparse_categorical_accuracy: 0.8583\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3870 - sparse_categorical_accuracy: 0.8876 - val_loss: 0.4750 - val_sparse_categorical_accuracy: 0.8854\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3884 - sparse_categorical_accuracy: 0.8876 - val_loss: 0.4411 - val_sparse_categorical_accuracy: 0.8843\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.3759 - sparse_categorical_accuracy: 0.8911 - val_loss: 0.4598 - val_sparse_categorical_accuracy: 0.8761\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.3722 - sparse_categorical_accuracy: 0.8920 - val_loss: 0.4331 - val_sparse_categorical_accuracy: 0.8773\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.3645 - sparse_categorical_accuracy: 0.8943 - val_loss: 0.4018 - val_sparse_categorical_accuracy: 0.8932\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.3642 - sparse_categorical_accuracy: 0.8956 - val_loss: 0.4083 - val_sparse_categorical_accuracy: 0.8847\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.3569 - sparse_categorical_accuracy: 0.8930 - val_loss: 0.4207 - val_sparse_categorical_accuracy: 0.8819\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3486 - sparse_categorical_accuracy: 0.8991 - val_loss: 0.4029 - val_sparse_categorical_accuracy: 0.8909\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3446 - sparse_categorical_accuracy: 0.9011 - val_loss: 0.4088 - val_sparse_categorical_accuracy: 0.8812\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.3365 - sparse_categorical_accuracy: 0.8988 - val_loss: 0.4439 - val_sparse_categorical_accuracy: 0.8804\n",
            "199/199 [==============================] - 2s 8ms/step - loss: 0.3946 - sparse_categorical_accuracy: 0.9000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.39457929134368896, 0.9000157713890076]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = Sequential()\n",
        "model_3._name=\"Experiement3_1LSTM_with_spatial_Attention\"\n",
        "model_3.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "model_3.add(Dense(SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # spatial module\n",
        "model_3.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_3.add(Flatten())\n",
        "\n",
        "model_3.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_3.summary()\n",
        "\n",
        "model_3.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_3.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2) \n",
        "model_3.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVesmPxk6fa1",
        "outputId": "4cf6ac36-2fec-4fcb-89a5-d4486e0ee1a6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement3_1LSTM_with_spatial_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 100, 100)          3700      \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 100, 16)           7488      \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 12)                19212     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,400\n",
            "Trainable params: 30,400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 6s 15ms/step - loss: 1.2780 - sparse_categorical_accuracy: 0.5889 - val_loss: 0.9346 - val_sparse_categorical_accuracy: 0.7266\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.7816 - sparse_categorical_accuracy: 0.7738 - val_loss: 0.6904 - val_sparse_categorical_accuracy: 0.7996\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.6069 - sparse_categorical_accuracy: 0.8292 - val_loss: 0.6205 - val_sparse_categorical_accuracy: 0.8210\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 2s 10ms/step - loss: 0.5166 - sparse_categorical_accuracy: 0.8570 - val_loss: 0.7185 - val_sparse_categorical_accuracy: 0.7821\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.4546 - sparse_categorical_accuracy: 0.8728 - val_loss: 0.5629 - val_sparse_categorical_accuracy: 0.8268\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.4091 - sparse_categorical_accuracy: 0.8856 - val_loss: 0.4383 - val_sparse_categorical_accuracy: 0.8757\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.3799 - sparse_categorical_accuracy: 0.8934 - val_loss: 0.4423 - val_sparse_categorical_accuracy: 0.8726\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.3508 - sparse_categorical_accuracy: 0.8993 - val_loss: 0.4338 - val_sparse_categorical_accuracy: 0.8699\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3288 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.3929 - val_sparse_categorical_accuracy: 0.8905\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3032 - sparse_categorical_accuracy: 0.9110 - val_loss: 0.3821 - val_sparse_categorical_accuracy: 0.8920\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2898 - sparse_categorical_accuracy: 0.9143 - val_loss: 0.3723 - val_sparse_categorical_accuracy: 0.8967\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.2722 - sparse_categorical_accuracy: 0.9206 - val_loss: 0.3843 - val_sparse_categorical_accuracy: 0.8948\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.2604 - sparse_categorical_accuracy: 0.9206 - val_loss: 0.4627 - val_sparse_categorical_accuracy: 0.8633\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.2525 - sparse_categorical_accuracy: 0.9245 - val_loss: 0.3539 - val_sparse_categorical_accuracy: 0.9041\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 2s 9ms/step - loss: 0.2403 - sparse_categorical_accuracy: 0.9268 - val_loss: 0.3712 - val_sparse_categorical_accuracy: 0.9060\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.2338 - sparse_categorical_accuracy: 0.9311 - val_loss: 0.3884 - val_sparse_categorical_accuracy: 0.8878\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2197 - sparse_categorical_accuracy: 0.9310 - val_loss: 0.3631 - val_sparse_categorical_accuracy: 0.9099\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.2142 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.3473 - val_sparse_categorical_accuracy: 0.9080\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.2093 - sparse_categorical_accuracy: 0.9332 - val_loss: 0.3478 - val_sparse_categorical_accuracy: 0.9118\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.2078 - sparse_categorical_accuracy: 0.9358 - val_loss: 0.3948 - val_sparse_categorical_accuracy: 0.8917\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.1971 - sparse_categorical_accuracy: 0.9378 - val_loss: 0.3361 - val_sparse_categorical_accuracy: 0.9130\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.1948 - sparse_categorical_accuracy: 0.9389 - val_loss: 0.3574 - val_sparse_categorical_accuracy: 0.9045\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1849 - sparse_categorical_accuracy: 0.9409 - val_loss: 0.3553 - val_sparse_categorical_accuracy: 0.9021\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 4s 17ms/step - loss: 0.1779 - sparse_categorical_accuracy: 0.9431 - val_loss: 0.3770 - val_sparse_categorical_accuracy: 0.9014\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.1740 - sparse_categorical_accuracy: 0.9463 - val_loss: 0.3262 - val_sparse_categorical_accuracy: 0.9134\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.1725 - sparse_categorical_accuracy: 0.9431 - val_loss: 0.3366 - val_sparse_categorical_accuracy: 0.9118\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.1669 - sparse_categorical_accuracy: 0.9475 - val_loss: 0.3573 - val_sparse_categorical_accuracy: 0.9052\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.1619 - sparse_categorical_accuracy: 0.9482 - val_loss: 0.3450 - val_sparse_categorical_accuracy: 0.9095\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.1622 - sparse_categorical_accuracy: 0.9480 - val_loss: 0.3639 - val_sparse_categorical_accuracy: 0.9087\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.1554 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.3472 - val_sparse_categorical_accuracy: 0.9126\n",
            "199/199 [==============================] - 2s 8ms/step - loss: 0.2665 - sparse_categorical_accuracy: 0.9265\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.26646026968955994, 0.9265100359916687]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4 = Sequential()\n",
        "model_4._name=\"Experiement4_1LSTM_with_spatial_temporal_Attention\"\n",
        "model_4.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "model_4.add(Dense(SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # spatial module\n",
        "model_4.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_4.add(Dense(NUM_UNITS_LSTM*SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # temporal module\n",
        "model_4.add(Flatten())\n",
        "\n",
        "model_4.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_4.summary()\n",
        "\n",
        "model_4.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_4.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2) \n",
        "model_4.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CMf7SuI6hqa",
        "outputId": "c78a0c85-30e0-4161-a187-914ca7d95f0b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement4_1LSTM_with_spatial_temporal_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 100, 100)          3700      \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 100, 16)           7488      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 100, 1600)         27200     \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 160000)            0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 12)                1920012   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,958,400\n",
            "Trainable params: 1,958,400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 8s 17ms/step - loss: 1.3846 - sparse_categorical_accuracy: 0.5726 - val_loss: 1.0388 - val_sparse_categorical_accuracy: 0.6854\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.8729 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.8847 - val_sparse_categorical_accuracy: 0.7355\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.6893 - sparse_categorical_accuracy: 0.7993 - val_loss: 0.7250 - val_sparse_categorical_accuracy: 0.7864\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.6032 - sparse_categorical_accuracy: 0.8229 - val_loss: 0.5608 - val_sparse_categorical_accuracy: 0.8264\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.5333 - sparse_categorical_accuracy: 0.8451 - val_loss: 0.5149 - val_sparse_categorical_accuracy: 0.8548\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.4869 - sparse_categorical_accuracy: 0.8616 - val_loss: 0.5656 - val_sparse_categorical_accuracy: 0.8350\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 4s 18ms/step - loss: 0.4492 - sparse_categorical_accuracy: 0.8695 - val_loss: 0.6454 - val_sparse_categorical_accuracy: 0.8012\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 4s 20ms/step - loss: 0.4227 - sparse_categorical_accuracy: 0.8755 - val_loss: 0.5707 - val_sparse_categorical_accuracy: 0.8384\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 4s 17ms/step - loss: 0.3978 - sparse_categorical_accuracy: 0.8842 - val_loss: 0.4695 - val_sparse_categorical_accuracy: 0.8614\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.3790 - sparse_categorical_accuracy: 0.8889 - val_loss: 0.3899 - val_sparse_categorical_accuracy: 0.8959\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 3s 17ms/step - loss: 0.3631 - sparse_categorical_accuracy: 0.8943 - val_loss: 0.4258 - val_sparse_categorical_accuracy: 0.8781\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.3420 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.4711 - val_sparse_categorical_accuracy: 0.8683\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3295 - sparse_categorical_accuracy: 0.9014 - val_loss: 0.3914 - val_sparse_categorical_accuracy: 0.8878\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.3105 - sparse_categorical_accuracy: 0.9122 - val_loss: 0.3739 - val_sparse_categorical_accuracy: 0.9010\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.3032 - sparse_categorical_accuracy: 0.9076 - val_loss: 0.3938 - val_sparse_categorical_accuracy: 0.8850\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.2932 - sparse_categorical_accuracy: 0.9134 - val_loss: 0.3837 - val_sparse_categorical_accuracy: 0.9014\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2858 - sparse_categorical_accuracy: 0.9145 - val_loss: 0.3731 - val_sparse_categorical_accuracy: 0.8959\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2714 - sparse_categorical_accuracy: 0.9148 - val_loss: 0.5217 - val_sparse_categorical_accuracy: 0.8485\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.2615 - sparse_categorical_accuracy: 0.9207 - val_loss: 0.3557 - val_sparse_categorical_accuracy: 0.9045\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 2s 12ms/step - loss: 0.2577 - sparse_categorical_accuracy: 0.9235 - val_loss: 0.3938 - val_sparse_categorical_accuracy: 0.8932\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.2503 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.3452 - val_sparse_categorical_accuracy: 0.9025\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.2418 - sparse_categorical_accuracy: 0.9252 - val_loss: 0.3286 - val_sparse_categorical_accuracy: 0.9107\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.2366 - sparse_categorical_accuracy: 0.9299 - val_loss: 0.3840 - val_sparse_categorical_accuracy: 0.8932\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.2300 - sparse_categorical_accuracy: 0.9307 - val_loss: 0.3400 - val_sparse_categorical_accuracy: 0.9099\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2259 - sparse_categorical_accuracy: 0.9296 - val_loss: 0.3232 - val_sparse_categorical_accuracy: 0.9177\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 2s 11ms/step - loss: 0.2252 - sparse_categorical_accuracy: 0.9309 - val_loss: 0.3629 - val_sparse_categorical_accuracy: 0.9014\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2131 - sparse_categorical_accuracy: 0.9354 - val_loss: 0.3529 - val_sparse_categorical_accuracy: 0.9076\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2094 - sparse_categorical_accuracy: 0.9360 - val_loss: 0.3411 - val_sparse_categorical_accuracy: 0.9025\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.2067 - sparse_categorical_accuracy: 0.9339 - val_loss: 0.3410 - val_sparse_categorical_accuracy: 0.9115\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.2034 - sparse_categorical_accuracy: 0.9364 - val_loss: 0.3558 - val_sparse_categorical_accuracy: 0.9064\n",
            "199/199 [==============================] - 1s 7ms/step - loss: 0.3367 - sparse_categorical_accuracy: 0.9177\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.33667731285095215, 0.9176785945892334]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5 = Sequential()\n",
        "model_5._name=\"Experiement5_2LSTM_without_Attention\"\n",
        "model_5.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "model_5.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_5.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_5.add(Flatten())\n",
        "\n",
        "model_5.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_5.summary()\n",
        "\n",
        "model_5.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_5.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2) \n",
        "model_5.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlayUnRA6mJb",
        "outputId": "b3cfeb5d-7eab-458f-a278-ef6d19a295b3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement5_2LSTM_without_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 100, 16)           3392      \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 100, 16)           2112      \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 12)                19212     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,716\n",
            "Trainable params: 24,716\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 10s 23ms/step - loss: 1.4677 - sparse_categorical_accuracy: 0.5401 - val_loss: 1.1698 - val_sparse_categorical_accuracy: 0.6454\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.0524 - sparse_categorical_accuracy: 0.6809 - val_loss: 0.8804 - val_sparse_categorical_accuracy: 0.7289\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 3s 17ms/step - loss: 0.8494 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.7286 - val_sparse_categorical_accuracy: 0.7876\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.7307 - sparse_categorical_accuracy: 0.7824 - val_loss: 0.6805 - val_sparse_categorical_accuracy: 0.8000\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.6514 - sparse_categorical_accuracy: 0.8121 - val_loss: 0.6658 - val_sparse_categorical_accuracy: 0.8082\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.5957 - sparse_categorical_accuracy: 0.8265 - val_loss: 0.6010 - val_sparse_categorical_accuracy: 0.8346\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.5520 - sparse_categorical_accuracy: 0.8416 - val_loss: 0.5271 - val_sparse_categorical_accuracy: 0.8548\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 4s 22ms/step - loss: 0.5100 - sparse_categorical_accuracy: 0.8514 - val_loss: 0.5338 - val_sparse_categorical_accuracy: 0.8497\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 4s 19ms/step - loss: 0.4779 - sparse_categorical_accuracy: 0.8610 - val_loss: 0.4972 - val_sparse_categorical_accuracy: 0.8559\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.4564 - sparse_categorical_accuracy: 0.8638 - val_loss: 0.5277 - val_sparse_categorical_accuracy: 0.8536\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 4s 18ms/step - loss: 0.4366 - sparse_categorical_accuracy: 0.8707 - val_loss: 0.4613 - val_sparse_categorical_accuracy: 0.8594\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 5s 25ms/step - loss: 0.4227 - sparse_categorical_accuracy: 0.8748 - val_loss: 0.4929 - val_sparse_categorical_accuracy: 0.8563\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 4s 20ms/step - loss: 0.4083 - sparse_categorical_accuracy: 0.8799 - val_loss: 0.5124 - val_sparse_categorical_accuracy: 0.8598\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3917 - sparse_categorical_accuracy: 0.8825 - val_loss: 0.4061 - val_sparse_categorical_accuracy: 0.8819\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 3s 17ms/step - loss: 0.3730 - sparse_categorical_accuracy: 0.8866 - val_loss: 0.4194 - val_sparse_categorical_accuracy: 0.8784\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 4s 20ms/step - loss: 0.3656 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.4325 - val_sparse_categorical_accuracy: 0.8831\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 4s 19ms/step - loss: 0.3503 - sparse_categorical_accuracy: 0.8943 - val_loss: 0.4082 - val_sparse_categorical_accuracy: 0.8827\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 4s 18ms/step - loss: 0.3531 - sparse_categorical_accuracy: 0.8932 - val_loss: 0.4495 - val_sparse_categorical_accuracy: 0.8804\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 4s 20ms/step - loss: 0.3390 - sparse_categorical_accuracy: 0.8978 - val_loss: 0.4106 - val_sparse_categorical_accuracy: 0.8777\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 4s 19ms/step - loss: 0.3369 - sparse_categorical_accuracy: 0.8988 - val_loss: 0.3860 - val_sparse_categorical_accuracy: 0.8917\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.3309 - sparse_categorical_accuracy: 0.9003 - val_loss: 0.3772 - val_sparse_categorical_accuracy: 0.8928\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.3180 - sparse_categorical_accuracy: 0.9040 - val_loss: 0.4472 - val_sparse_categorical_accuracy: 0.8765\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.3125 - sparse_categorical_accuracy: 0.9044 - val_loss: 0.3563 - val_sparse_categorical_accuracy: 0.8990\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3028 - sparse_categorical_accuracy: 0.9067 - val_loss: 0.4945 - val_sparse_categorical_accuracy: 0.8513\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3041 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.3658 - val_sparse_categorical_accuracy: 0.8994\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.3023 - sparse_categorical_accuracy: 0.9100 - val_loss: 0.3437 - val_sparse_categorical_accuracy: 0.9037\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.2982 - sparse_categorical_accuracy: 0.9112 - val_loss: 0.3683 - val_sparse_categorical_accuracy: 0.8882\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.2893 - sparse_categorical_accuracy: 0.9093 - val_loss: 0.3531 - val_sparse_categorical_accuracy: 0.9014\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.2756 - sparse_categorical_accuracy: 0.9123 - val_loss: 0.3697 - val_sparse_categorical_accuracy: 0.8994\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 3s 12ms/step - loss: 0.2764 - sparse_categorical_accuracy: 0.9146 - val_loss: 0.3725 - val_sparse_categorical_accuracy: 0.8971\n",
            "199/199 [==============================] - 1s 6ms/step - loss: 0.3328 - sparse_categorical_accuracy: 0.9060\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.33284857869148254, 0.9060085415840149]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6a = Sequential()\n",
        "model_6a._name=\"Experiement6a_2LSTM_with_temporal_Attention\"\n",
        "model_6a.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "model_6a.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_6a.add(Dense(NUM_UNITS_LSTM*SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # temporal module\n",
        "model_6a.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_6a.add(Flatten())\n",
        "\n",
        "model_6a.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_6a.summary()\n",
        "\n",
        "model_6a.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_6a.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2) \n",
        "model_6a.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWJzVI7X60Uy",
        "outputId": "a7bf83d6-5103-44b6-8603-1c78ab6e875e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement6a_2LSTM_with_temporal_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_6 (LSTM)               (None, 100, 16)           3392      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 100, 1600)         27200     \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 100, 16)           103488    \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 12)                19212     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 153,292\n",
            "Trainable params: 153,292\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 7s 20ms/step - loss: 1.3155 - sparse_categorical_accuracy: 0.5715 - val_loss: 0.9370 - val_sparse_categorical_accuracy: 0.6905\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.8201 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.7052 - val_sparse_categorical_accuracy: 0.7794\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.6405 - sparse_categorical_accuracy: 0.8013 - val_loss: 0.5906 - val_sparse_categorical_accuracy: 0.8229\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.5321 - sparse_categorical_accuracy: 0.8408 - val_loss: 0.5130 - val_sparse_categorical_accuracy: 0.8637\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.4707 - sparse_categorical_accuracy: 0.8601 - val_loss: 0.4960 - val_sparse_categorical_accuracy: 0.8680\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.4280 - sparse_categorical_accuracy: 0.8719 - val_loss: 0.4734 - val_sparse_categorical_accuracy: 0.8680\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 3s 17ms/step - loss: 0.3990 - sparse_categorical_accuracy: 0.8802 - val_loss: 0.4885 - val_sparse_categorical_accuracy: 0.8563\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.3687 - sparse_categorical_accuracy: 0.8866 - val_loss: 0.4085 - val_sparse_categorical_accuracy: 0.8905\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3518 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.3861 - val_sparse_categorical_accuracy: 0.8963\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3299 - sparse_categorical_accuracy: 0.9026 - val_loss: 0.3817 - val_sparse_categorical_accuracy: 0.8944\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3162 - sparse_categorical_accuracy: 0.8996 - val_loss: 0.4461 - val_sparse_categorical_accuracy: 0.8788\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3037 - sparse_categorical_accuracy: 0.9057 - val_loss: 0.3851 - val_sparse_categorical_accuracy: 0.8944\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.2971 - sparse_categorical_accuracy: 0.9098 - val_loss: 0.3809 - val_sparse_categorical_accuracy: 0.8944\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2877 - sparse_categorical_accuracy: 0.9108 - val_loss: 0.3534 - val_sparse_categorical_accuracy: 0.9017\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2776 - sparse_categorical_accuracy: 0.9137 - val_loss: 0.3501 - val_sparse_categorical_accuracy: 0.9002\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.2689 - sparse_categorical_accuracy: 0.9161 - val_loss: 0.3399 - val_sparse_categorical_accuracy: 0.9021\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.2649 - sparse_categorical_accuracy: 0.9174 - val_loss: 0.3314 - val_sparse_categorical_accuracy: 0.9076\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.2621 - sparse_categorical_accuracy: 0.9196 - val_loss: 0.3133 - val_sparse_categorical_accuracy: 0.9146\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2461 - sparse_categorical_accuracy: 0.9206 - val_loss: 0.3447 - val_sparse_categorical_accuracy: 0.9091\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2456 - sparse_categorical_accuracy: 0.9241 - val_loss: 0.3598 - val_sparse_categorical_accuracy: 0.9060\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2405 - sparse_categorical_accuracy: 0.9218 - val_loss: 0.3936 - val_sparse_categorical_accuracy: 0.9010\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.2385 - sparse_categorical_accuracy: 0.9250 - val_loss: 0.3745 - val_sparse_categorical_accuracy: 0.9049\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.2313 - sparse_categorical_accuracy: 0.9269 - val_loss: 0.3589 - val_sparse_categorical_accuracy: 0.9017\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2278 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.3480 - val_sparse_categorical_accuracy: 0.9115\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2277 - sparse_categorical_accuracy: 0.9269 - val_loss: 0.3167 - val_sparse_categorical_accuracy: 0.9095\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 4s 20ms/step - loss: 0.2155 - sparse_categorical_accuracy: 0.9325 - val_loss: 0.3128 - val_sparse_categorical_accuracy: 0.9111\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.2158 - sparse_categorical_accuracy: 0.9315 - val_loss: 0.3451 - val_sparse_categorical_accuracy: 0.9138\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.2173 - sparse_categorical_accuracy: 0.9290 - val_loss: 0.3207 - val_sparse_categorical_accuracy: 0.9165\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.2022 - sparse_categorical_accuracy: 0.9350 - val_loss: 0.3480 - val_sparse_categorical_accuracy: 0.9068\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2130 - sparse_categorical_accuracy: 0.9305 - val_loss: 0.3386 - val_sparse_categorical_accuracy: 0.9060\n",
            "199/199 [==============================] - 1s 7ms/step - loss: 0.3233 - sparse_categorical_accuracy: 0.9081\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.32331961393356323, 0.9080586433410645]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6b = Sequential()\n",
        "model_6b._name=\"Experiement6b_2LSTM_with_temporal_Attention\"\n",
        "model_6b.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "model_6b.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_6b.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_6b.add(Dense(NUM_UNITS_LSTM*SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # temporal module\n",
        "model_6b.add(Flatten())\n",
        "\n",
        "model_6b.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_6b.summary()\n",
        "\n",
        "model_6b.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_6b.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2) \n",
        "model_6b.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIzHEBUZ69RF",
        "outputId": "d6e49ccf-2f9c-4946-9fce-31d0220003d6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement6b_2LSTM_with_temporal_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_8 (LSTM)               (None, 100, 16)           3392      \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 100, 16)           2112      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 100, 1600)         27200     \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 160000)            0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 12)                1920012   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,952,716\n",
            "Trainable params: 1,952,716\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 7s 19ms/step - loss: 1.4864 - sparse_categorical_accuracy: 0.5259 - val_loss: 1.2252 - val_sparse_categorical_accuracy: 0.6229\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 1.0534 - sparse_categorical_accuracy: 0.6827 - val_loss: 0.8917 - val_sparse_categorical_accuracy: 0.7095\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.8786 - sparse_categorical_accuracy: 0.7359 - val_loss: 0.8337 - val_sparse_categorical_accuracy: 0.7441\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.7670 - sparse_categorical_accuracy: 0.7694 - val_loss: 0.7866 - val_sparse_categorical_accuracy: 0.7798\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.6976 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.6623 - val_sparse_categorical_accuracy: 0.8175\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.6536 - sparse_categorical_accuracy: 0.8077 - val_loss: 0.6073 - val_sparse_categorical_accuracy: 0.8311\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.5960 - sparse_categorical_accuracy: 0.8269 - val_loss: 0.6428 - val_sparse_categorical_accuracy: 0.8159\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.5781 - sparse_categorical_accuracy: 0.8321 - val_loss: 0.5747 - val_sparse_categorical_accuracy: 0.8350\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.5468 - sparse_categorical_accuracy: 0.8440 - val_loss: 0.5206 - val_sparse_categorical_accuracy: 0.8520\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.5181 - sparse_categorical_accuracy: 0.8510 - val_loss: 0.5504 - val_sparse_categorical_accuracy: 0.8489\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.5072 - sparse_categorical_accuracy: 0.8546 - val_loss: 0.4711 - val_sparse_categorical_accuracy: 0.8730\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.4803 - sparse_categorical_accuracy: 0.8638 - val_loss: 0.4850 - val_sparse_categorical_accuracy: 0.8695\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.4656 - sparse_categorical_accuracy: 0.8647 - val_loss: 0.4611 - val_sparse_categorical_accuracy: 0.8680\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.4640 - sparse_categorical_accuracy: 0.8657 - val_loss: 0.4674 - val_sparse_categorical_accuracy: 0.8734\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.4472 - sparse_categorical_accuracy: 0.8698 - val_loss: 0.4616 - val_sparse_categorical_accuracy: 0.8746\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.4354 - sparse_categorical_accuracy: 0.8769 - val_loss: 0.4891 - val_sparse_categorical_accuracy: 0.8691\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.4228 - sparse_categorical_accuracy: 0.8758 - val_loss: 0.4072 - val_sparse_categorical_accuracy: 0.8889\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.4024 - sparse_categorical_accuracy: 0.8866 - val_loss: 0.4066 - val_sparse_categorical_accuracy: 0.8889\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.3985 - sparse_categorical_accuracy: 0.8853 - val_loss: 0.4322 - val_sparse_categorical_accuracy: 0.8816\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.3975 - sparse_categorical_accuracy: 0.8868 - val_loss: 0.4417 - val_sparse_categorical_accuracy: 0.8831\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.3822 - sparse_categorical_accuracy: 0.8859 - val_loss: 0.4194 - val_sparse_categorical_accuracy: 0.8924\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.3742 - sparse_categorical_accuracy: 0.8939 - val_loss: 0.4154 - val_sparse_categorical_accuracy: 0.8897\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.3631 - sparse_categorical_accuracy: 0.8947 - val_loss: 0.4413 - val_sparse_categorical_accuracy: 0.8819\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.3497 - sparse_categorical_accuracy: 0.8985 - val_loss: 0.3890 - val_sparse_categorical_accuracy: 0.8986\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.3558 - sparse_categorical_accuracy: 0.8948 - val_loss: 0.4015 - val_sparse_categorical_accuracy: 0.8936\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.3388 - sparse_categorical_accuracy: 0.9021 - val_loss: 0.4014 - val_sparse_categorical_accuracy: 0.8944\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3392 - sparse_categorical_accuracy: 0.9021 - val_loss: 0.4716 - val_sparse_categorical_accuracy: 0.8676\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 4s 18ms/step - loss: 0.3269 - sparse_categorical_accuracy: 0.9036 - val_loss: 0.4223 - val_sparse_categorical_accuracy: 0.8936\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.3232 - sparse_categorical_accuracy: 0.9023 - val_loss: 0.4249 - val_sparse_categorical_accuracy: 0.8858\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.3112 - sparse_categorical_accuracy: 0.9077 - val_loss: 0.4133 - val_sparse_categorical_accuracy: 0.8936\n",
            "199/199 [==============================] - 1s 7ms/step - loss: 0.3551 - sparse_categorical_accuracy: 0.9077\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.35505303740501404, 0.9077432751655579]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6c = Sequential()\n",
        "model_6c._name=\"Experiement6c_2LSTM_with_temporal_Attention\"\n",
        "model_6c.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "model_6c.add(Dense(NUM_UNITS_LSTM*SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # temporal module\n",
        "model_6c.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_6c.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_6c.add(Flatten())\n",
        "\n",
        "model_6c.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_6c.summary()\n",
        "\n",
        "model_6c.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_6c.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2) \n",
        "model_6c.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMt7GCXf7GVz",
        "outputId": "29c8a670-7c9a-4e17-8a4f-729a034c153e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement6c_2LSTM_with_temporal_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_13 (Dense)            (None, 100, 1600)         59200     \n",
            "                                                                 \n",
            " lstm_10 (LSTM)              (None, 100, 16)           103488    \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 100, 16)           2112      \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 12)                19212     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 184,012\n",
            "Trainable params: 184,012\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 8s 20ms/step - loss: 1.2135 - sparse_categorical_accuracy: 0.6143 - val_loss: 0.8238 - val_sparse_categorical_accuracy: 0.7437\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.6571 - sparse_categorical_accuracy: 0.8127 - val_loss: 0.5557 - val_sparse_categorical_accuracy: 0.8369\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.4993 - sparse_categorical_accuracy: 0.8602 - val_loss: 0.5038 - val_sparse_categorical_accuracy: 0.8524\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.4237 - sparse_categorical_accuracy: 0.8809 - val_loss: 0.4376 - val_sparse_categorical_accuracy: 0.8715\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3686 - sparse_categorical_accuracy: 0.8935 - val_loss: 0.3825 - val_sparse_categorical_accuracy: 0.8920\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3341 - sparse_categorical_accuracy: 0.9010 - val_loss: 0.3977 - val_sparse_categorical_accuracy: 0.8854\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3018 - sparse_categorical_accuracy: 0.9085 - val_loss: 0.3738 - val_sparse_categorical_accuracy: 0.8917\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2789 - sparse_categorical_accuracy: 0.9155 - val_loss: 0.3730 - val_sparse_categorical_accuracy: 0.8913\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2617 - sparse_categorical_accuracy: 0.9197 - val_loss: 0.3535 - val_sparse_categorical_accuracy: 0.9002\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.2421 - sparse_categorical_accuracy: 0.9245 - val_loss: 0.3499 - val_sparse_categorical_accuracy: 0.9049\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2336 - sparse_categorical_accuracy: 0.9260 - val_loss: 0.3178 - val_sparse_categorical_accuracy: 0.9103\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 4s 20ms/step - loss: 0.2124 - sparse_categorical_accuracy: 0.9312 - val_loss: 0.3312 - val_sparse_categorical_accuracy: 0.9068\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2084 - sparse_categorical_accuracy: 0.9340 - val_loss: 0.3797 - val_sparse_categorical_accuracy: 0.8889\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.1973 - sparse_categorical_accuracy: 0.9377 - val_loss: 0.2871 - val_sparse_categorical_accuracy: 0.9196\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1856 - sparse_categorical_accuracy: 0.9410 - val_loss: 0.3215 - val_sparse_categorical_accuracy: 0.9099\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.1816 - sparse_categorical_accuracy: 0.9429 - val_loss: 0.3366 - val_sparse_categorical_accuracy: 0.9130\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.1758 - sparse_categorical_accuracy: 0.9418 - val_loss: 0.3265 - val_sparse_categorical_accuracy: 0.9146\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.1651 - sparse_categorical_accuracy: 0.9469 - val_loss: 0.3020 - val_sparse_categorical_accuracy: 0.9223\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.1635 - sparse_categorical_accuracy: 0.9465 - val_loss: 0.2877 - val_sparse_categorical_accuracy: 0.9282\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1597 - sparse_categorical_accuracy: 0.9495 - val_loss: 0.3291 - val_sparse_categorical_accuracy: 0.9157\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.1505 - sparse_categorical_accuracy: 0.9506 - val_loss: 0.2841 - val_sparse_categorical_accuracy: 0.9266\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.1509 - sparse_categorical_accuracy: 0.9502 - val_loss: 0.3118 - val_sparse_categorical_accuracy: 0.9196\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1427 - sparse_categorical_accuracy: 0.9539 - val_loss: 0.2920 - val_sparse_categorical_accuracy: 0.9282\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1406 - sparse_categorical_accuracy: 0.9555 - val_loss: 0.3886 - val_sparse_categorical_accuracy: 0.9103\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1384 - sparse_categorical_accuracy: 0.9547 - val_loss: 0.3104 - val_sparse_categorical_accuracy: 0.9270\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.1326 - sparse_categorical_accuracy: 0.9575 - val_loss: 0.3241 - val_sparse_categorical_accuracy: 0.9219\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 3s 17ms/step - loss: 0.1356 - sparse_categorical_accuracy: 0.9556 - val_loss: 0.2687 - val_sparse_categorical_accuracy: 0.9332\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1288 - sparse_categorical_accuracy: 0.9584 - val_loss: 0.3254 - val_sparse_categorical_accuracy: 0.9270\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1262 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.3230 - val_sparse_categorical_accuracy: 0.9219\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.1178 - sparse_categorical_accuracy: 0.9604 - val_loss: 0.3300 - val_sparse_categorical_accuracy: 0.9181\n",
            "199/199 [==============================] - 1s 7ms/step - loss: 0.2649 - sparse_categorical_accuracy: 0.9314\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2649204432964325, 0.9313988089561462]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_7a = Sequential()\n",
        "model_7a._name=\"Experiement7a_2LSTM_with_spatial_Attention\"\n",
        "model_7a.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "model_7a.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_7a.add(Dense(SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # spatial module\n",
        "model_7a.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_7a.add(Flatten())\n",
        "\n",
        "model_7a.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_7a.summary()\n",
        "\n",
        "model_7a.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_7a.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2) \n",
        "model_7a.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ddjjwWn7NJb",
        "outputId": "15d142d2-3a2c-4063-bcef-160262d6f586"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement7a_2LSTM_with_spatial_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_12 (LSTM)              (None, 100, 16)           3392      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 100, 100)          1700      \n",
            "                                                                 \n",
            " lstm_13 (LSTM)              (None, 100, 16)           7488      \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 12)                19212     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,792\n",
            "Trainable params: 31,792\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 7s 18ms/step - loss: 1.4371 - sparse_categorical_accuracy: 0.5419 - val_loss: 1.0389 - val_sparse_categorical_accuracy: 0.6889\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.9255 - sparse_categorical_accuracy: 0.7197 - val_loss: 0.8602 - val_sparse_categorical_accuracy: 0.7313\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.7329 - sparse_categorical_accuracy: 0.7807 - val_loss: 0.6689 - val_sparse_categorical_accuracy: 0.8031\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.6263 - sparse_categorical_accuracy: 0.8157 - val_loss: 0.5921 - val_sparse_categorical_accuracy: 0.8221\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.5555 - sparse_categorical_accuracy: 0.8375 - val_loss: 0.5529 - val_sparse_categorical_accuracy: 0.8357\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.5062 - sparse_categorical_accuracy: 0.8534 - val_loss: 0.5090 - val_sparse_categorical_accuracy: 0.8528\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.4774 - sparse_categorical_accuracy: 0.8607 - val_loss: 0.5213 - val_sparse_categorical_accuracy: 0.8478\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.4442 - sparse_categorical_accuracy: 0.8713 - val_loss: 0.4838 - val_sparse_categorical_accuracy: 0.8575\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.4312 - sparse_categorical_accuracy: 0.8696 - val_loss: 0.4697 - val_sparse_categorical_accuracy: 0.8649\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.4043 - sparse_categorical_accuracy: 0.8826 - val_loss: 0.4324 - val_sparse_categorical_accuracy: 0.8773\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.3829 - sparse_categorical_accuracy: 0.8862 - val_loss: 0.4183 - val_sparse_categorical_accuracy: 0.8788\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.3677 - sparse_categorical_accuracy: 0.8889 - val_loss: 0.4372 - val_sparse_categorical_accuracy: 0.8800\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.3505 - sparse_categorical_accuracy: 0.8946 - val_loss: 0.4477 - val_sparse_categorical_accuracy: 0.8718\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 4s 19ms/step - loss: 0.3491 - sparse_categorical_accuracy: 0.8934 - val_loss: 0.3932 - val_sparse_categorical_accuracy: 0.8901\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.3305 - sparse_categorical_accuracy: 0.9041 - val_loss: 0.3800 - val_sparse_categorical_accuracy: 0.8963\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.3232 - sparse_categorical_accuracy: 0.9012 - val_loss: 0.3881 - val_sparse_categorical_accuracy: 0.8932\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.3129 - sparse_categorical_accuracy: 0.9051 - val_loss: 0.3802 - val_sparse_categorical_accuracy: 0.8897\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.3044 - sparse_categorical_accuracy: 0.9092 - val_loss: 0.4276 - val_sparse_categorical_accuracy: 0.8843\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.3008 - sparse_categorical_accuracy: 0.9100 - val_loss: 0.3384 - val_sparse_categorical_accuracy: 0.9064\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2891 - sparse_categorical_accuracy: 0.9111 - val_loss: 0.3722 - val_sparse_categorical_accuracy: 0.8948\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.2807 - sparse_categorical_accuracy: 0.9155 - val_loss: 0.3799 - val_sparse_categorical_accuracy: 0.8994\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.2832 - sparse_categorical_accuracy: 0.9146 - val_loss: 0.3690 - val_sparse_categorical_accuracy: 0.8940\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.2719 - sparse_categorical_accuracy: 0.9166 - val_loss: 0.3583 - val_sparse_categorical_accuracy: 0.9014\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.2624 - sparse_categorical_accuracy: 0.9200 - val_loss: 0.3407 - val_sparse_categorical_accuracy: 0.9037\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2606 - sparse_categorical_accuracy: 0.9178 - val_loss: 0.3520 - val_sparse_categorical_accuracy: 0.9021\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2573 - sparse_categorical_accuracy: 0.9197 - val_loss: 0.3302 - val_sparse_categorical_accuracy: 0.9060\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2549 - sparse_categorical_accuracy: 0.9217 - val_loss: 0.3324 - val_sparse_categorical_accuracy: 0.9002\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2463 - sparse_categorical_accuracy: 0.9228 - val_loss: 0.3160 - val_sparse_categorical_accuracy: 0.9150\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2446 - sparse_categorical_accuracy: 0.9253 - val_loss: 0.3509 - val_sparse_categorical_accuracy: 0.9017\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2411 - sparse_categorical_accuracy: 0.9243 - val_loss: 0.3919 - val_sparse_categorical_accuracy: 0.8928\n",
            "199/199 [==============================] - 1s 6ms/step - loss: 0.3263 - sparse_categorical_accuracy: 0.9093\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3263467848300934, 0.9093202948570251]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_7b = Sequential()\n",
        "model_7b._name=\"Experiement7b_2LSTM_with_spatial_Attention\"\n",
        "model_7b.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "model_7b.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_7b.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_7b.add(Dense(SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # spatial module\n",
        "model_7b.add(Flatten())\n",
        "\n",
        "model_7b.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_7b.summary()\n",
        "\n",
        "model_7b.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_7b.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2) \n",
        "model_7b.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpSHnjCE7NOs",
        "outputId": "9254ab95-1188-4c9e-e0a8-ed835de4fb5b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement7b_2LSTM_with_spatial_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_14 (LSTM)              (None, 100, 16)           3392      \n",
            "                                                                 \n",
            " lstm_15 (LSTM)              (None, 100, 16)           2112      \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 100, 100)          1700      \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 10000)             0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 12)                120012    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 127,216\n",
            "Trainable params: 127,216\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 7s 17ms/step - loss: 1.3975 - sparse_categorical_accuracy: 0.5599 - val_loss: 1.1872 - val_sparse_categorical_accuracy: 0.6369\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 1.0376 - sparse_categorical_accuracy: 0.6763 - val_loss: 0.9342 - val_sparse_categorical_accuracy: 0.7017\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.8249 - sparse_categorical_accuracy: 0.7465 - val_loss: 0.8048 - val_sparse_categorical_accuracy: 0.7503\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.7116 - sparse_categorical_accuracy: 0.7829 - val_loss: 0.6358 - val_sparse_categorical_accuracy: 0.8109\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.6352 - sparse_categorical_accuracy: 0.8088 - val_loss: 0.7073 - val_sparse_categorical_accuracy: 0.7981\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.5885 - sparse_categorical_accuracy: 0.8230 - val_loss: 0.5936 - val_sparse_categorical_accuracy: 0.8299\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.5549 - sparse_categorical_accuracy: 0.8346 - val_loss: 0.5576 - val_sparse_categorical_accuracy: 0.8307\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.5174 - sparse_categorical_accuracy: 0.8450 - val_loss: 0.5551 - val_sparse_categorical_accuracy: 0.8412\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.4911 - sparse_categorical_accuracy: 0.8505 - val_loss: 0.4809 - val_sparse_categorical_accuracy: 0.8559\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.4674 - sparse_categorical_accuracy: 0.8591 - val_loss: 0.5120 - val_sparse_categorical_accuracy: 0.8571\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.4497 - sparse_categorical_accuracy: 0.8685 - val_loss: 0.4660 - val_sparse_categorical_accuracy: 0.8637\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.4256 - sparse_categorical_accuracy: 0.8730 - val_loss: 0.4192 - val_sparse_categorical_accuracy: 0.8870\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.4212 - sparse_categorical_accuracy: 0.8751 - val_loss: 0.4534 - val_sparse_categorical_accuracy: 0.8800\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.4027 - sparse_categorical_accuracy: 0.8809 - val_loss: 0.4344 - val_sparse_categorical_accuracy: 0.8800\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.3828 - sparse_categorical_accuracy: 0.8845 - val_loss: 0.4422 - val_sparse_categorical_accuracy: 0.8761\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.3813 - sparse_categorical_accuracy: 0.8841 - val_loss: 0.4011 - val_sparse_categorical_accuracy: 0.8889\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8884 - val_loss: 0.4131 - val_sparse_categorical_accuracy: 0.8862\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.3654 - sparse_categorical_accuracy: 0.8900 - val_loss: 0.4192 - val_sparse_categorical_accuracy: 0.8885\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 4s 18ms/step - loss: 0.3588 - sparse_categorical_accuracy: 0.8932 - val_loss: 0.3852 - val_sparse_categorical_accuracy: 0.8983\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.3436 - sparse_categorical_accuracy: 0.8968 - val_loss: 0.4089 - val_sparse_categorical_accuracy: 0.8917\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.3356 - sparse_categorical_accuracy: 0.9001 - val_loss: 0.3477 - val_sparse_categorical_accuracy: 0.9002\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.3278 - sparse_categorical_accuracy: 0.9010 - val_loss: 0.3713 - val_sparse_categorical_accuracy: 0.9010\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3261 - sparse_categorical_accuracy: 0.9009 - val_loss: 0.3752 - val_sparse_categorical_accuracy: 0.8983\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.3230 - sparse_categorical_accuracy: 0.8998 - val_loss: 0.3715 - val_sparse_categorical_accuracy: 0.8955\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.3182 - sparse_categorical_accuracy: 0.9037 - val_loss: 0.3484 - val_sparse_categorical_accuracy: 0.9049\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.3106 - sparse_categorical_accuracy: 0.9043 - val_loss: 0.3865 - val_sparse_categorical_accuracy: 0.8913\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.3051 - sparse_categorical_accuracy: 0.9060 - val_loss: 0.3558 - val_sparse_categorical_accuracy: 0.9083\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2964 - sparse_categorical_accuracy: 0.9099 - val_loss: 0.3851 - val_sparse_categorical_accuracy: 0.8986\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2981 - sparse_categorical_accuracy: 0.9119 - val_loss: 0.3498 - val_sparse_categorical_accuracy: 0.9060\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.2922 - sparse_categorical_accuracy: 0.9113 - val_loss: 0.3553 - val_sparse_categorical_accuracy: 0.9041\n",
            "199/199 [==============================] - 1s 7ms/step - loss: 0.3196 - sparse_categorical_accuracy: 0.9164\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.31956106424331665, 0.9164169430732727]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_7c = Sequential()\n",
        "model_7c._name=\"Experiement7c_2LSTM_with_spatial_Attention\"\n",
        "model_7c.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "model_7c.add(Dense(SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # spatial module\n",
        "model_7c.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_7c.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_7c.add(Flatten())\n",
        "\n",
        "model_7c.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_7c.summary()\n",
        "\n",
        "model_7c.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_7c.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2) \n",
        "model_7c.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twAz6aLl7amn",
        "outputId": "2a7212ef-7bc3-4f68-d943-ff0a9259ec7e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement7c_2LSTM_with_spatial_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_19 (Dense)            (None, 100, 100)          3700      \n",
            "                                                                 \n",
            " lstm_16 (LSTM)              (None, 100, 16)           7488      \n",
            "                                                                 \n",
            " lstm_17 (LSTM)              (None, 100, 16)           2112      \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 12)                19212     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,512\n",
            "Trainable params: 32,512\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 7s 17ms/step - loss: 1.3132 - sparse_categorical_accuracy: 0.5812 - val_loss: 0.9338 - val_sparse_categorical_accuracy: 0.7014\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 4s 17ms/step - loss: 0.8260 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.7295 - val_sparse_categorical_accuracy: 0.7930\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.6395 - sparse_categorical_accuracy: 0.8181 - val_loss: 0.6001 - val_sparse_categorical_accuracy: 0.8268\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.5392 - sparse_categorical_accuracy: 0.8446 - val_loss: 0.5748 - val_sparse_categorical_accuracy: 0.8427\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.4745 - sparse_categorical_accuracy: 0.8601 - val_loss: 0.4587 - val_sparse_categorical_accuracy: 0.8726\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.4359 - sparse_categorical_accuracy: 0.8724 - val_loss: 0.4587 - val_sparse_categorical_accuracy: 0.8691\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.3961 - sparse_categorical_accuracy: 0.8841 - val_loss: 0.4196 - val_sparse_categorical_accuracy: 0.8808\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.3744 - sparse_categorical_accuracy: 0.8885 - val_loss: 0.4069 - val_sparse_categorical_accuracy: 0.8804\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.3492 - sparse_categorical_accuracy: 0.8937 - val_loss: 0.3827 - val_sparse_categorical_accuracy: 0.8882\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.3324 - sparse_categorical_accuracy: 0.8995 - val_loss: 0.3981 - val_sparse_categorical_accuracy: 0.8777\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.3147 - sparse_categorical_accuracy: 0.9027 - val_loss: 0.3616 - val_sparse_categorical_accuracy: 0.8971\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2989 - sparse_categorical_accuracy: 0.9096 - val_loss: 0.3682 - val_sparse_categorical_accuracy: 0.8963\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2826 - sparse_categorical_accuracy: 0.9162 - val_loss: 0.3721 - val_sparse_categorical_accuracy: 0.8936\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2785 - sparse_categorical_accuracy: 0.9174 - val_loss: 0.3381 - val_sparse_categorical_accuracy: 0.9056\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.2720 - sparse_categorical_accuracy: 0.9158 - val_loss: 0.3307 - val_sparse_categorical_accuracy: 0.9095\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2573 - sparse_categorical_accuracy: 0.9203 - val_loss: 0.3298 - val_sparse_categorical_accuracy: 0.9072\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2533 - sparse_categorical_accuracy: 0.9235 - val_loss: 0.3561 - val_sparse_categorical_accuracy: 0.8975\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2426 - sparse_categorical_accuracy: 0.9238 - val_loss: 0.3230 - val_sparse_categorical_accuracy: 0.9130\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2336 - sparse_categorical_accuracy: 0.9266 - val_loss: 0.3530 - val_sparse_categorical_accuracy: 0.9006\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2317 - sparse_categorical_accuracy: 0.9280 - val_loss: 0.3647 - val_sparse_categorical_accuracy: 0.9060\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2232 - sparse_categorical_accuracy: 0.9297 - val_loss: 0.3408 - val_sparse_categorical_accuracy: 0.9076\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2174 - sparse_categorical_accuracy: 0.9310 - val_loss: 0.3556 - val_sparse_categorical_accuracy: 0.9002\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2156 - sparse_categorical_accuracy: 0.9341 - val_loss: 0.3263 - val_sparse_categorical_accuracy: 0.9122\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2111 - sparse_categorical_accuracy: 0.9329 - val_loss: 0.3214 - val_sparse_categorical_accuracy: 0.9099\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.2052 - sparse_categorical_accuracy: 0.9349 - val_loss: 0.3174 - val_sparse_categorical_accuracy: 0.9115\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.1952 - sparse_categorical_accuracy: 0.9388 - val_loss: 0.3334 - val_sparse_categorical_accuracy: 0.9095\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.1988 - sparse_categorical_accuracy: 0.9358 - val_loss: 0.3197 - val_sparse_categorical_accuracy: 0.9150\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.1908 - sparse_categorical_accuracy: 0.9388 - val_loss: 0.3057 - val_sparse_categorical_accuracy: 0.9212\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.1869 - sparse_categorical_accuracy: 0.9377 - val_loss: 0.2899 - val_sparse_categorical_accuracy: 0.9157\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 3s 13ms/step - loss: 0.1812 - sparse_categorical_accuracy: 0.9402 - val_loss: 0.3027 - val_sparse_categorical_accuracy: 0.9188\n",
            "199/199 [==============================] - 1s 6ms/step - loss: 0.2604 - sparse_categorical_accuracy: 0.9319\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2604054808616638, 0.9318719506263733]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_8a = Sequential()\n",
        "model_8a._name=\"Experiement8a_2LSTM_with_spatial_temporal_Attention\"\n",
        "model_8a.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "model_8a.add(Dense(SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # spatial module\n",
        "model_8a.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_8a.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_8a.add(Dense(NUM_UNITS_LSTM*SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # temporal module\n",
        "\n",
        "model_8a.add(Flatten())\n",
        "\n",
        "model_8a.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_8a.summary()\n",
        "\n",
        "model_8a.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_8a.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2) \n",
        "model_8a.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zRrKpGW7uIA",
        "outputId": "74d67838-d015-478c-8cd8-fd124a66978d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement8a_2LSTM_with_spatial_temporal_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_21 (Dense)            (None, 100, 100)          3700      \n",
            "                                                                 \n",
            " lstm_18 (LSTM)              (None, 100, 16)           7488      \n",
            "                                                                 \n",
            " lstm_19 (LSTM)              (None, 100, 16)           2112      \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 100, 1600)         27200     \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 160000)            0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 12)                1920012   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,960,512\n",
            "Trainable params: 1,960,512\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 7s 19ms/step - loss: 1.4288 - sparse_categorical_accuracy: 0.5470 - val_loss: 1.0128 - val_sparse_categorical_accuracy: 0.6784\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.9365 - sparse_categorical_accuracy: 0.7157 - val_loss: 0.7666 - val_sparse_categorical_accuracy: 0.7724\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.7404 - sparse_categorical_accuracy: 0.7808 - val_loss: 0.7020 - val_sparse_categorical_accuracy: 0.8097\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.6229 - sparse_categorical_accuracy: 0.8191 - val_loss: 0.5325 - val_sparse_categorical_accuracy: 0.8517\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.5379 - sparse_categorical_accuracy: 0.8416 - val_loss: 0.6312 - val_sparse_categorical_accuracy: 0.8000\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 4s 18ms/step - loss: 0.4906 - sparse_categorical_accuracy: 0.8563 - val_loss: 0.5051 - val_sparse_categorical_accuracy: 0.8489\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.4526 - sparse_categorical_accuracy: 0.8721 - val_loss: 0.4599 - val_sparse_categorical_accuracy: 0.8707\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.4174 - sparse_categorical_accuracy: 0.8793 - val_loss: 0.4560 - val_sparse_categorical_accuracy: 0.8750\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3931 - sparse_categorical_accuracy: 0.8817 - val_loss: 0.5198 - val_sparse_categorical_accuracy: 0.8668\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3728 - sparse_categorical_accuracy: 0.8912 - val_loss: 0.5007 - val_sparse_categorical_accuracy: 0.8590\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3530 - sparse_categorical_accuracy: 0.8932 - val_loss: 0.4569 - val_sparse_categorical_accuracy: 0.8532\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3391 - sparse_categorical_accuracy: 0.8997 - val_loss: 0.3887 - val_sparse_categorical_accuracy: 0.8928\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3269 - sparse_categorical_accuracy: 0.8996 - val_loss: 0.4244 - val_sparse_categorical_accuracy: 0.8866\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3176 - sparse_categorical_accuracy: 0.9046 - val_loss: 0.3846 - val_sparse_categorical_accuracy: 0.8901\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3036 - sparse_categorical_accuracy: 0.9108 - val_loss: 0.4260 - val_sparse_categorical_accuracy: 0.8905\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2969 - sparse_categorical_accuracy: 0.9107 - val_loss: 0.3984 - val_sparse_categorical_accuracy: 0.8866\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2905 - sparse_categorical_accuracy: 0.9125 - val_loss: 0.4360 - val_sparse_categorical_accuracy: 0.8750\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2805 - sparse_categorical_accuracy: 0.9144 - val_loss: 0.3827 - val_sparse_categorical_accuracy: 0.8920\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2702 - sparse_categorical_accuracy: 0.9186 - val_loss: 0.4599 - val_sparse_categorical_accuracy: 0.8765\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2673 - sparse_categorical_accuracy: 0.9173 - val_loss: 0.3354 - val_sparse_categorical_accuracy: 0.9126\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2584 - sparse_categorical_accuracy: 0.9202 - val_loss: 0.3747 - val_sparse_categorical_accuracy: 0.9037\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2583 - sparse_categorical_accuracy: 0.9206 - val_loss: 0.4441 - val_sparse_categorical_accuracy: 0.8784\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2395 - sparse_categorical_accuracy: 0.9247 - val_loss: 0.3476 - val_sparse_categorical_accuracy: 0.9060\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2446 - sparse_categorical_accuracy: 0.9257 - val_loss: 0.3826 - val_sparse_categorical_accuracy: 0.9045\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2362 - sparse_categorical_accuracy: 0.9247 - val_loss: 0.3401 - val_sparse_categorical_accuracy: 0.9068\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2397 - sparse_categorical_accuracy: 0.9227 - val_loss: 0.3947 - val_sparse_categorical_accuracy: 0.8948\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2209 - sparse_categorical_accuracy: 0.9290 - val_loss: 0.3857 - val_sparse_categorical_accuracy: 0.9014\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2217 - sparse_categorical_accuracy: 0.9332 - val_loss: 0.4098 - val_sparse_categorical_accuracy: 0.8955\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2273 - sparse_categorical_accuracy: 0.9296 - val_loss: 0.3830 - val_sparse_categorical_accuracy: 0.9037\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2200 - sparse_categorical_accuracy: 0.9290 - val_loss: 0.4064 - val_sparse_categorical_accuracy: 0.9010\n",
            "199/199 [==============================] - 1s 7ms/step - loss: 0.3355 - sparse_categorical_accuracy: 0.9150\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3354703485965729, 0.9149976372718811]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_8b = Sequential()\n",
        "model_8b._name=\"Experiement8b_2LSTM_with_spatial_temporal_Attention\"\n",
        "model_8b.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "model_8b.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_8b.add(Dense(SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # spatial module\n",
        "model_8b.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_8b.add(Dense(NUM_UNITS_LSTM*SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # temporal module\n",
        "\n",
        "model_8b.add(Flatten())\n",
        "\n",
        "model_8b.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_8b.summary()\n",
        "\n",
        "model_8b.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_8b.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2) \n",
        "model_8b.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6S7VTxC71vp",
        "outputId": "f87a314e-b086-4348-9441-09d477b0e58c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement8b_2LSTM_with_spatial_temporal_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_20 (LSTM)              (None, 100, 16)           3392      \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 100, 100)          1700      \n",
            "                                                                 \n",
            " lstm_21 (LSTM)              (None, 100, 16)           7488      \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 100, 1600)         27200     \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 160000)            0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 12)                1920012   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,959,792\n",
            "Trainable params: 1,959,792\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 8s 19ms/step - loss: 1.4545 - sparse_categorical_accuracy: 0.5448 - val_loss: 1.3436 - val_sparse_categorical_accuracy: 0.5472\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.9870 - sparse_categorical_accuracy: 0.6947 - val_loss: 0.9012 - val_sparse_categorical_accuracy: 0.7274\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.8219 - sparse_categorical_accuracy: 0.7560 - val_loss: 0.7381 - val_sparse_categorical_accuracy: 0.7744\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.7082 - sparse_categorical_accuracy: 0.7933 - val_loss: 0.7694 - val_sparse_categorical_accuracy: 0.7693\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.6277 - sparse_categorical_accuracy: 0.8185 - val_loss: 0.5908 - val_sparse_categorical_accuracy: 0.8291\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.5801 - sparse_categorical_accuracy: 0.8315 - val_loss: 0.5091 - val_sparse_categorical_accuracy: 0.8501\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 4s 20ms/step - loss: 0.5293 - sparse_categorical_accuracy: 0.8427 - val_loss: 0.6745 - val_sparse_categorical_accuracy: 0.7744\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.4979 - sparse_categorical_accuracy: 0.8506 - val_loss: 0.5434 - val_sparse_categorical_accuracy: 0.8377\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.4698 - sparse_categorical_accuracy: 0.8635 - val_loss: 0.3919 - val_sparse_categorical_accuracy: 0.8905\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.4447 - sparse_categorical_accuracy: 0.8688 - val_loss: 0.5239 - val_sparse_categorical_accuracy: 0.8404\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.4161 - sparse_categorical_accuracy: 0.8772 - val_loss: 0.6750 - val_sparse_categorical_accuracy: 0.8214\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3982 - sparse_categorical_accuracy: 0.8817 - val_loss: 0.4598 - val_sparse_categorical_accuracy: 0.8742\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.4041 - sparse_categorical_accuracy: 0.8789 - val_loss: 0.4090 - val_sparse_categorical_accuracy: 0.8885\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3842 - sparse_categorical_accuracy: 0.8850 - val_loss: 0.3954 - val_sparse_categorical_accuracy: 0.8901\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3671 - sparse_categorical_accuracy: 0.8879 - val_loss: 0.4084 - val_sparse_categorical_accuracy: 0.8854\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3525 - sparse_categorical_accuracy: 0.8925 - val_loss: 0.4554 - val_sparse_categorical_accuracy: 0.8792\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3439 - sparse_categorical_accuracy: 0.8930 - val_loss: 0.4226 - val_sparse_categorical_accuracy: 0.8858\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3428 - sparse_categorical_accuracy: 0.8971 - val_loss: 0.3799 - val_sparse_categorical_accuracy: 0.8948\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3384 - sparse_categorical_accuracy: 0.8987 - val_loss: 0.3819 - val_sparse_categorical_accuracy: 0.8913\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3282 - sparse_categorical_accuracy: 0.9000 - val_loss: 0.4375 - val_sparse_categorical_accuracy: 0.8858\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3230 - sparse_categorical_accuracy: 0.8995 - val_loss: 0.3625 - val_sparse_categorical_accuracy: 0.8975\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.3122 - sparse_categorical_accuracy: 0.9033 - val_loss: 0.3650 - val_sparse_categorical_accuracy: 0.9060\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3082 - sparse_categorical_accuracy: 0.9063 - val_loss: 0.4489 - val_sparse_categorical_accuracy: 0.8870\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3027 - sparse_categorical_accuracy: 0.9080 - val_loss: 0.3999 - val_sparse_categorical_accuracy: 0.8955\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2954 - sparse_categorical_accuracy: 0.9099 - val_loss: 0.3465 - val_sparse_categorical_accuracy: 0.9091\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2968 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.3654 - val_sparse_categorical_accuracy: 0.9122\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2818 - sparse_categorical_accuracy: 0.9150 - val_loss: 0.3621 - val_sparse_categorical_accuracy: 0.9025\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 3s 14ms/step - loss: 0.2745 - sparse_categorical_accuracy: 0.9164 - val_loss: 0.3594 - val_sparse_categorical_accuracy: 0.9045\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2764 - sparse_categorical_accuracy: 0.9142 - val_loss: 0.3729 - val_sparse_categorical_accuracy: 0.9056\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2753 - sparse_categorical_accuracy: 0.9135 - val_loss: 0.3865 - val_sparse_categorical_accuracy: 0.9021\n",
            "199/199 [==============================] - 1s 7ms/step - loss: 0.3562 - sparse_categorical_accuracy: 0.9090\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3561500906944275, 0.9090048670768738]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_8c = Sequential()\n",
        "model_8c._name=\"Experiement8c_2LSTM_with_spatial_temporal_Attention\"\n",
        "model_8c.add(Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = initializers.Orthogonal()\n",
        "model_8c.add(Dense(SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # spatial module\n",
        "model_8c.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_8c.add(Dense(NUM_UNITS_LSTM*SLIDING_WINDOW_LENGTH, input_shape=(SLIDING_WINDOW_LENGTH,), activation=None)) # temporal module\n",
        "model_8c.add(LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model_8c.add(Flatten())\n",
        "\n",
        "model_8c.add(Dense(NUM_CLASSES))\n",
        "\n",
        "model_8c.summary()\n",
        "\n",
        "model_8c.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model_8c.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=30,validation_split=0.2) \n",
        "model_8c.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KN-NucEB79gU",
        "outputId": "e0831192-f265-4c9e-fb22-b012465d7974"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Experiement8c_2LSTM_with_spatial_temporal_Attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_27 (Dense)            (None, 100, 100)          3700      \n",
            "                                                                 \n",
            " lstm_22 (LSTM)              (None, 100, 16)           7488      \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 100, 1600)         27200     \n",
            "                                                                 \n",
            " lstm_23 (LSTM)              (None, 100, 16)           103488    \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 12)                19212     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 161,088\n",
            "Trainable params: 161,088\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "206/206 [==============================] - 8s 21ms/step - loss: 1.2127 - sparse_categorical_accuracy: 0.6093 - val_loss: 0.7976 - val_sparse_categorical_accuracy: 0.7790\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.6853 - sparse_categorical_accuracy: 0.8012 - val_loss: 0.7832 - val_sparse_categorical_accuracy: 0.7468\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.5068 - sparse_categorical_accuracy: 0.8552 - val_loss: 0.4692 - val_sparse_categorical_accuracy: 0.8586\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.4103 - sparse_categorical_accuracy: 0.8801 - val_loss: 0.5181 - val_sparse_categorical_accuracy: 0.8474\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.3588 - sparse_categorical_accuracy: 0.8931 - val_loss: 0.5100 - val_sparse_categorical_accuracy: 0.8470\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.3280 - sparse_categorical_accuracy: 0.9026 - val_loss: 0.3898 - val_sparse_categorical_accuracy: 0.8917\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.3028 - sparse_categorical_accuracy: 0.9112 - val_loss: 0.3643 - val_sparse_categorical_accuracy: 0.8920\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 4s 19ms/step - loss: 0.2792 - sparse_categorical_accuracy: 0.9159 - val_loss: 0.3321 - val_sparse_categorical_accuracy: 0.9068\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 3s 17ms/step - loss: 0.2692 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.3406 - val_sparse_categorical_accuracy: 0.9076\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.2500 - sparse_categorical_accuracy: 0.9246 - val_loss: 0.3442 - val_sparse_categorical_accuracy: 0.9095\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.2343 - sparse_categorical_accuracy: 0.9265 - val_loss: 0.3464 - val_sparse_categorical_accuracy: 0.9033\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.2299 - sparse_categorical_accuracy: 0.9298 - val_loss: 0.3104 - val_sparse_categorical_accuracy: 0.9192\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.2131 - sparse_categorical_accuracy: 0.9332 - val_loss: 0.3721 - val_sparse_categorical_accuracy: 0.9021\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1993 - sparse_categorical_accuracy: 0.9398 - val_loss: 0.3374 - val_sparse_categorical_accuracy: 0.9107\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1931 - sparse_categorical_accuracy: 0.9377 - val_loss: 0.3602 - val_sparse_categorical_accuracy: 0.9076\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1873 - sparse_categorical_accuracy: 0.9426 - val_loss: 0.3150 - val_sparse_categorical_accuracy: 0.9250\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1846 - sparse_categorical_accuracy: 0.9425 - val_loss: 0.3714 - val_sparse_categorical_accuracy: 0.9033\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1765 - sparse_categorical_accuracy: 0.9432 - val_loss: 0.3167 - val_sparse_categorical_accuracy: 0.9208\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1663 - sparse_categorical_accuracy: 0.9474 - val_loss: 0.3683 - val_sparse_categorical_accuracy: 0.9126\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1632 - sparse_categorical_accuracy: 0.9486 - val_loss: 0.3193 - val_sparse_categorical_accuracy: 0.9223\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1556 - sparse_categorical_accuracy: 0.9503 - val_loss: 0.3288 - val_sparse_categorical_accuracy: 0.9227\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1533 - sparse_categorical_accuracy: 0.9505 - val_loss: 0.3319 - val_sparse_categorical_accuracy: 0.9150\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1502 - sparse_categorical_accuracy: 0.9521 - val_loss: 0.3464 - val_sparse_categorical_accuracy: 0.9223\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1416 - sparse_categorical_accuracy: 0.9542 - val_loss: 0.3621 - val_sparse_categorical_accuracy: 0.9115\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1429 - sparse_categorical_accuracy: 0.9526 - val_loss: 0.3527 - val_sparse_categorical_accuracy: 0.9115\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1354 - sparse_categorical_accuracy: 0.9549 - val_loss: 0.3520 - val_sparse_categorical_accuracy: 0.9200\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1351 - sparse_categorical_accuracy: 0.9581 - val_loss: 0.3393 - val_sparse_categorical_accuracy: 0.9177\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 4s 17ms/step - loss: 0.1305 - sparse_categorical_accuracy: 0.9571 - val_loss: 0.3422 - val_sparse_categorical_accuracy: 0.9216\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1294 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.3452 - val_sparse_categorical_accuracy: 0.9173\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.1225 - sparse_categorical_accuracy: 0.9599 - val_loss: 0.3745 - val_sparse_categorical_accuracy: 0.9130\n",
            "199/199 [==============================] - 2s 8ms/step - loss: 0.2950 - sparse_categorical_accuracy: 0.9259\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.29502785205841064, 0.925879180431366]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary:**\n",
        "\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n"
      ],
      "metadata": {
        "id": "DdE5eYxw9XZ3"
      }
    }
  ]
}
